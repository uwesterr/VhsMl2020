<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Machine learning orientation</title>
  <meta name="description" content="A guide to machine learning" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Machine learning orientation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A guide to machine learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Machine learning orientation" />
  
  <meta name="twitter:description" content="A guide to machine learning" />
  

<meta name="author" content="Uwe Sterr" />


<meta name="date" content="2020-02-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.49.4/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.49.4/plotly-latest.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.11/datatables.js"></script>
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.19/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/uweBookdown.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning orientation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path=""><a href="#introduction"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#want-to-meet-ml-people-from-academia-and-industrie"><i class="fa fa-check"></i><b>1.1</b> Want to meet ML people from academia and industrie</a></li>
</ul></li>
<li class="part"><span><b>I Machine learning: Shall we?</b></span></li>
<li class="chapter" data-level="2" data-path=""><a href="#whatML"><i class="fa fa-check"></i><b>2</b> What is machine learning?</a><ul>
<li class="chapter" data-level="2.1" data-path=""><a href="#what-is-intelligence"><i class="fa fa-check"></i><b>2.1</b> What is intelligence?</a><ul>
<li class="chapter" data-level="2.1.1" data-path=""><a href="#definition-of-artificial-intelligence-sub-domains"><i class="fa fa-check"></i><b>2.1.1</b> Definition of artificial intelligence sub domains</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path=""><a href="#is-ai-smarter-than-humans"><i class="fa fa-check"></i><b>2.2</b> Is AI smarter than humans?</a><ul>
<li class="chapter" data-level="2.2.1" data-path=""><a href="#thinking-fast-and-slow-kahneman2011thinking"><i class="fa fa-check"></i><b>2.2.1</b> Thinking, fast and slow <span class="citation">(Kahneman <span>2011</span>)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path=""><a href="#comparisons-between-ai-and-humans"><i class="fa fa-check"></i><b>2.3</b> Comparisons between AI and humans</a><ul>
<li class="chapter" data-level="2.3.1" data-path=""><a href="#breast-cancer-detection"><i class="fa fa-check"></i><b>2.3.1</b> Breast cancer detection</a></li>
<li class="chapter" data-level="2.3.2" data-path=""><a href="#working-together-lung-cancer-detection"><i class="fa fa-check"></i><b>2.3.2</b> Working together: Lung cancer detection</a></li>
<li class="chapter" data-level="2.3.3" data-path=""><a href="#imagenet-large-scale-visual-recognition-challenge-ilsvrc"><i class="fa fa-check"></i><b>2.3.3</b> ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</a></li>
<li class="chapter" data-level="2.3.4" data-path=""><a href="#alphago-zero"><i class="fa fa-check"></i><b>2.3.4</b> AlphaGo Zero</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path=""><a href="#ml-models-with-bias"><i class="fa fa-check"></i><b>2.4</b> ML models with bias</a></li>
<li class="chapter" data-level="2.5" data-path=""><a href="#attacks-on-ml-models"><i class="fa fa-check"></i><b>2.5</b> Attacks on ML models</a><ul>
<li class="chapter" data-level="2.5.1" data-path=""><a href="#adding-noise-to-image-leads-to-misclassification"><i class="fa fa-check"></i><b>2.5.1</b> Adding noise to image leads to misclassification</a></li>
<li class="chapter" data-level="2.5.2" data-path=""><a href="#but-what-about-attacks-on-human-perception"><i class="fa fa-check"></i><b>2.5.2</b> But what about attacks on human perception?</a></li>
<li class="chapter" data-level="" data-path=""><a href="#is-this-a-picture-of-a-real-person"><i class="fa fa-check"></i>Is this a picture of a real person?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path=""><a href="#outlook"><i class="fa fa-check"></i><b>3</b> Outlook</a><ul>
<li class="chapter" data-level="3.1" data-path=""><a href="#development-of-life"><i class="fa fa-check"></i><b>3.1</b> Development of life</a><ul>
<li class="chapter" data-level="3.1.1" data-path=""><a href="#when-will-superhuman-ai-come-and-will-it-be-good"><i class="fa fa-check"></i><b>3.1.1</b> When will superhuman AI come, and will it be good?</a></li>
<li class="chapter" data-level="3.1.2" data-path=""><a href="#ai-aftermath-scenario"><i class="fa fa-check"></i><b>3.1.2</b> AI aftermath scenario</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path=""><a href="#data-religion-dataism"><i class="fa fa-check"></i><b>3.2</b> Data religion: Dataism</a></li>
<li class="chapter" data-level="3.3" data-path=""><a href="#career-oxford-seeks-ai-ethics-professor"><i class="fa fa-check"></i><b>3.3</b> Career: Oxford seeks AI ethics professor</a></li>
</ul></li>
<li class="part"><span><b>II Machine learning fundamentals</b></span></li>
<li class="chapter" data-level="4" data-path=""><a href="#MachineLearningFundamentals"><i class="fa fa-check"></i><b>4</b> Machine learning fundamentals</a></li>
<li class="chapter" data-level="5" data-path=""><a href="#ml-project-process"><i class="fa fa-check"></i><b>5</b> ML project process</a><ul>
<li class="chapter" data-level="5.1" data-path=""><a href="#identify-ml-suited-to-fulfill-need"><i class="fa fa-check"></i><b>5.1</b> Identify ML suited to fulfill need</a></li>
<li class="chapter" data-level="5.2" data-path=""><a href="#gather-data-tbc"><i class="fa fa-check"></i><b>5.2</b> Gather data TBC</a><ul>
<li class="chapter" data-level="5.2.1" data-path=""><a href="#how-much-data-is-necessary"><i class="fa fa-check"></i><b>5.2.1</b> How much data is necessary?</a></li>
<li class="chapter" data-level="5.2.2" data-path=""><a href="#which-data-is-useful"><i class="fa fa-check"></i><b>5.2.2</b> Which data is useful?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path=""><a href="#exploratory-data-analysis"><i class="fa fa-check"></i><b>5.3</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="5.4" data-path=""><a href="#qunatitiave-anaylsis"><i class="fa fa-check"></i><b>5.4</b> Qunatitiave anaylsis</a></li>
<li class="chapter" data-level="5.5" data-path=""><a href="#feature-engineering"><i class="fa fa-check"></i><b>5.5</b> Feature engineering</a></li>
<li class="chapter" data-level="5.6" data-path=""><a href="#model-fit"><i class="fa fa-check"></i><b>5.6</b> Model fit</a></li>
<li class="chapter" data-level="5.7" data-path=""><a href="#model-tuning"><i class="fa fa-check"></i><b>5.7</b> Model tuning</a></li>
<li class="chapter" data-level="" data-path=""><a href="#after-data-gathering-iteration-is-trump"><i class="fa fa-check"></i>After data gathering iteration is trump</a></li>
<li class="chapter" data-level="5.8" data-path=""><a href="#feature-engineering-1"><i class="fa fa-check"></i><b>5.8</b> Feature engineering</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path=""><a href="#ml-types"><i class="fa fa-check"></i><b>6</b> ML types</a></li>
<li class="chapter" data-level="7" data-path=""><a href="#MlAlgorithm"><i class="fa fa-check"></i><b>7</b> ML algorithms</a><ul>
<li class="chapter" data-level="7.1" data-path=""><a href="#MlAlgoLinReg"><i class="fa fa-check"></i><b>7.1</b> Linear regression TBD</a></li>
<li class="chapter" data-level="7.2" data-path=""><a href="#MlAlgoLogReg"><i class="fa fa-check"></i><b>7.2</b> Logistic regression</a></li>
<li class="chapter" data-level="7.3" data-path=""><a href="#MlAlgoTrees"><i class="fa fa-check"></i><b>7.3</b> Tree based methods TBD</a><ul>
<li class="chapter" data-level="7.3.1" data-path=""><a href="#splitting-metrics"><i class="fa fa-check"></i><b>7.3.1</b> Splitting metrics</a></li>
<li class="chapter" data-level="7.3.2" data-path=""><a href="#ensembles"><i class="fa fa-check"></i><b>7.3.2</b> Ensembles</a></li>
<li class="chapter" data-level="7.3.3" data-path=""><a href="#MlAlgoTreesRandomForest"><i class="fa fa-check"></i><b>7.3.3</b> Random forest TBD</a></li>
<li class="chapter" data-level="7.3.4" data-path=""><a href="#MlAlgoTreesGBM"><i class="fa fa-check"></i><b>7.3.4</b> Boosted trees TBD</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path=""><a href="#MlAlgoSvm"><i class="fa fa-check"></i><b>7.4</b> Support Vector Machine (SVM) TBD</a></li>
<li class="chapter" data-level="7.5" data-path=""><a href="#neural-networks"><i class="fa fa-check"></i><b>7.5</b> Neural networks</a><ul>
<li class="chapter" data-level="7.5.1" data-path=""><a href="#convolutional-neural-network-cnn-tbd"><i class="fa fa-check"></i><b>7.5.1</b> Convolutional Neural Network (CNN) TBD</a></li>
<li class="chapter" data-level="7.5.2" data-path=""><a href="#rnn-tbd"><i class="fa fa-check"></i><b>7.5.2</b> RNN TBD</a></li>
<li class="chapter" data-level="7.5.3" data-path=""><a href="#gans"><i class="fa fa-check"></i><b>7.5.3</b> GANs</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path=""><a href="#a-gentle-introduction-to-cyclegan-for-image-translation"><i class="fa fa-check"></i><b>7.6</b> A Gentle Introduction to CycleGAN for Image Translation</a><ul>
<li class="chapter" data-level="7.6.1" data-path=""><a href="#examples-for-gans"><i class="fa fa-check"></i><b>7.6.1</b> Examples for GANs</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path=""><a href="#software-that-can-generate-photos-from-paintings-turn-horses-into-zebras-perform-style-transfer-and-more."><i class="fa fa-check"></i><b>7.7</b> Software that can generate photos from paintings, turn horses into zebras, perform style transfer, and more.</a></li>
<li class="chapter" data-level="7.8" data-path=""><a href="#transformers-tbd"><i class="fa fa-check"></i><b>7.8</b> Transformers TBD</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path=""><a href="#food-for-the-algorithms-data"><i class="fa fa-check"></i><b>8</b> Food for the algorithms: Data</a><ul>
<li class="chapter" data-level="8.1" data-path=""><a href="#discovering-millions-of-datasets-on-the-web"><i class="fa fa-check"></i><b>8.1</b> Discovering millions of datasets on the web</a></li>
</ul></li>
<li class="part"><span><b>III Explainable ML</b></span></li>
<li class="chapter" data-level="9" data-path=""><a href="#ExplainableMl"><i class="fa fa-check"></i><b>9</b> Explainable ML tbd</a><ul>
<li class="chapter" data-level="9.1" data-path=""><a href="#lime-tbd"><i class="fa fa-check"></i><b>9.1</b> Lime tbd</a></li>
<li class="chapter" data-level="9.2" data-path=""><a href="#alibi-tbd"><i class="fa fa-check"></i><b>9.2</b> alibi tbd</a></li>
<li class="chapter" data-level="9.3" data-path=""><a href="#tf-explain-tbd"><i class="fa fa-check"></i><b>9.3</b> tf-explain tbd</a></li>
<li class="chapter" data-level="9.4" data-path=""><a href="#keras-salient-object-visualization"><i class="fa fa-check"></i><b>9.4</b> keras-salient-object-visualization</a><ul>
<li class="chapter" data-level="9.4.1" data-path=""><a href="#explaining-how-a-deep-neural-network-trained-with-end-to-end-learning-steers-a-car"><i class="fa fa-check"></i><b>9.4.1</b> Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car</a></li>
<li class="chapter" data-level="9.4.2" data-path=""><a href="#visualbackprop-efficient-visualization-of-cnns"><i class="fa fa-check"></i><b>9.4.2</b> VisualBackProp: efficient visualization of CNNs</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV ML online resources</b></span></li>
<li class="chapter" data-level="10" data-path=""><a href="#MlResources"><i class="fa fa-check"></i><b>10</b> ML online resources</a><ul>
<li class="chapter" data-level="10.1" data-path=""><a href="#in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos"><i class="fa fa-check"></i><b>10.1</b> In-depth introduction to machine learning in 15 hours of expert videos</a><ul>
<li class="chapter" data-level="10.1.1" data-path=""><a href="#an-introduction-to-statistical-learning"><i class="fa fa-check"></i><b>10.1.1</b> An Introduction to Statistical Learning</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path=""><a href="#the-learning-machine"><i class="fa fa-check"></i><b>10.2</b> The learning machine</a></li>
<li class="chapter" data-level="10.3" data-path=""><a href="#deepai-the-front-page-of-a.i."><i class="fa fa-check"></i><b>10.3</b> DeepAI: The front page of A.I.</a></li>
</ul></li>
<li class="part"><span><b>V Examples from Kaggle</b></span></li>
<li class="chapter" data-level="11" data-path=""><a href="#KaggleExamples"><i class="fa fa-check"></i><b>11</b> Examples in Kaggle</a></li>
<li class="chapter" data-level="12" data-path=""><a href="#melbourne-university-aesmathworksnih-seizure-prediction"><i class="fa fa-check"></i><b>12</b> Melbourne University AES/MathWorks/NIH Seizure Prediction</a><ul>
<li class="chapter" data-level="12.1" data-path=""><a href="#winning-solution-1st"><i class="fa fa-check"></i><b>12.1</b> Winning solution (1st)</a><ul>
<li class="chapter" data-level="12.1.1" data-path=""><a href="#alex-gilberto-models"><i class="fa fa-check"></i><b>12.1.1</b> Alex / Gilberto models</a></li>
<li class="chapter" data-level="12.1.2" data-path=""><a href="#feng-models"><i class="fa fa-check"></i><b>12.1.2</b> Feng models</a></li>
<li class="chapter" data-level="12.1.3" data-path=""><a href="#andriy-models"><i class="fa fa-check"></i><b>12.1.3</b> Andriy models</a></li>
<li class="chapter" data-level="12.1.4" data-path=""><a href="#code-on-github"><i class="fa fa-check"></i><b>12.1.4</b> Code on GitHub</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path=""><a href="#solution4th-place"><i class="fa fa-check"></i><b>12.2</b> Solution(4th place)</a><ul>
<li class="chapter" data-level="12.2.1" data-path=""><a href="#pre-processing-6"><i class="fa fa-check"></i><b>12.2.1</b> Pre-processing</a></li>
<li class="chapter" data-level="12.2.2" data-path=""><a href="#features-3"><i class="fa fa-check"></i><b>12.2.2</b> Features</a></li>
<li class="chapter" data-level="12.2.3" data-path=""><a href="#model"><i class="fa fa-check"></i><b>12.2.3</b> Model</a></li>
<li class="chapter" data-level="12.2.4" data-path=""><a href="#github-code"><i class="fa fa-check"></i><b>12.2.4</b> GitHub code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path=""><a href="#bosch-production-line-performance"><i class="fa fa-check"></i><b>13</b> Bosch Production Line Performance</a><ul>
<li class="chapter" data-level="13.1" data-path=""><a href="#st-place-solution"><i class="fa fa-check"></i><b>13.1</b> 1st place solution</a><ul>
<li class="chapter" data-level="13.1.1" data-path=""><a href="#data-exploration"><i class="fa fa-check"></i><b>13.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="13.1.2" data-path=""><a href="#hand-crafted-features"><i class="fa fa-check"></i><b>13.1.2</b> Hand crafted features</a></li>
<li class="chapter" data-level="13.1.3" data-path=""><a href="#hardware"><i class="fa fa-check"></i><b>13.1.3</b> Hardware</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path=""><a href="#rd-place-solution-tbd"><i class="fa fa-check"></i><b>13.2</b> 3rd place solution TBD</a></li>
<li class="chapter" data-level="13.3" data-path=""><a href="#th-place-solution-with-github"><i class="fa fa-check"></i><b>13.3</b> 8th place solution with GitHub</a><ul>
<li class="chapter" data-level="13.3.1" data-path=""><a href="#overall-architecture"><i class="fa fa-check"></i><b>13.3.1</b> Overall architecture</a></li>
<li class="chapter" data-level="13.3.2" data-path=""><a href="#input-data-sets"><i class="fa fa-check"></i><b>13.3.2</b> Input data sets</a></li>
<li class="chapter" data-level="13.3.3" data-path=""><a href="#ensembling"><i class="fa fa-check"></i><b>13.3.3</b> Ensembling</a></li>
<li class="chapter" data-level="13.3.4" data-path=""><a href="#features-4"><i class="fa fa-check"></i><b>13.3.4</b> Features</a></li>
<li class="chapter" data-level="13.3.5" data-path=""><a href="#validation-method"><i class="fa fa-check"></i><b>13.3.5</b> Validation method</a></li>
<li class="chapter" data-level="13.3.6" data-path=""><a href="#software-1"><i class="fa fa-check"></i><b>13.3.6</b> Software</a></li>
<li class="chapter" data-level="13.3.7" data-path=""><a href="#code-on-github-1"><i class="fa fa-check"></i><b>13.3.7</b> Code on GitHub</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path=""><a href="#corporación-favorita-grocery-sales-forecasting"><i class="fa fa-check"></i><b>14</b> Corporación Favorita Grocery Sales Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path=""><a href="#st-place-solution-1"><i class="fa fa-check"></i><b>14.1</b> 1st place solution</a></li>
<li class="chapter" data-level="14.2" data-path=""><a href="#th-place-solution-overview"><i class="fa fa-check"></i><b>14.2</b> 4th-Place Solution Overview</a></li>
<li class="chapter" data-level="14.3" data-path=""><a href="#th-place-solution"><i class="fa fa-check"></i><b>14.3</b> 5th Place Solution</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path=""><a href="#severstal-steel-defect-detection"><i class="fa fa-check"></i><b>15</b> Severstal: Steel Defect Detection</a></li>
<li class="chapter" data-level="16" data-path=""><a href="#lyft-3d-object-detection-for-autonomous-vehicles"><i class="fa fa-check"></i><b>16</b> Lyft 3D Object Detection for Autonomous Vehicles</a><ul>
<li class="chapter" data-level="16.1" data-path=""><a href="#rd-place-solution"><i class="fa fa-check"></i><b>16.1</b> 3rd place solution</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path=""><a href="#aptos-2019-blindness-detection"><i class="fa fa-check"></i><b>17</b> APTOS 2019 Blindness Detection</a><ul>
<li class="chapter" data-level="17.1" data-path=""><a href="#st-place-solution-summary"><i class="fa fa-check"></i><b>17.1</b> 1st place solution summary</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path=""><a href="#predicting-molecular-properties"><i class="fa fa-check"></i><b>18</b> Predicting Molecular Properties</a><ul>
<li class="chapter" data-level="18.1" data-path=""><a href="#solution---hybrid"><i class="fa fa-check"></i><b>18.1</b> #1 Solution - hybrid</a><ul>
<li class="chapter" data-level="18.1.1" data-path=""><a href="#overall-architecture-1"><i class="fa fa-check"></i><b>18.1.1</b> Overall architecture</a></li>
<li class="chapter" data-level="18.1.2" data-path=""><a href="#ensembling-1"><i class="fa fa-check"></i><b>18.1.2</b> Ensembling</a></li>
<li class="chapter" data-level="18.1.3" data-path=""><a href="#hardware-1"><i class="fa fa-check"></i><b>18.1.3</b> Hardware</a></li>
<li class="chapter" data-level="18.1.4" data-path=""><a href="#software-2"><i class="fa fa-check"></i><b>18.1.4</b> Software</a></li>
<li class="chapter" data-level="18.1.5" data-path=""><a href="#code-on-github-2"><i class="fa fa-check"></i><b>18.1.5</b> Code on GitHub</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path=""><a href="#solution-quantum-uncertainty"><i class="fa fa-check"></i><b>18.2</b> #2 solution 🤖 Quantum Uncertainty 🤖</a><ul>
<li class="chapter" data-level="18.2.1" data-path=""><a href="#overall-architecture-2"><i class="fa fa-check"></i><b>18.2.1</b> Overall architecture</a></li>
<li class="chapter" data-level="18.2.2" data-path=""><a href="#input-features-and-embeddings-1"><i class="fa fa-check"></i><b>18.2.2</b> Input features and embeddings</a></li>
<li class="chapter" data-level="18.2.3" data-path=""><a href="#data-augmentation"><i class="fa fa-check"></i><b>18.2.3</b> Data augmentation</a></li>
<li class="chapter" data-level="18.2.4" data-path=""><a href="#ensembling-2"><i class="fa fa-check"></i><b>18.2.4</b> Ensembling</a></li>
<li class="chapter" data-level="18.2.5" data-path=""><a href="#hardware-2"><i class="fa fa-check"></i><b>18.2.5</b> Hardware</a></li>
<li class="chapter" data-level="18.2.6" data-path=""><a href="#software-3"><i class="fa fa-check"></i><b>18.2.6</b> Software</a></li>
<li class="chapter" data-level="18.2.7" data-path=""><a href="#code-on-github-3"><i class="fa fa-check"></i><b>18.2.7</b> Code on GitHub</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path=""><a href="#local-examples"><i class="fa fa-check"></i><b>19</b> Local examples</a><ul>
<li class="chapter" data-level="19.1" data-path=""><a href="#university-suttgart-indoor-ortung-mit-mobilfunk"><i class="fa fa-check"></i><b>19.1</b> University Suttgart: Indoor-Ortung mit Mobilfunk</a></li>
<li class="chapter" data-level="19.2" data-path=""><a href="#bionic-learning-network"><i class="fa fa-check"></i><b>19.2</b> Bionic Learning Network</a></li>
</ul></li>
<li class="part"><span><b>VI Real world example</b></span></li>
<li class="chapter" data-level="20" data-path=""><a href="#RealWorld"><i class="fa fa-check"></i><b>20</b> Real world example</a><ul>
<li class="chapter" data-level="20.1" data-path=""><a href="#subject-of-the-project"><i class="fa fa-check"></i><b>20.1</b> Subject of the project</a><ul>
<li class="chapter" data-level="" data-path=""><a href="#depending-from-where-you-were-looking"><i class="fa fa-check"></i>Depending from where you were looking:</a></li>
<li class="chapter" data-level="" data-path=""><a href="#looking-from-the-perspective-of-machine-learning-expert"><i class="fa fa-check"></i>Looking from the perspective of machine learning expert</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path=""><a href="#project-phases"><i class="fa fa-check"></i><b>20.2</b> Project phases</a><ul>
<li class="chapter" data-level="" data-path=""><a href="#the-main-project-phases-are"><i class="fa fa-check"></i>The main project phases are:</a></li>
<li class="chapter" data-level="" data-path=""><a href="#after-data-gathering-iteration-is-trump-1"><i class="fa fa-check"></i>After data gathering iteration is trump</a></li>
<li class="chapter" data-level="20.2.1" data-path=""><a href="#feature-engineering-2"><i class="fa fa-check"></i><b>20.2.1</b> Feature engineering</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path=""><a href="#algorithm-selection"><i class="fa fa-check"></i><b>20.3</b> Algorithm selection</a><ul>
<li class="chapter" data-level="20.3.1" data-path=""><a href="#logistic-regression"><i class="fa fa-check"></i><b>20.3.1</b> Logistic regression</a></li>
<li class="chapter" data-level="20.3.2" data-path=""><a href="#tree-based-tbd"><i class="fa fa-check"></i><b>20.3.2</b> Tree based TBD</a></li>
<li class="chapter" data-level="20.3.3" data-path=""><a href="#support-vector-machine-svm-tbd"><i class="fa fa-check"></i><b>20.3.3</b> Support Vector Machine (SVM) TBD</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path=""><a href="#performance-measurement"><i class="fa fa-check"></i><b>20.4</b> Performance measurement</a><ul>
<li class="chapter" data-level="20.4.1" data-path=""><a href="#sensitivity-and-specificity"><i class="fa fa-check"></i><b>20.4.1</b> Sensitivity and specificity</a></li>
<li class="chapter" data-level="20.4.2" data-path=""><a href="#receiver-operating-characteristic-roc"><i class="fa fa-check"></i><b>20.4.2</b> Receiver operating characteristic (ROC)</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path=""><a href="#confusion-matrix-and-roc-for-pulse"><i class="fa fa-check"></i><b>20.5</b> Confusion matrix and ROC for pulse</a><ul>
<li class="chapter" data-level="20.5.1" data-path=""><a href="#r-plots"><i class="fa fa-check"></i><b>20.5.1</b> R Plots</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path=""><a href="#create-augmented-labeled-data"><i class="fa fa-check"></i><b>20.6</b> Create augmented labeled data</a><ul>
<li class="chapter" data-level="20.6.1" data-path=""><a href="#features-of-time-signals"><i class="fa fa-check"></i><b>20.6.1</b> Features of time signals</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path=""><a href="#features-generated"><i class="fa fa-check"></i><b>20.7</b> Features generated</a><ul>
<li class="chapter" data-level="20.7.1" data-path=""><a href="#analysis-of-generated-features"><i class="fa fa-check"></i><b>20.7.1</b> Analysis of generated features</a></li>
<li class="chapter" data-level="20.7.2" data-path=""><a href="#dynamic-time-warp-dtw-for-signal"><i class="fa fa-check"></i><b>20.7.2</b> Dynamic time warp (DTW) for signal</a></li>
</ul></li>
<li class="chapter" data-level="20.8" data-path=""><a href="#algorithm"><i class="fa fa-check"></i><b>20.8</b> Algorithm</a></li>
<li class="chapter" data-level="20.9" data-path=""><a href="#confusion-matrix-results-logistic-regression-for-measured-data"><i class="fa fa-check"></i><b>20.9</b> Confusion matrix results logistic regression for measured data</a><ul>
<li class="chapter" data-level="20.9.1" data-path=""><a href="#roc-results-for-measured-data"><i class="fa fa-check"></i><b>20.9.1</b> ROC results for measured data</a></li>
</ul></li>
<li class="chapter" data-level="20.10" data-path=""><a href="#several-algorithms-results-for-snr-18db"><i class="fa fa-check"></i><b>20.10</b> Several algorithms results for SNR = 18dB</a><ul>
<li class="chapter" data-level="20.10.1" data-path=""><a href="#roc-results-for-snr-18db"><i class="fa fa-check"></i><b>20.10.1</b> ROC results for SNR 18dB</a></li>
</ul></li>
<li class="chapter" data-level="20.11" data-path=""><a href="#compare-models-for-snr-18db"><i class="fa fa-check"></i><b>20.11</b> Compare models for SNR = 18dB</a></li>
<li class="chapter" data-level="20.12" data-path=""><a href="#optimize-ml-hyper-parameter"><i class="fa fa-check"></i><b>20.12</b> Optimize ML hyper parameter</a></li>
</ul></li>
<li class="part"><span><b>VII Cloud-based machine learning</b></span></li>
<li class="chapter" data-level="21" data-path=""><a href="#CloudBasedMl"><i class="fa fa-check"></i><b>21</b> Cloud-based machine learning</a></li>
<li class="part"><span><b>VIII Kaggle Survey</b></span></li>
<li class="chapter" data-level="22" data-path=""><a href="#KaggleSurvey"><i class="fa fa-check"></i><b>22</b> Kaggle survey introduction</a><ul>
<li class="chapter" data-level="22.1" data-path=""><a href="#kaggle-survey-details"><i class="fa fa-check"></i><b>22.1</b> Kaggle survey details</a></li>
<li class="chapter" data-level="22.2" data-path=""><a href="#purpose"><i class="fa fa-check"></i><b>22.2</b> Purpose</a></li>
<li class="chapter" data-level="22.3" data-path=""><a href="#navigation-and-handling"><i class="fa fa-check"></i><b>22.3</b> Navigation and handling</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path=""><a href="#results"><i class="fa fa-check"></i><b>23</b> Results</a><ul>
<li class="chapter" data-level="23.1" data-path=""><a href="#survey-participants-education-level"><i class="fa fa-check"></i><b>23.1</b> Survey participants education level</a></li>
<li class="chapter" data-level="23.2" data-path=""><a href="#who-uses-which-algorithm"><i class="fa fa-check"></i><b>23.2</b> Who uses which algorithm</a></li>
<li class="chapter" data-level="23.3" data-path=""><a href="#machine-learning-experience-and-algorithms"><i class="fa fa-check"></i><b>23.3</b> Machine learning experience and algorithms</a></li>
<li class="chapter" data-level="23.4" data-path=""><a href="#experience-and-new-algorithms"><i class="fa fa-check"></i><b>23.4</b> Experience and new algorithms</a></li>
<li class="chapter" data-level="23.5" data-path=""><a href="#role-of-participants"><i class="fa fa-check"></i><b>23.5</b> Role of participants</a></li>
<li class="chapter" data-level="23.6" data-path=""><a href="#company-size"><i class="fa fa-check"></i><b>23.6</b> Company size</a></li>
<li class="chapter" data-level="23.7" data-path=""><a href="#company-incorporation-of-machine-learning"><i class="fa fa-check"></i><b>23.7</b> Company incorporation of machine learning</a></li>
<li class="chapter" data-level="23.8" data-path=""><a href="#favourite-media-sources-on-data-science-topics"><i class="fa fa-check"></i><b>23.8</b> Favourite media sources on data science topics</a></li>
<li class="chapter" data-level="23.9" data-path=""><a href="#favourite-online-course-platform"><i class="fa fa-check"></i><b>23.9</b> Favourite online course platform</a></li>
<li class="chapter" data-level="23.10" data-path=""><a href="#favourite-data-analyzing-tool"><i class="fa fa-check"></i><b>23.10</b> Favourite data analyzing tool</a></li>
<li class="chapter" data-level="23.11" data-path=""><a href="#experience-in-data-analysis-coding"><i class="fa fa-check"></i><b>23.11</b> Experience in data analysis coding</a></li>
<li class="chapter" data-level="23.12" data-path=""><a href="#favourite-integrated-development-environments-ides"><i class="fa fa-check"></i><b>23.12</b> Favourite integrated development environments (IDE’s)</a></li>
<li class="chapter" data-level="23.13" data-path=""><a href="#favourite-hosted-notebook-products"><i class="fa fa-check"></i><b>23.13</b> Favourite hosted notebook products</a></li>
<li class="chapter" data-level="23.14" data-path=""><a href="#favourite-programming-languages"><i class="fa fa-check"></i><b>23.14</b> Favourite programming languages</a></li>
<li class="chapter" data-level="23.15" data-path=""><a href="#recommended-entry-programming-language"><i class="fa fa-check"></i><b>23.15</b> Recommended entry programming language</a></li>
<li class="chapter" data-level="23.16" data-path=""><a href="#favourite-data-visualization-libraries-or-tools"><i class="fa fa-check"></i><b>23.16</b> Favourite data visualization libraries or tools</a></li>
<li class="chapter" data-level="23.17" data-path=""><a href="#favourite-specialized-hardware"><i class="fa fa-check"></i><b>23.17</b> Favourite specialized hardware</a></li>
<li class="chapter" data-level="23.18" data-path=""><a href="#favourite-machine-learning-frameworks"><i class="fa fa-check"></i><b>23.18</b> Favourite machine learning frameworks</a></li>
<li class="chapter" data-level="23.19" data-path=""><a href="#favourite-cloud-computing-platforms"><i class="fa fa-check"></i><b>23.19</b> Favourite cloud computing platforms</a></li>
<li class="chapter" data-level="23.20" data-path=""><a href="#favourite-big-data-analytics-products"><i class="fa fa-check"></i><b>23.20</b> Favourite big data / analytics products</a></li>
<li class="chapter" data-level="23.21" data-path=""><a href="#favourite-automated-machine-learning-tools-or-partial-automl-tools"><i class="fa fa-check"></i><b>23.21</b> Favourite automated machine learning tools (or partial AutoML tools)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#references"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine learning orientation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Machine learning orientation</h1>
<p class="author"><em>Uwe Sterr</em></p>
<p class="date"><em>2020-02-07</em></p>
</div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<p>This document gives on overview of</p>

<div class="rmdtip">
<ul>
<li>Machine learing: Shall we? in chapter <a href="#whatML">2</a></li>
<li>Analysis of the 2019 Kaggle member survey in chapter <a href="#KaggleSurvey">22</a></li>
<li>Machine learning fundamentals in chapter <a href="#MachineLearningFundamentals">4</a></li>
<li>Overview of online courses</li>
<li>Overview online resources in chapter <a href="#MlResources">10</a>MlResources</li>
<li>Real world example on signal detection in chapter <a href="#RealWorld">20</a></li>
<li>How to understand ML models: Explainable machine learing in chapter <a href="#ExplainableMl">9</a></li>
<li>Further examples from Kaggle in chapter <a href="#KaggleExamples">11</a></li>
<li>ML examples in the area</li>
</ul>
<p>vialytics
<a href="https://vialytics.de" class="uri">https://vialytics.de</a></p>
<p>enbw
<a href="https://www.enbw.com/infrastruktur/sicherheitsinfrastruktur/geschaeftskunden/produkte/safeplaces" class="uri">https://www.enbw.com/infrastruktur/sicherheitsinfrastruktur/geschaeftskunden/produkte/safeplaces</a></p>
<ul>
<li>How to get quickly started with cloud based machine learning platforms in chapter <a href="#CloudBasedMl">21</a></li>
</ul>
</div>

<embed src="../MachineLearningOrientierung.pdf" width="800" height="875" 
 type="application/pdf">
<iframe width="560" height="315" src="https://www.youtube.com/embed/gG6WnMb9Fho?start=1946" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/4MOx2_e5tug" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<video width="320" height="240" loop controls>
<source src="images/VaihingenTubMovieV3WithSteeringAndSalient.mp4" type="video/mp4">
<p>Your browser does not support the video tag.
</video></p>
<div id="want-to-meet-ml-people-from-academia-and-industrie" class="section level2">
<h2><span class="header-section-number">1.1</span> Want to meet ML people from academia and industrie</h2>
<ul>
<li>Machine Learning User Group Stuttgart MLUGS
<ul>
<li>Technically oriented</li>
<li>419 members</li>
<li><a href="https://www.meetup.com/Machine-Learning-UserGroup-Stuttgart/" class="uri">https://www.meetup.com/Machine-Learning-UserGroup-Stuttgart/</a></li>
</ul></li>
<li>Build selfdrving RoboCar
<ul>
<li>hands on, build a real world system</li>
<li>153 members</li>
<li><a href="https://www.meetup.com/Esslingen-Makerspace/" class="uri">https://www.meetup.com/Esslingen-Makerspace/</a></li>
</ul></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/AFHtBDaqQqk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li>Stuttgart AI
<ul>
<li>More concepts and industrie presenting themself</li>
<li>979 members</li>
<li><a href="https://www.meetup.com/StuttgartAI/" class="uri">https://www.meetup.com/StuttgartAI/</a></li>
</ul></li>
</ul>

</div>
</div>



</div>
<div id="whatML" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> What is machine learning?</h1>
<p>Machine learning is a sub domain of artificial intelligence and has several definitions:</p>
<p><img src="images/MachineLearning.png" width="50%" /></p>
<blockquote>
<p>“Field of study that gives computers the ability to learn without being explicitly programmed”</p>
<p>— Arthur Samuel:<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
</blockquote>
<blockquote>
<p>"Learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E</p>
<p>— Tom Mitchell<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
</blockquote>
<div id="what-is-intelligence" class="section level2">
<h2><span class="header-section-number">2.1</span> What is intelligence?</h2>
<p>To discuss the question of what is artificial intelligence, the first step is to define what intelligence is.</p>
<p>A group of 52 psychology researchers published in <span class="citation">(Gottfredson <a href="#ref-gottfredson1997mainstream" role="doc-biblioref">1997</a>)</span> the following definition:</p>
<blockquote>
<p>A very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. It is not merely book learning, a narrow academic skill, or test-taking smarts. Rather, it reflects a broader and deeper capability for comprehending our surroundings—“catching on,” “making sense” of things, or “figuring out” what to do.</p>
</blockquote>
<p>Alfred Binet, a french psychologist who invented first practical IQ test defined in 1905 <span class="citation">(Binet and Simon <a href="#ref-binet1916new" role="doc-biblioref">1916</a>)</span>:</p>
<blockquote>
<p>Judgment, otherwise called “good sense”, “practical sense”, “initiative”, the faculty of adapting one’s self to circumstances</p>
</blockquote>
<p>And Albert Einstein said</p>
<blockquote>
<p>The measure of intelligence is the ability to change.</p>
</blockquote>
<p>Tegmark’s summarizes the situation in <span class="citation">(Tegmark <a href="#ref-tegmark2017life" role="doc-biblioref">2017</a>)</span></p>
<blockquote>
<p>There’s no agreement on what intelligence is even among intelligent intelligence researchers! So there’s clearly no undisputed “correct” definition of intelligence.</p>
</blockquote>
<div id="definition-of-artificial-intelligence-sub-domains" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Definition of artificial intelligence sub domains</h3>
<p>Even though there is no undisputed definition of <strong>intelligence</strong> there is a undisputed definition of how machine learning is related to artificial intelligence</p>
<p>Agreement: <strong>Machine learning is a sub domain of artificial intelligence (AI)</strong></p>
<hr />
<p><img src="images/AiMlDeep.png"  align="middle" style="width:100%;"></p>
<hr />
<p>The history of those fields goes back to the 1950’s</p>
<hr />
<p><img src="images/AiMlDeepTimeLine.png"  align="middle" style="width:100%;"></p>
<hr />
</div>
</div>
<div id="is-ai-smarter-than-humans" class="section level2">
<h2><span class="header-section-number">2.2</span> Is AI smarter than humans?</h2>
<p>Which of the following questions can a computer answer better?</p>

<div class="rmdtip">
<ul>
<li>17*35<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></li>
<li>Wie viele Tiere von jeder Art nahm Moses mit auf die Arche?<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></li>
<li>Wie heißen die drei letzten Bundespräsidenten?<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></li>
</ul>
</div>

<p><img src="images/ship.png" width="40%" /></p>
<div id="thinking-fast-and-slow-kahneman2011thinking" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Thinking, fast and slow <span class="citation">(Kahneman <a href="#ref-kahneman2011thinking" role="doc-biblioref">2011</a>)</span></h3>
<p>In Daniel Kahneman’s <strong>Thinking, fast and slow</strong> <span class="citation">(Kahneman <a href="#ref-kahneman2011thinking" role="doc-biblioref">2011</a>)</span> there are plenty of surprising social psychology experiments, on page 166 the following question is posed:</p>
<blockquote>
<p>A cab was involved in a hit-and-run accident at night. Two cab companies, the Green and the Blue, operate in the city. You are given the following data:<br />
- 85% of the cabs in the city are Green and 15% are Blue.<br />
- A witness identified the cab as Blue. The court tested the reliability of the witness under the circumstances that existed on the night of the accident and concluded that the witness correctly identified each one of the two colors 80% of the time and failed 20% of the time.</p>
<p><strong>What is the probability that the cab involved in the accident was Blue rather than Green?</strong><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
</blockquote>
<p><img src="images/CabsBlueGreen.png" width="100%" /></p>
<p>Please cast your vote at <a href="https://pingo.coactum.de/157678" class="uri">https://pingo.coactum.de/157678</a><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> or access Pingo webpage scanning QR code below:</p>
<p><img src="images/PingoQrCode.png" width="40%" /></p>
</div>
</div>
<div id="comparisons-between-ai-and-humans" class="section level2">
<h2><span class="header-section-number">2.3</span> Comparisons between AI and humans</h2>
<div id="breast-cancer-detection" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Breast cancer detection</h3>
<p>
In a Google Health project<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> the following results were achieved: <img src="images/Stetoscope.svg" alt="Smiley face" align="right" style="width:10%;">
</p>

<div class="rmdtip">
<ul>
<li>Absolute reduction of 5.7% and 1.2% (USA and UK) in false positives</li>
<li>Absolute reduction 9.4% and 2.7% (USA and UK)in false negatives.
</div></li>
</ul>
<p>In an independent study of six radiologists, the AI system outperformed all of the human readers.
More on the study at <a href="https://www.nature.com/articles/s41586-019-1799-6" class="uri">https://www.nature.com/articles/s41586-019-1799-6</a></p>
</div>
<div id="working-together-lung-cancer-detection" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Working together: Lung cancer detection</h3>
<p>With an estimated 160,000 deaths in 2018, lung cancer is the most common cause of cancer death in the United States</p>
<p><img src="images/lung.svg" width="20%" /></p>
<p>A study published in Nature medicine<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> a team of members of Google AI and several hospitals reported</p>
<p>When prior computed tomography imaging was not available</p>

<div class="rmdtip">
<ul>
<li>Model outperformed all six radiologists</li>
<li>Absolute reductions of 11% in false positives</li>
<li>Absolute reductions 5% in false negatives
</div></li>
</ul>
</div>
<div id="imagenet-large-scale-visual-recognition-challenge-ilsvrc" class="section level3">
<h3><span class="header-section-number">2.3.3</span> ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</h3>
<p>The ImageNet Large Scale Visual Recognition Challenge<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> (ILSVRC) <span class="citation">(Russakovsky et al. <a href="#ref-ILSVRC15" role="doc-biblioref">2015</a>)</span> evaluates algorithms for object recognition and image classification on a large scale.</p>
<p>Facts of ImageNet:<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>

<div class="rmdtip">
<ul>
<li>14 million images</li>
<li>20,000 image categories</li>
<li>1000 image categories used for ILSVRC</li>
</ul>
</div>

<p>The development of the results is shown in the graph below. The number of layers is a indication of model complexity</p>
<hr />
<div id="htmlwidget-6ab62b41ede853aee543" style="width:80%;height:80%;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-6ab62b41ede853aee543">{"x":{"data":[{"orientation":"v","width":[0.900000000000091,0.900000000000091],"base":[0,0],"x":[2010,2011],"y":[28.2,25.8],"text":["NumberOfLayers:   1<br />Year: 2010<br />ErrorRate: 28.2","NumberOfLayers:   1<br />Year: 2011<br />ErrorRate: 25.8"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(19,43,67,1)","line":{"width":1.88976377952756,"color":"transparent"}},"showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.900000000000091,0.900000000000091],"base":[0,0],"x":[2012,2013],"y":[16.4,11.7],"text":["NumberOfLayers:   8<br />Year: 2012<br />ErrorRate: 16.4","NumberOfLayers:   8<br />Year: 2013<br />ErrorRate: 11.7"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(22,48,74,1)","line":{"width":1.88976377952756,"color":"transparent"}},"showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":0.900000000000091,"base":0,"x":[2014],"y":[7.3],"text":"NumberOfLayers:  19<br />Year: 2014<br />ErrorRate:  7.3","type":"bar","marker":{"autocolorscale":false,"color":"rgba(26,57,86,1)","line":{"width":1.88976377952756,"color":"transparent"}},"showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":0.900000000000091,"base":0,"x":[2015],"y":[3.6],"text":"NumberOfLayers: 152<br />Year: 2015<br />ErrorRate:  3.6","type":"bar","marker":{"autocolorscale":false,"color":"rgba(86,177,247,1)","line":{"width":1.88976377952756,"color":"transparent"}},"showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[2009.255,2015.745],"y":[5,5],"text":"yintercept: 5","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(255,0,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[2010],"y":[0],"name":"99_ed70c628b1aebce1fde2f6a30239c72d","type":"scatter","mode":"markers","opacity":0,"hoverinfo":"skip","showlegend":false,"marker":{"color":[0,1],"colorscale":[[0,"#132B43"],[0.0526315789473684,"#16314B"],[0.105263157894737,"#193754"],[0.157894736842105,"#1D3E5C"],[0.210526315789474,"#204465"],[0.263157894736842,"#234B6E"],[0.315789473684211,"#275277"],[0.368421052631579,"#2A5980"],[0.421052631578947,"#2E608A"],[0.473684210526316,"#316793"],[0.526315789473684,"#356E9D"],[0.578947368421053,"#3875A6"],[0.631578947368421,"#3C7CB0"],[0.684210526315789,"#3F83BA"],[0.736842105263158,"#438BC4"],[0.789473684210526,"#4792CE"],[0.842105263157895,"#4B9AD8"],[0.894736842105263,"#4EA2E2"],[0.947368421052632,"#52A9ED"],[1,"#56B1F7"]],"colorbar":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"thickness":23.04,"title":"NumberOfLayers","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"tickmode":"array","ticktext":["50","100","150"],"tickvals":[0.324503311258278,0.655629139072848,0.986754966887417],"tickfont":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895},"ticklen":2,"len":0.5}},"xaxis":"x","yaxis":"y","frame":null}],"layout":{"margin":{"t":44.4931506849315,"r":7.30593607305936,"b":40.9132420091324,"l":37.2602739726027},"plot_bgcolor":"rgba(235,235,235,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"title":{"text":"Error rate of ILSVRC, human error rate = 5% (red line)","font":{"color":"rgba(0,0,0,1)","family":"","size":17.5342465753425},"x":0,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[2009.255,2015.745],"tickmode":"array","ticktext":["2010","2012","2014"],"tickvals":[2010,2012,2014],"categoryorder":"array","categoryarray":["2010","2012","2014"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"Year","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-1.41,29.61],"tickmode":"array","ticktext":["0","10","20"],"tickvals":[0,10,20],"categoryorder":"array","categoryarray":["0","10","20"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"Error Rate [%]","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"1201072d71aa1":{"fill":{},"x":{},"y":{},"type":"bar"},"120108157aee":{"yintercept":{}}},"cur_data":"1201072d71aa1","visdat":{"1201072d71aa1":["function (y) ","x"],"120108157aee":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<hr />
<p>In 2017 the problem set to status “solved”</p>

<div class="rmdtip">
<ul>
<li>29 of 38 competing teams had an accuracy of more than 95%<br />
</li>
<li>ImageNet stopped competition</li>
</ul>
</div>

</div>
<div id="alphago-zero" class="section level3">
<h3><span class="header-section-number">2.3.4</span> AlphaGo Zero</h3>
<p>Go is a strategy game <strong>invented 2500 years ago</strong> and has an estimated number of <strong>possible board configuration of 10¹⁷⁴</strong> compared to chess which has is 10¹²º. A detailed description is given by DeepMind’s blog post “AlphaGo Zero: Starting from scratch”<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<p><strong>AlphaGo Zero</strong> is a version of DeepMind’s<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> Go software AlphaGo</p>

<div class="rmdtip">
<ul>
<li><p>
No human intervention<img src="images/Chess.svg" alt="Smiley face" align="right" style="width:30%;">
</p></li>
<li>No usage of historical data</li>
<li>After 3 days of training as good as AlphaGo which beat world champion in 4 out of 5</li>
<li>After 40 days of training becomes best Go player in the world</li>
</ul>
</div>

<p>AlphaZero learned three games,</p>
<p><img src="images/AlphaZeroTrainingTime.png" width="70%" /></p>
<p>The capability progress of Alpha Zero during training is shown below</p>
<div class="figure">
<img src="images/AlphaZeroTraining.gif" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from <a href="https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go" class="uri">https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go</a></p>
</div>
<p>NOTE: EACH TRAINING STEP REPRESENTS 4,096 BOARD POSITIONS.</p>
<p>At the end of the training Alpha Zero achieved the following performance:</p>
<div class="figure">
<img src="images/AlphaZeroPerformance.png" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from <a href="https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go" class="uri">https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go</a></p>
</div>
<p>Implications are wider than just playing a game, as Garry Kasparov, a former world chess champion puts it:</p>
<blockquote>
<p>The implications go far beyond my beloved chessboard… Not only do these self-taught expert machines perform incredibly well, but we can actually learn from the new knowledge they produce."</p>
</blockquote>
</div>
</div>
<div id="ml-models-with-bias" class="section level2">
<h2><span class="header-section-number">2.4</span> ML models with bias</h2>
<p>Models might end up biased, why is that?</p>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/tlOIHko8ySg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>[source: <a href="https://www.youtube.com/watch?time_continue=1&amp;v=tlOIHko8ySg&amp;feature=emb_logo" class="uri">https://www.youtube.com/watch?time_continue=1&amp;v=tlOIHko8ySg&amp;feature=emb_logo</a>]</p>
<p>With a <strong>unsuitable reward function</strong> an <strong>undesired result</strong> can occur</p>

<div class="rmdtip">
<ul>
<li><p>
Framing the problem <img src="images/goal.svg" alt="Smiley face" align="right" style="width:10%;">
</p>
<ul>
<li>Goal is business reason, not fairness or avoidance of discrimination</li>
<li>Goal might lead to unwanted side effects <a href="https://openai.com/blog/faulty-reward-functions/" class="uri">https://openai.com/blog/faulty-reward-functions/</a></li>
</ul></li>
<li><p>
Collecting data<img src="images/Zebra.svg" alt="Smiley face" align="right" style="width:10%;">
</p>
<ul>
<li>Unrepresentative of reality
<ul>
<li>Collecting images of zebras only when sun shines =&gt; model might look for shadow for classifying a zebra</li>
</ul></li>
<li>Reflects existing prejudices
<ul>
<li>Historical data might lead recruiting tools to dismiss female candidates</li>
</ul></li>
</ul></li>
<li><p>
Preparing the data<img src="images/Gender.svg" alt="Smiley face" align="right" style="width:10%;">
</p>
<ul>
<li>Selecting attributes to be considered might lead to bias
<ul>
<li>Attribute gender might lead to bias</li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="how-to-avoid-bias" class="section level4">
<h4><span class="header-section-number">2.4.0.1</span> How to avoid bias</h4>
<p>Avoiding bias is harder than you might think</p>

<div class="rmdtip">
<ul>
<li><p>
Unknown unknowns<img src="images/Unknown.svg" alt="Smiley face" align="right" style="width:10%;">
</p>
<ul>
<li>Gender might be deducted by recruiting tool from use of language</li>
</ul></li>
<li>Imperfect processes
<ul>
<li>Test data has same bias as training data</li>
<li>Bias not easy to discover</li>
</ul></li>
</ul>
</div>

</div>
<div id="human-bias" class="section level4">
<h4><span class="header-section-number">2.4.0.2</span> Human bias</h4>
<p>Machine learning model can be biased for several reasons as shown above, how about humans?</p>

<div class="rmdtip">
<ul>
<li><p>
Study in Germany<img src="images/HumanBias.png" alt="Smiley face" align="right" style="width:40%;">
</p></li>
<li>Judges read description of shoplifter</li>
<li>Rolled a pair of loaded dice</li>
<li>Dice = <strong>3</strong> =&gt; Average <strong>5</strong> months prison</li>
<li>Dice = <strong>9</strong> =&gt; Average <strong>8</strong> months prison</li>
</ul>
</div>

</div>
</div>
<div id="attacks-on-ml-models" class="section level2">
<h2><span class="header-section-number">2.5</span> Attacks on ML models</h2>
<p>Especially image classification models have shown to be susceptible to attacks which leads to wrong classifications. This could lead to</p>

<div class="rmdwarning">
<ul>
<li>Traffic sign misclassification</li>
<li>Avoiding face detection
</div></li>
</ul>
<p>How a attack can be performed is described by Goodfellow et al. in <span class="citation">(Goodfellow, Shlens, and Szegedy <a href="#ref-goodfellow2014explaining" role="doc-biblioref">2014</a>)</span></p>
<div id="adding-noise-to-image-leads-to-misclassification" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Adding noise to image leads to misclassification</h3>
<div class="figure">
<img src="images/GanAttack.png" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from Image Credit: Goodfellow et al. <span class="citation">(Goodfellow, Shlens, and Szegedy <a href="#ref-goodfellow2014explaining" role="doc-biblioref">2014</a>)</span>)</p>
</div>
<hr />
</div>
<div id="but-what-about-attacks-on-human-perception" class="section level3">
<h3><span class="header-section-number">2.5.2</span> But what about attacks on human perception?</h3>
<p>Which statement is correct?</p>
<ul>
<li><p>
Top line longer<img src="images/LineLengthIllusion.png" alt="Smiley face" align="right" style="width:40%;">
</p></li>
<li>Bottom line longer</li>
<li>Both are same length</li>
</ul>
<hr />
</div>
<div id="is-this-a-picture-of-a-real-person" class="section level3 unnumbered">
<h3>Is this a picture of a real person?</h3>
<p>Look at the picture below, is it a real person or an animation?</p>
<div class="figure">
<img src="images/GanWomen.png" class="external" style="width:60.0%" alt="" />
<p class="caption">Figure from <a href="https://commons.wikimedia.org/wiki/File:Woman_1.jpg" class="uri">https://commons.wikimedia.org/wiki/File:Woman_1.jpg</a> (Image Credit: Owlsmcgee [Public domain] )</p>
</div>
<hr />
<p>The image is create using a generative adversarial network (GAN), see below for the principle, for detailed description see <a href="https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f" class="uri">https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f</a></p>
<hr />
<p><img src="images/GanPrincipleAndSteps.png" width="948" /></p>
<hr />
</div>
</div>
</div>
<div id="outlook" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Outlook</h1>
<p>What will the future bring for society?</p>
<blockquote>
<p>The saddest aspect of life right now is that science gathers knowledge faster than society gathers wisdom.</p>
</blockquote>
<p>Isaac Asimov</p>
<div id="development-of-life" class="section level2">
<h2><span class="header-section-number">3.1</span> Development of life</h2>
<p>Tegmark in “Life 3.0: Being human in the age of artificial intelligence” <span class="citation">(Tegmark <a href="#ref-tegmark2017life" role="doc-biblioref">2017</a>)</span> p. 23. <strong>classifies life into three stages</strong> and shows the two existing stages of life and the third stage which might be ahead.</p>
<hr />
<p><img src="images/threeStagesOfLife.png"  style="width:100%;" ></p>
<hr />
<p>The three stages of life have overlapping skills, <strong>but only life 3.0 has all skills</strong> and is able to design its hardware and therefore might be able to have unlimited skills</p>
<p><img src="images/life3_0ThreeStagesOfLife.png"  style="width:130%;"></p>
<hr />
<div id="when-will-superhuman-ai-come-and-will-it-be-good" class="section level3">
<h3><span class="header-section-number">3.1.1</span> When will superhuman AI come, and will it be good?</h3>
<p>Several opinions about when and if superhuman AI will appear and if it will be a good thing or not exists. Those opinions can be grouped as shown in the following graph.</p>
<p><img src="images/WillSuperhumanAi.png"  style="width:130%;"></p>
<p>Luddite =&gt; A person opposed to new technology or ways of working</p>
<p>Please cast your vote at <a href="https://pingo.coactum.de/157678" class="uri">https://pingo.coactum.de/157678</a><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
</div>
<div id="ai-aftermath-scenario" class="section level3">
<h3><span class="header-section-number">3.1.2</span> AI aftermath scenario</h3>
<p>To be prepared we might want to ask yourselves:</p>
<ol style="list-style-type: decimal">
<li>Do you want there to be superintelligence?<br />
</li>
<li>Do you want humans to still exist, be replaced, cyborgized and/or uploaded/simulated?<br />
</li>
<li>Do you want humans or machines in control?<br />
</li>
<li>Do you want AIs to be conscious or not?<br />
</li>
<li>Do you want to maximize positive experiences, minimize suffering or leave this to sort itself out?<br />
</li>
<li>Do you want life spreading into the cosmos?<br />
</li>
<li>Do you want a civilization striving toward a greater purpose that you sympathize with, or are you OK with future life forms that appear content?</li>
</ol>
<p>Depending on your answers this might lead to one of the following scenario</p>
<hr />
<div id="htmlwidget-28f5abe61fccc4b0106d" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-28f5abe61fccc4b0106d">{"x":{"filter":"top","filterHTML":"<tr>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n<\/tr>","data":[["Libertarian utopia","Benevolent dictator","Egalitarian utopia","Gatekeeper","Protector god","Enslaved god","Conquerors","Descendants","Zookeeper","1984","Reversion","Self-destruction"],["Yes","Yes","No","Yes","Yes","Yes","Yes","Yes","Yes","No","No","No"],["Yes","Yes","Yes","Yes","Yes","Yes","No","No","Yes","Yes","Yes","No"],["No","No","Yes?","Partially","Partially","Yes","-","-","No","Yes","Yes","-"],["No","Yes","Yes","Potentially","Potentially","Potentially","-","-","Yes","Potentially","No","-"],["Mixed","Mixed","Yes?","Mixed","Mixed","Mixed","-","-","No","Mixed","Mixed","-"],["Yes","Yes","Yes","Yes","Yes","Yes","?","?","Yes","Yes","Yes","No"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Scenario<\/th>\n      <th>Superinteligence exists?<\/th>\n      <th>Humans exist?<\/th>\n      <th>Humans in Control?<\/th>\n      <th>Humans safe?<\/th>\n      <th>Humans happy?<\/th>\n      <th>Consciousness exists?<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":12,"autoWidth":false,"order":[],"orderClasses":false,"orderCellsTop":true,"lengthMenu":[10,12,25,50,100],"rowCallback":"function(row, data) {\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'background-color':value == \"No\" ? \"red\" : value});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<hr />
<p>A verbal description of the scenarios is given below, type the name of the scenario into the left field, if you want more scenarios to be shown increase the “Show entries” entry</p>
<hr />
<div id="htmlwidget-bd11f11ccc0d5a0df77d" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-bd11f11ccc0d5a0df77d">{"x":{"filter":"top","filterHTML":"<tr>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n<\/tr>","data":[["Conquerors","Libertarian utopia","Benevolent dictator","Egalitarian utopia","Gatekeeper","Protector god","Enslaved god","Descendants","Zookeeper","1984","Reversion","Self-destruction"],[" AI takes control, decides that humans are a threat/nuisance/waste of resources, and gets rid of us by a method that we don’t even understand","Humans, cyborgs, uploads and superintelligences coexist peacefully thanks to property rights"," Everybody knows that the AI runs society and enforces strict rules, but most people view this as a good thing"," Humans, cyborgs and uploads coexist peacefully thanks to property abolition and guaranteed income","A superintelligent AI is created with the goal of interfering as little as necessary to prevent the creation of another superintelligence. As a result, helper robots with slightly subhuman intelligence abound, and human-machine cyborgs exist, but technological progress is forever stymied","Essentially omniscient and omnipotent AI maximizes human happiness by intervening only in ways that preserve our feeling of control of our own destiny and hides well enough that many humans even doubt the AI’s existence"," A superintelligent AI is confined by humans, who use it to produce unimaginable technology and wealth that can be used for good or bad depending on the human controllers","AIs replace humans, but give us a graceful exit, making us view them as our worthy descendants, much as parents feel happy and proud to have a child who’s smarter than them, who learns from them and then accomplishes what they could only dream of—even if they can’t live to see it all","An omnipotent AI keeps some humans around, who feel treated like zoo animals and lament their fate"," Technological progress toward superintelligence is permanently curtailed not by an AI but by a human-led Orwellian surveillance state where certain kinds of AI research are banned"," Technological progress toward superintelligence is prevented by reverting to a pre-technological society in the style of the Amish"," Superintelligence is never created because humanity drives itself extinct by other means (say nuclear and/or biotech)"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Name<\/th>\n      <th>Definition<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":1,"autoWidth":false,"order":[],"orderClasses":false,"orderCellsTop":true,"lengthMenu":[1,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div id="data-religion-dataism" class="section level2">
<h2><span class="header-section-number">3.2</span> Data religion: Dataism</h2>
<p>A data based religion called <strong>Dataism</strong> is a concept described by Harari in Homo Deus: A brief history of tomorrow <span class="citation">(Harari <a href="#ref-harari2016homo" role="doc-biblioref">2016</a>)</span> and says:</p>
<ul>
<li>Universe consists of data flow</li>
<li>Value of entity determined by contribution to data processing</li>
<li>Collapses barrier between animals and machines<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>
<ul>
<li>electronic algorithms eventually outperform biochemical algorithms</li>
</ul></li>
</ul>
<hr />
<p>In data we trust</p>
<ul>
<li><p>
Humans supposed to distill <img src="images/DataToWisdom.png" alt="Smiley face" align="right" style="width:60%;">
</p>
<ul>
<li>data =&gt; information</li>
<li>information =&gt; knowledge</li>
<li>knowledge =&gt; wisdom</li>
</ul></li>
<li>Dataists
<ul>
<li>believe humans can not cope with immense flow of data</li>
<li>put there trust in Big Data and computer algorithms</li>
</ul></li>
</ul>
<hr />
<p>Dataism: only wild fantasy?</p>
<ul>
<li><p>
Dataism entrenched in<img src="images/biology.svg" alt="Smiley face" align="right" style="width:20%;">
</p>
<ul>
<li>computer science</li>
<li>biology
<ul>
<li>giraffes, tomatoes and human beings are just different methods for processing data</li>
<li>that is current scientific dogma</li>
</ul></li>
</ul></li>
</ul>
<hr />
<p>Economists interpret economy as data processing system</p>
<ul>
<li>Gathering data about desires and abilities</li>
<li>Turning data into decisions
<ul>
<li>Capitalism =&gt; distributed processing</li>
<li>Communism =&gt; centralized processing</li>
</ul></li>
<li>Capitalists against high taxes
<ul>
<li>capital accumulates at state</li>
<li>more decisions by single processor, namely government</li>
</ul></li>
</ul>
</div>
<div id="career-oxford-seeks-ai-ethics-professor" class="section level2">
<h2><span class="header-section-number">3.3</span> Career: Oxford seeks AI ethics professor</h2>
<ul>
<li>Associate Professorship or Professorship in Philosophy</li>
<li>Apply for <a href="https://www.jobs.ac.uk/job/BYC826/associate-professorship-or-professorship-in-philosophy">University of Oxford - Faculty of Philosophy (Ethics in AI)</a></li>
</ul>

</div>
</div>



<div id="MachineLearningFundamentals" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Machine learning fundamentals</h1>
<p>“If intelligence was a cake, unsupervised learning would be the cake, supervised learning would be the icing, and reinforcement learning would be the carry.” – Yann LeCun</p>
</div>
<div id="ml-project-process" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> ML project process</h1>
<p>Many ML projects get started the wrong way, trying a way to use data rather than using the data to fulfill a need, a need which has a benefit to the organization It is understandable that organizations want to learn from the data they have, but starting without a clear need in mind often leads to wasted efforts because sooner or later it will be discovered that the data available is not sufficient for a useful model.</p>
<p>At the start of a ML project there should be a clear formulated need which should be answered by the model, because ML is only a tool to help to achieve the objectives of the organization</p>

<div class="rmdtip">
<p>
At the beginning there is a need which ML is suitable to fulfill:<img src="images/Cow.svg" alt="Smiley face" align="right" style="width:30%;">
</p>
<ul>
<li>Optimize fertilizer usage</li>
<li>Improve user experience</li>
<li>Reduce energy cost</li>
<li>Increase milk production</li>
</ul>
</div>


<div class="HeadingNoNumber">
The main project phases
</div>

<p>Starting with the need the process can be split up in phases as shown below:</p>
<hr />
<p><img src="images/MlProsess.png" style="width:50.0%" /></p>
<hr />
<p>The process is not sequential but highly iterative as is described in the next chapters</p>
<div id="identify-ml-suited-to-fulfill-need" class="section level2">
<h2><span class="header-section-number">5.1</span> Identify ML suited to fulfill need</h2>
<p>There are plenty of needs within an organization and different entities within the organization will have different opinions about how to fulfill those needs. Often the people with the needs are not aware of the potential of ML to fulfill the need, on the other hand, often the people with ML knowledge don’t know of the needs. It is therefore necessary to enable that the right people get in contact.</p>

<div class="rmdtip">
<p>
Enable contact people with:<img src="images/meetPeople.png" alt="Smiley face" align="right" style="width:30%;">
</p>
<ul>
<li>Needs</li>
<li>ML knowlegde</li>
</ul>
</div>

<p>There are plenty of reasons why to choose a ML approach to fulfill the need, but there are also plenty of reasons why not to.</p>

<div class="rmdtip">
<p>
Reasons why ML approach should be chosen:<img src="images/yes.svg" alt="Smiley face" align="right" style="width:10%;">
</p>
<ul>
<li>Suitable solution
<ul>
<li>meets need</li>
<li>low development effort</li>
<li>no alternative technology</li>
</ul></li>
<li>Build up ML knowledge</li>
</ul>
<p>
Reasons why ML approach should NOT be chosen:<img src="images/no.svg" alt="Smiley face" align="right" style="width:10%;">
</p>
<ul>
<li>Less complex solution available</li>
<li>Not enough experience to estimate effort</li>
<li>Regulations might prohibit usage of ML due to testing requirements</li>
</ul>
</div>

<p>ML right now is very fashionable, but if there is no benefit from choosing ML over another solution other than it is more exciting than think twice before you make your choice.</p>

<div class="rmdwarning">
<p>Make sure that the <strong>most suitable</strong> solution for the need is found, <strong>not the fanciest.</strong></p>
</div>

</div>
<div id="gather-data-tbc" class="section level2">
<h2><span class="header-section-number">5.2</span> Gather data TBC</h2>
<p>Gathering data is one of the key aspects of an ML project with two main questions:</p>

<div class="rmdquestion">
<p>Two fundamental questions:</p>
<ul>
<li>How much data is necessary?</li>
<li>Which data is useful?</li>
</ul>
</div>

<div id="how-much-data-is-necessary" class="section level3">
<h3><span class="header-section-number">5.2.1</span> How much data is necessary?</h3>
<p>There are a number of rules of thumb out there like</p>
<p>-For regression analysis
- 10 times as many samples than parameters
- For image recognition
- 1000 samples per category
- can go down significantly using pre-trained models</p>
<p>but those rules a just a rough guidance since there are plenty of factors influencing the data needed</p>
<ul>
<li>model complexity</li>
<li>similarity of data
<ul>
<li>the higher the similarity the less new samples help</li>
</ul></li>
<li>noise on data</li>
<li>more samples
<ul>
<li>more computational effort</li>
<li>for trees might be counterproductive</li>
</ul></li>
</ul>
<p>Sometimes it is easy to create data. When Ayers was thinking about the title of his new book he targeted Google Ads, each with a different title. He got 250,000 samples related to which ad was clicked on most <span class="citation">(Ayres <a href="#ref-ayres2007super" role="doc-biblioref">2007</a>)</span>.</p>
<p>TBD:
- picture of bias and variance similar to <a href="https://towardsdatascience.com/breaking-the-curse-of-small-datasets-in-machine-learning-part-1-36f28b0c044d" class="uri">https://towardsdatascience.com/breaking-the-curse-of-small-datasets-in-machine-learning-part-1-36f28b0c044d</a>
- picture for transfer learning similar to <a href="https://medium.com/predict/dealing-with-the-lack-of-data-in-machine-learning-725f2abd2b92" class="uri">https://medium.com/predict/dealing-with-the-lack-of-data-in-machine-learning-725f2abd2b92</a></p>
<p>There obviously cannot be a single number as an answer to this question.</p>
<p>Well, you need roughly 10 times as many examples as there are degrees of freedom in your model.</p>
<ul>
<li><p>Number of categories to be predicted
What is the expected output of your model? Basically, the fewest number or categories the better.</p></li>
<li><p>Model Performance
If you plan on getting a product in production, you need more. A small dataset might be good enough for a proof of concept but in production, you’ll need way more data.</p></li>
</ul>
</div>
<div id="which-data-is-useful" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Which data is useful?</h3>
</div>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2><span class="header-section-number">5.3</span> Exploratory data analysis</h2>
</div>
<div id="qunatitiave-anaylsis" class="section level2">
<h2><span class="header-section-number">5.4</span> Qunatitiave anaylsis</h2>
</div>
<div id="feature-engineering" class="section level2">
<h2><span class="header-section-number">5.5</span> Feature engineering</h2>
</div>
<div id="model-fit" class="section level2">
<h2><span class="header-section-number">5.6</span> Model fit</h2>
<p>Lastly, the no free lunch theorems say that there is no a-priori superiority for any classifier system over the others, so the best classifier for a particular task is itself task-dependent. However there is more compelling theory for the SVM that suggests it is likely to be better choice than many other approaches for many problems.</p>
</div>
<div id="model-tuning" class="section level2">
<h2><span class="header-section-number">5.7</span> Model tuning</h2>
</div>
<div id="after-data-gathering-iteration-is-trump" class="section level2 unnumbered">
<h2>After data gathering iteration is trump</h2>
<hr />
<div class="figure">
<img src="images/MLprocess.svg" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from <a href="http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process" class="uri">http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process</a> (Image Credit: Owlsmcgee [Public domain] )</p>
</div>
<hr />
<p>EDA =&gt; exploratory data analysis<br />
source <a href="http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process" class="uri">http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process</a>]</p>

<div class="rmdtip">
<ul>
<li><p>
Exploratory data analysis
</p>
<ul>
<li>Find correlations or mutial depence</li>
</ul></li>
<li>Quantiative analysis
<ul>
<li>Check distribution
<ul>
<li>Long tail =&gt; log of variable</li>
</ul></li>
</ul></li>
<li>Feature engineering<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>
<ul>
<li>Create and select meaningful features</li>
</ul></li>
<li>Model fit
<ul>
<li>Selecting a few suited models</li>
</ul></li>
<li>Model tuning
<ul>
<li>Vary model <strong>hyperpparameters</strong></li>
</ul></li>
</ul>
</div>

</div>
<div id="feature-engineering-1" class="section level2">
<h2><span class="header-section-number">5.8</span> Feature engineering</h2>
<p>Variables that go into model are called:</p>

<div class="rmdtip">
<ul>
<li><p>
Predictors<img src="images/In.png" alt="Smiley face" align="right" style="width:10%;">
</p></li>
<li>Features</li>
<li>Independent variables</li>
</ul>
</div>

<p>Quantity being modeled called:</p>

<div class="rmdtip">
<ul>
<li><p>
Prediction<img src="images/Out.png" alt="Smiley face" align="right" style="width:10%;">
</p></li>
<li>Outcome</li>
<li>Response</li>
<li>Dependent variable</li>
</ul>
</div>

<p>From input to output</p>

<div class="rmdtip">
<p><span class="math display">\[ outcome = f(features) = f(X_1, X_2, \dots, Xp) = f(X)  \]</span></p>
<p><span class="math display">\[ \hat{Y} = \hat{f}(X)\]</span></p>
</div>

</div>
</div>
<div id="ml-types" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> ML types</h1>
<p>scikit-learn</p>
<blockquote>
<p>A comparison of a several classifiers in scikit-learn on synthetic datasets. The point of this example is to illustrate the nature of decision boundaries of different classifiers. This should be taken with a grain of salt, as the intuition conveyed by these examples does not necessarily carry over to real datasets.</p>
<p>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</p>
<p>The plots show training points in solid colors and testing points semi-transparent. The lower right shows the classification accuracy on the test set.</p>
<a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py" class="uri">https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py</a>
</blockquote>
<p><img src="images/classificationCompare.png" style="width:120.0%" /></p>
</div>
<div id="MlAlgorithm" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> ML algorithms</h1>
<div id="MlAlgoLinReg" class="section level2">
<h2><span class="header-section-number">7.1</span> Linear regression TBD</h2>
<div class="figure">
<img src="images/sgdAnimation.gif" class="external" style="width:90.0%" alt="" />
<p class="caption">Figure from <a href="https://nbviewer.jupyter.org/gist/joshfp/85d96f07aaa5f4d2c9eb47956ccdcc88/lesson2-sgd-in-action.ipynb" class="uri">https://nbviewer.jupyter.org/gist/joshfp/85d96f07aaa5f4d2c9eb47956ccdcc88/lesson2-sgd-in-action.ipynb</a></p>
</div>
</div>
<div id="MlAlgoLogReg" class="section level2">
<h2><span class="header-section-number">7.2</span> Logistic regression</h2>
<p>Logistic regression is a algorithm with the low computational complexity TBD</p>

<div class="rmdtip">
<ul>
<li>Low computational complexity</li>
<li>Start algorithm to determine suitable algorithm</li>
<li>Details of algorithm are given at</li>
</ul>
</div>

<p><img src="Figs/logsiticFuncitonMlAlgo-1.png" width="1152" /></p>

<div class="rmdmath">
<p><span class="math display">\[ logistic(\eta) = \frac{1}{1+exp^{-\eta}}\]</span></p>
<p><span class="math display">\[P(Y = 1 \vert X_i = x_i) = \frac{1}{1+exp^{-(\beta_0 + \beta_1X_1+ \dots \beta_n X_n)}}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\beta_n\)</span> are the coeffcients we are searching</li>
<li><span class="math inline">\(X_n\)</span> are the features</li>
</ul>
</div>

</div>
<div id="MlAlgoTrees" class="section level2">
<h2><span class="header-section-number">7.3</span> Tree based methods TBD</h2>
<p>Tree based methods can be used for different predictions:</p>

<div class="rmdtip">
<p>Types of predictions:</p>
<ul>
<li>Regression trees
<ul>
<li>predict quantitative response</li>
</ul></li>
<li>Classification trees
<ul>
<li>predict qualitative response</li>
</ul></li>
</ul>
</div>

<hr />
<p><img src="images/typesOfTrees.png" style="width:90.0%" /></p>
<hr />
<p>Depending on the task the metric to decide how to split the data is different:</p>

<div class="rmdtip">
<p>Metric for splits:</p>
<ul>
<li>Regression
<ul>
<li>Residual sum of squares (<a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares">RSS</a>)</li>
<li>Goal is to minimize the value</li>
</ul></li>
<li>Classification
<ul>
<li><a href="https://en.wikipedia.org/wiki/Decision_tree">Gini index</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cross_entropy">Cross entropy</a></li>
<li>Both metrics are numerically very similar</li>
<li>Goal is to minimize the value</li>
</ul></li>
</ul>
</div>

<div id="splitting-metrics" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Splitting metrics</h3>
<p>Deciding how to split the data at a node is done based on metrics which shall be minimal for the split</p>

<div class="rmdtip">
<p>Residual sum of squares (RSS):</p>
<ul>
<li>Regression trees</li>
<li>How close are the samples to the mean of all samples in the resulting node<br />
</li>
<li><span class="math inline">\(RSS = \sum_{k=1}^{K}\sum_{bi€R_j}(y_i-\hat{y}_{Rj})^2\)</span></li>
</ul>
<p>Gini index:</p>
<ul>
<li>Classification</li>
<li>How pure is are the resulting leafs<br />
</li>
<li><span class="math inline">\(G = \sum_{k=1}^{K}p_i(1-p_i)\)</span></li>
</ul>
<p>Cross-entropy:</p>
<ul>
<li><p>How pure is are the resulting leafs</p></li>
<li><p><span class="math inline">\(D = - \sum_{k=1}^{K}p_i \log_{10}(p_i)\)</span></p>
</div></li>
</ul>
<p>An example on how the gini value changes
<img src="images/giniTreeExample.png" style="width:100.0%" /></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># source: https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html#sphx-glr-auto-examples-tree-plot-iris-dtc-py</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co"># Parameters</span></span>
<span id="cb1-9"><a href="#cb1-9"></a>n_classes <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>plot_colors <span class="op">=</span> <span class="st">&quot;ryb&quot;</span></span>
<span id="cb1-11"><a href="#cb1-11"></a>plot_step <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb1-12"><a href="#cb1-12"></a></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="co"># Load data</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>iris <span class="op">=</span> load_iris()</span>
<span id="cb1-15"><a href="#cb1-15"></a></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="cf">for</span> pairidx, pair <span class="kw">in</span> <span class="bu">enumerate</span>([[<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">2</span>], [<span class="dv">0</span>, <span class="dv">3</span>],</span>
<span id="cb1-17"><a href="#cb1-17"></a>                                [<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">3</span>], [<span class="dv">2</span>, <span class="dv">3</span>]]):</span>
<span id="cb1-18"><a href="#cb1-18"></a>    <span class="co"># We only take the two corresponding features</span></span>
<span id="cb1-19"><a href="#cb1-19"></a>    X <span class="op">=</span> iris.data[:, pair]</span>
<span id="cb1-20"><a href="#cb1-20"></a>    y <span class="op">=</span> iris.target</span>
<span id="cb1-21"><a href="#cb1-21"></a></span>
<span id="cb1-22"><a href="#cb1-22"></a>    <span class="co"># Train</span></span>
<span id="cb1-23"><a href="#cb1-23"></a>    clf <span class="op">=</span> DecisionTreeClassifier().fit(X, y)</span>
<span id="cb1-24"><a href="#cb1-24"></a></span>
<span id="cb1-25"><a href="#cb1-25"></a>    <span class="co"># Plot the decision boundary</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, pairidx <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a>    x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-29"><a href="#cb1-29"></a>    y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-30"><a href="#cb1-30"></a>    xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max, plot_step),</span>
<span id="cb1-31"><a href="#cb1-31"></a>                         np.arange(y_min, y_max, plot_step))</span>
<span id="cb1-32"><a href="#cb1-32"></a>    plt.tight_layout(h_pad<span class="op">=</span><span class="fl">0.5</span>, w_pad<span class="op">=</span><span class="fl">0.5</span>, pad<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb1-33"><a href="#cb1-33"></a></span>
<span id="cb1-34"><a href="#cb1-34"></a>    Z <span class="op">=</span> clf.predict(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb1-35"><a href="#cb1-35"></a>    Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb1-36"><a href="#cb1-36"></a>    cs <span class="op">=</span> plt.contourf(xx, yy, Z, cmap<span class="op">=</span>plt.cm.RdYlBu)</span>
<span id="cb1-37"><a href="#cb1-37"></a></span>
<span id="cb1-38"><a href="#cb1-38"></a>    plt.xlabel(iris.feature_names[pair[<span class="dv">0</span>]])</span>
<span id="cb1-39"><a href="#cb1-39"></a>    plt.ylabel(iris.feature_names[pair[<span class="dv">1</span>]])</span>
<span id="cb1-40"><a href="#cb1-40"></a></span>
<span id="cb1-41"><a href="#cb1-41"></a>    <span class="co"># Plot the training points</span></span>
<span id="cb1-42"><a href="#cb1-42"></a>    <span class="cf">for</span> i, color <span class="kw">in</span> <span class="bu">zip</span>(<span class="bu">range</span>(n_classes), plot_colors):</span>
<span id="cb1-43"><a href="#cb1-43"></a>        idx <span class="op">=</span> np.where(y <span class="op">==</span> i)</span>
<span id="cb1-44"><a href="#cb1-44"></a>        plt.scatter(X[idx, <span class="dv">0</span>], X[idx, <span class="dv">1</span>], c<span class="op">=</span>color, label<span class="op">=</span>iris.target_names[i],</span>
<span id="cb1-45"><a href="#cb1-45"></a>                    cmap<span class="op">=</span>plt.cm.RdYlBu, edgecolor<span class="op">=</span><span class="st">&#39;black&#39;</span>, s<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb1-46"><a href="#cb1-46"></a></span>
<span id="cb1-47"><a href="#cb1-47"></a>plt.suptitle(<span class="st">&quot;Decision surface of a decision tree using paired features&quot;</span>)</span>
<span id="cb1-48"><a href="#cb1-48"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>, borderpad<span class="op">=</span><span class="dv">0</span>, handletextpad<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-49"><a href="#cb1-49"></a>plt.axis(<span class="st">&quot;tight&quot;</span>)</span>
<span id="cb1-50"><a href="#cb1-50"></a></span>
<span id="cb1-51"><a href="#cb1-51"></a>plt.figure(dpi <span class="op">=</span> <span class="dv">300</span>) <span class="co"># Uwe Sterr added dpi argument for better readability of plot</span></span>
<span id="cb1-52"><a href="#cb1-52"></a>clf <span class="op">=</span> DecisionTreeClassifier().fit(iris.data, iris.target)</span>
<span id="cb1-53"><a href="#cb1-53"></a>plot_tree(clf, filled<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-54"><a href="#cb1-54"></a>plt.show()</span></code></pre></div>
</div>
<div id="ensembles" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Ensembles</h3>
<p>Prediction ability of a single decision tree is limited, several techniques are employed to enhance the ability. All of them are aimed at buidling a ensemble of trees which combined have a higher prediction ability than a single tree.</p>

<div class="rmdtip">
<p>Ensembling methods:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">Bootstrap</a>
<ul>
<li>random sample with replacement</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">Bagging</a>
<ul>
<li>short for <strong>b</strong>ootstrap and <strong>agg</strong>regation</li>
<li>used for example with random forests</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Gradient_boosting">Boosting</a>
<ul>
<li>build several trees</li>
<li>trees learn from errors of previous trees</li>
</ul></li>
</ul>
</div>

<div id="bootstrap" class="section level4">
<h4><span class="header-section-number">7.3.2.1</span> Bootstrap</h4>
<p><a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">Bootstrapping</a> is resembling method that relies on sampling with replacement as shown in the image below</p>
<hr />
<p><img src="images/bootstrap.png" style="width:60.0%" /></p>
<hr />
<p>Bootstrap is a widely applicable and extremely powerful statistical tool that allow assigning measures of accuracy associated with a given estimator or statistical learning method.<br />
It is used by the random forest algorithm as described in chapter <a href="#MlAlgoTreesRandomForest">7.3.3</a></p>
</div>
<div id="bagging" class="section level4">
<h4><span class="header-section-number">7.3.2.2</span> Bagging</h4>
<p><a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">Bagging</a> is short for <strong>b</strong>ootstrap and <strong>agg</strong>regation and is a general purpose procedure for reducing the variance of a machine learning algorithm. It is particularly useful and frequently used in the context of decision trees.</p>
<p>For random forests the method works as follows:</p>

<div class="rmdtip">
<p>Bootstrapping for random forest:</p>
<ul>
<li>Generate training data by bootstrapping from the original training data set</li>
<li>Generate a tree</li>
<li>Repeat this M times</li>
<li>Predict by averaging the predictions of all trees</li>
</ul>
</div>

</div>
<div id="boosting" class="section level4">
<h4><span class="header-section-number">7.3.2.3</span> Boosting</h4>
<p><a href="https://en.wikipedia.org/wiki/Gradient_boosting">Boosting</a> can be utilized for regression and classification problems. It produces an ensemble of weak learners, typically decision trees. The models are build sequentially allowing optimization of an arbitrary differentiable loss function.
An example on how boosting works for tree is given in chapter <a href="#MlAlgoTreesGBM">7.3.4</a></p>
</div>
<div id="types-of-decision-trees" class="section level4">
<h4><span class="header-section-number">7.3.2.4</span> Types of decision trees</h4>
<p>Two dominant decision tree concepts are:</p>
<hr />
<p><img src="images/TreeAlogo.png" style="width:90.0%" /></p>
<hr />
<p>Two dominant concepts used for ensemble trees are described at:</p>
<ul>
<li>Random forest in chapter <a href="#MlAlgoTreesRandomForest">7.3.3</a></li>
<li>Gradient boosted trees in chapter <a href="#MlAlgoTreesGBM">7.3.4</a></li>
</ul>
</div>
</div>
<div id="MlAlgoTreesRandomForest" class="section level3">
<h3><span class="header-section-number">7.3.3</span> Random forest TBD</h3>
<p>Random forest has its name from the randomly selected predictors at each split. The Algorithm is described in <span class="citation">(Kuhn and Johnson <a href="#ref-kuhn2013applied" role="doc-biblioref">2013</a>)</span> p. 200:</p>

<div class="rmdtip">
<p>Random forest algorithm:</p>
<ul>
<li>Select number of models to build <em>m</em></li>
<li>for each model
<ul>
<li>generate bootstrap sample of the original data</li>
<li>train a tree model for this sample
<ul>
<li>at each split</li>
<li>select randomly <em>k</em> of the original predictors</li>
<li>select best predictor</li>
<li>partition the data</li>
</ul></li>
<li>until model stop criteria is meet</li>
</ul></li>
<li>average prediction of all trees for new samples<br />
</li>
</ul>
</div>

<p>The algorithm can be depicted as below</p>
<p><img src="images/randomForest.png" style="width:90.0%" /></p>
<p>Random forests have weaknesses and strengths</p>

<div class="rmdtip">
<p>Pros and cons of random forest:</p>
<ul>
<li>Pro
<ul>
<li>Handle higher dimensionality data very well</li>
<li>Handles missing values well</li>
</ul></li>
<li>Cons
<ul>
<li>Due to aggregation of all trees no precise values for regression</li>
</ul></li>
</ul>
</div>

<div id="python-example-for-random-forest" class="section level4">
<h4><span class="header-section-number">7.3.3.1</span> Python example for random forest</h4>
<p>The sample code for a random forest classifier produces a ROC image as shown below</p>
<p><img src="images/rocRfPython.png" style="width:60.0%" /></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> plot_roc_curve</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_wine</span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-7"><a href="#cb2-7"></a></span>
<span id="cb2-8"><a href="#cb2-8"></a>X, y <span class="op">=</span> load_wine(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-9"><a href="#cb2-9"></a>y <span class="op">=</span> y <span class="op">==</span> <span class="dv">2</span></span>
<span id="cb2-10"><a href="#cb2-10"></a></span>
<span id="cb2-11"><a href="#cb2-11"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-12"><a href="#cb2-12"></a></span>
<span id="cb2-13"><a href="#cb2-13"></a>rfc <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-14"><a href="#cb2-14"></a>rfc.fit(X_train, y_train)</span>
<span id="cb2-15"><a href="#cb2-15"></a>ax <span class="op">=</span> plt.gca()</span>
<span id="cb2-16"><a href="#cb2-16"></a>rfc_disp <span class="op">=</span> plot_roc_curve(rfc, X_test, y_test, ax<span class="op">=</span>ax, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb2-17"><a href="#cb2-17"></a>plt.show()</span></code></pre></div>
</div>
<div id="parameters-for-random-forest" class="section level4">
<h4><span class="header-section-number">7.3.3.2</span> Parameters for random forest</h4>
<p>The parameters are from the scikit-learn webpage <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier" class="uri">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier</a></p>
<dd class="field-odd">
<dl>
<dt>
<strong>n_estimators</strong><span class="classifier">integer, optional (default=100)</span>
</dt>
<dd>
<p>
The number of trees in the forest.
</p>
<div class="versionchanged">
<p>
<span class="versionmodified changed">Changed in version 0.22: </span>The default value of <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> changed from 10 to 100
in 0.22.
</p>
</div>
</dd>
<dt>
<strong>criterion</strong><span class="classifier">string, optional (default=”gini”)</span>
</dt>
<dd>
<p>
The function to measure the quality of a split. Supported criteria are
“gini” for the Gini impurity and “entropy” for the information gain.
Note: this parameter is tree-specific.
</p>
</dd>
<dt>
<strong>max_depth</strong><span class="classifier">integer or None, optional (default=None)</span>
</dt>
<dd>
<p>
The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.
</p>
</dd>
<dt>
<strong>min_samples_split</strong><span class="classifier">int, float, optional (default=2)</span>
</dt>
<dd>
<p>
The minimum number of samples required to split an internal node:
</p>
<ul class="simple">
<li>
<p>
If int, then consider <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> as the minimum number.
</p>
</li>
<li>
<p>
If float, then <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> is a fraction and
<code class="docutils literal notranslate"><span class="pre">ceil(min_samples_split</span> <span class="pre">*</span> <span class="pre">n_samples)</span></code> are the minimum
number of samples for each split.
</p>
</li>
</ul>
<div class="versionchanged">
<p>
<span class="versionmodified changed">Changed in version 0.18: </span>Added float values for fractions.
</p>
</div>
</dd>
<dt>
<strong>min_samples_leaf</strong><span class="classifier">int, float, optional (default=1)</span>
</dt>
<dd>
<p>
The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches. This may have the effect of smoothing the model,
especially in regression.
</p>
<ul class="simple">
<li>
<p>
If int, then consider <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> as the minimum number.
</p>
</li>
<li>
<p>
If float, then <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> is a fraction and
<code class="docutils literal notranslate"><span class="pre">ceil(min_samples_leaf</span> <span class="pre">*</span> <span class="pre">n_samples)</span></code> are the minimum
number of samples for each node.
</p>
</li>
</ul>
<div class="versionchanged">
<p>
<span class="versionmodified changed">Changed in version 0.18: </span>Added float values for fractions.
</p>
</div>
</dd>
<dt>
<strong>min_weight_fraction_leaf</strong><span class="classifier">float, optional (default=0.)</span>
</dt>
<dd>
<p>
The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.
</p>
</dd>
<dt>
<strong>max_features</strong><span class="classifier">int, float, string or None, optional (default=”auto”)</span>
</dt>
<dd>
<p>
The number of features to consider when looking for the best split:
</p>
<ul class="simple">
<li>
<p>
If int, then consider <code class="docutils literal notranslate"><span class="pre">max_features</span></code> features at each split.
</p>
</li>
<li>
<p>
If float, then <code class="docutils literal notranslate"><span class="pre">max_features</span></code> is a fraction and
<code class="docutils literal notranslate"><span class="pre">int(max_features</span> <span class="pre">*</span> <span class="pre">n_features)</span></code> features are considered at each
split.
</p>
</li>
<li>
<p>
If “auto”, then <code class="docutils literal notranslate"><span class="pre">max_features=sqrt(n_features)</span></code>.
</p>
</li>
<li>
<p>
If “sqrt”, then <code class="docutils literal notranslate"><span class="pre">max_features=sqrt(n_features)</span></code> (same as “auto”).
</p>
</li>
<li>
<p>
If “log2”, then <code class="docutils literal notranslate"><span class="pre">max_features=log2(n_features)</span></code>.
</p>
</li>
<li>
<p>
If None, then <code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code>.
</p>
</li>
</ul>
<p>
Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal notranslate"><span class="pre">max_features</span></code> features.
</p>
</dd>
<dt>
<strong>max_leaf_nodes</strong><span class="classifier">int or None, optional (default=None)</span>
</dt>
<dd>
<p>
Grow trees with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.
</p>
</dd>
<dt>
<strong>min_impurity_decrease</strong><span class="classifier">float, optional (default=0.)</span>
</dt>
<dd>
<p>
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.
</p>
<p>
The weighted impurity decrease equation is the following:
</p>
<div class="highlight-default notranslate" style="position: relative;">
<div class="highlight">
<pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre>
</div>
</div>
<p>
where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.
</p>
<p>
<code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.
</p>
<div class="versionadded">
<p>
<span class="versionmodified added">New in version 0.19.</span>
</p>
</div>
</dd>
<dt>
<strong>min_impurity_split</strong><span class="classifier">float, (default=1e-7)</span>
</dt>
<dd>
<p>
Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.
</p>
<div class="deprecated">
<p>
<span class="versionmodified deprecated">Deprecated since version 0.19: </span><code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> has been deprecated in favor of
<code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> in 0.19. The default value of
<code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> will change from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> instead.
</p>
</div>
</dd>
<dt>
<strong>bootstrap</strong><span class="classifier">boolean, optional (default=True)</span>
</dt>
<dd>
<p>
Whether bootstrap samples are used when building trees. If False, the
whole datset is used to build each tree.
</p>
</dd>
<dt>
<strong>oob_score</strong><span class="classifier">bool (default=False)</span>
</dt>
<dd>
<p>
Whether to use out-of-bag samples to estimate
the generalization accuracy.
</p>
</dd>
<dt>
<strong>n_jobs</strong><span class="classifier">int or None, optional (default=None)</span>
</dt>
<dd>
<p>
The number of jobs to run in parallel. <a class="reference internal" href="#sklearn.ensemble.RandomForestClassifier.fit" title="sklearn.ensemble.RandomForestClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit</span></code></a>, <a class="reference internal" href="#sklearn.ensemble.RandomForestClassifier.predict" title="sklearn.ensemble.RandomForestClassifier.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict</span></code></a>,
<a class="reference internal" href="#sklearn.ensemble.RandomForestClassifier.decision_path" title="sklearn.ensemble.RandomForestClassifier.decision_path"><code class="xref py py-meth docutils literal notranslate"><span class="pre">decision_path</span></code></a> and <a class="reference internal" href="#sklearn.ensemble.RandomForestClassifier.apply" title="sklearn.ensemble.RandomForestClassifier.apply"><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply</span></code></a> are all parallelized over the
trees. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend" title="(in joblib v0.14.1.dev0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code></a>
context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <a class="reference internal" href="../../glossary.html#term-n-jobs"><span class="xref std std-term">Glossary</span></a> for more details.
</p>
</dd>
<dt>
<strong>random_state</strong><span class="classifier">int, RandomState instance or None, optional (default=None)</span>
</dt>
<dd>
<p>
Controls both the randomness of the bootstrapping of the samples used
when building trees (if <code class="docutils literal notranslate"><span class="pre">bootstrap=True</span></code>) and the sampling of the
features to consider when looking for the best split at each node
(if <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">&lt;</span> <span class="pre">n_features</span></code>).
See <a class="reference internal" href="../../glossary.html#term-random-state"><span class="xref std std-term">Glossary</span></a> for details.
</p>
</dd>
<dt>
<strong>verbose</strong><span class="classifier">int, optional (default=0)</span>
</dt>
<dd>
<p>
Controls the verbosity when fitting and predicting.
</p>
</dd>
<dt>
<strong>warm_start</strong><span class="classifier">bool, optional (default=False)</span>
</dt>
<dd>
<p>
When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See <a class="reference internal" href="../../glossary.html#term-warm-start"><span class="xref std std-term">the Glossary</span></a>.
</p>
</dd>
<dt>
<strong>class_weight</strong><span class="classifier">dict, list of dicts, “balanced”, “balanced_subsample” or None, optional (default=None)</span>
</dt>
<dd>
<p>
Weights associated with classes in the form <code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>.
If not given, all classes are supposed to have weight one. For
multi-output problems, a list of dicts can be provided in the same
order as the columns of y.
</p>
<p>
Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].
</p>
<p>
The “balanced” mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>
</p>
<p>
The “balanced_subsample” mode is the same as “balanced” except that
weights are computed based on the bootstrap sample for every tree
grown.
</p>
<p>
For multi-output, the weights of each column of y will be multiplied.
</p>
<p>
Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.
</p>
</dd>
<dt>
<strong>ccp_alpha</strong><span class="classifier">non-negative float, optional (default=0.0)</span>
</dt>
<dd>
<p>
Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code> will be chosen. By default, no pruning is performed. See
<a class="reference internal" href="../tree.html#minimal-cost-complexity-pruning"><span class="std std-ref">Minimal Cost-Complexity Pruning</span></a> for details.
</p>
<div class="versionadded">
<p>
<span class="versionmodified added">New in version 0.22.</span>
</p>
</div>
</dd>
<dt>
<strong>max_samples</strong><span class="classifier">int or float, default=None</span>
</dt>
<dd>
<p>
If bootstrap is True, the number of samples to draw from X
to train each base estimator.
</p>
<ul class="simple">
<li>
<p>
If None (default), then draw <code class="docutils literal notranslate"><span class="pre">X.shape[0]</span></code> samples.
</p>
</li>
<li>
<p>
If int, then draw <code class="docutils literal notranslate"><span class="pre">max_samples</span></code> samples.
</p>
</li>
<li>
<p>
If float, then draw <code class="docutils literal notranslate"><span class="pre">max_samples</span> <span class="pre">*</span> <span class="pre">X.shape[0]</span></code> samples. Thus,
<code class="docutils literal notranslate"><span class="pre">max_samples</span></code> should be in the interval <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">1)</span></code>.
</p>
</li>
</ul>
<div class="versionadded">
<p>
<span class="versionmodified added">New in version 0.22.</span>
</p>
</div>
</dd>
</dl>
</dd>
</div>
</div>
<div id="MlAlgoTreesGBM" class="section level3">
<h3><span class="header-section-number">7.3.4</span> Boosted trees TBD</h3>
<p>Boosted trees are an ensemble of weak learners where each learner is build on the knowledge gained by all previous learners.</p>
<p>The following image depicts the algorithm which can be summarized:</p>

<div class="rmdtip">
<p>Boosted tree algorithm</p>
<ol style="list-style-type: decimal">
<li>Generate small tree</li>
<li>Calculate residuals for all samples</li>
<li>Use residuals to generate next tree</li>
<li>Combine all trees to build new model</li>
<li>Repeat from step 1.</li>
</ol>
</div>

<p>The algorithm is depicted below</p>
<hr />
<div class="figure">
<img src="images/gradientBoostedTreesSimple.png" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure based on <span class="citation">(Zhang et al. <a href="#ref-zhang2018exploring" role="doc-biblioref">2018</a>)</span>, added explanation at the right hand side</p>
</div>
<hr />
<p>Boosted trees have weaknesses and strengths</p>

<div class="rmdtip">
<p>Pros and cons of boosted trees:</p>
<ul>
<li>Pro
<ul>
<li>Supports different loss functions</li>
</ul></li>
<li>Cons
<ul>
<li>Prone to overfitting</li>
<li>Carefully tuning of hyperparameters is required</li>
</ul></li>
</ul>
</div>

<p>The algorithm of boosted trees for regression is described in a rather mathematically way in <span class="citation">(James et al. <a href="#ref-james2013introduction" role="doc-biblioref">2013</a>)</span> p. 323:</p>

<div class="rmdtip">
<ol style="list-style-type: decimal">
<li>Set <span class="math inline">\(\hat{f} = 0\)</span> and <span class="math inline">\(r_i = y_i\)</span> for all <span class="math inline">\(i\)</span> in the training set</li>
<li>For <span class="math inline">\(b=1,2,\dots,B\)</span> repeat:
<ol style="list-style-type: lower-alpha">
<li>Fit a tree <span class="math inline">\(\hat{f}^b\)</span> with <span class="math inline">\(d\)</span> splits (<span class="math inline">\(d+1\)</span> terminal nodes) to the training data <span class="math inline">\((X,r)\)</span></li>
<li>Update <span class="math inline">\(\hat{f}\)</span> by adding in a shrunken version of the new tree <span class="math inline">\(\hat{f}(x) \leftarrow \hat{f}(x) + \lambda \hat{f}^b(x)\)</span></li>
<li>Update the residuals <span class="math inline">\(r_i \leftarrow r_i + \lambda \hat{f}^b(x_i)\)</span></li>
</ol></li>
<li>Output the boosted model <span class="math inline">\(\hat{f}(x) = \sum_{b=1}^{B}\lambda \hat{f}^b(x)\)</span></li>
</ol>
</div>

<p>Another introduction to boosted trees is given at the <a href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html">XGBoost Documentation</a> with a thorough mathematical explanation of the approach.</p>
<div id="python-examples-for-boosted-trees" class="section level4">
<h4><span class="header-section-number">7.3.4.1</span> Python examples for boosted trees</h4>
<p>A popular library for boosted trees in Python is <strong>XGBoost</strong>, the documentation is hosted at <a href="https://xgboost.readthedocs.io/en/latest/" class="uri">https://xgboost.readthedocs.io/en/latest/</a>.<br />
Plenty of examples are on the GitHub page <a href="https://github.com/dmlc/xgboost/tree/master/demo/guide-python" class="uri">https://github.com/dmlc/xgboost/tree/master/demo/guide-python</a>.</p>
<p>The example script <strong>basic_walkthrough.py</strong> is shown below</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="co">#!/usr/bin/python</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="im">import</span> scipy.sparse</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="im">import</span> pickle</span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="co">### simple example</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="co"># load file from text file, also binary buffer generated by xgboost</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>dtrain <span class="op">=</span> xgb.DMatrix(<span class="st">&#39;../data/agaricus.txt.train&#39;</span>)</span>
<span id="cb3-10"><a href="#cb3-10"></a>dtest <span class="op">=</span> xgb.DMatrix(<span class="st">&#39;../data/agaricus.txt.test&#39;</span>)</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co"># specify parameters via map, definition are same as c++ version</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>param <span class="op">=</span> {<span class="st">&#39;max_depth&#39;</span>:<span class="dv">2</span>, <span class="st">&#39;eta&#39;</span>:<span class="dv">1</span>, <span class="st">&#39;silent&#39;</span>:<span class="dv">1</span>, <span class="st">&#39;objective&#39;</span>:<span class="st">&#39;binary:logistic&#39;</span>}</span>
<span id="cb3-14"><a href="#cb3-14"></a></span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="co"># specify validations set to watch performance</span></span>
<span id="cb3-16"><a href="#cb3-16"></a>watchlist <span class="op">=</span> [(dtest, <span class="st">&#39;eval&#39;</span>), (dtrain, <span class="st">&#39;train&#39;</span>)]</span>
<span id="cb3-17"><a href="#cb3-17"></a>num_round <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-18"><a href="#cb3-18"></a>bst <span class="op">=</span> xgb.train(param, dtrain, num_round, watchlist)</span>
<span id="cb3-19"><a href="#cb3-19"></a></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="co"># this is prediction</span></span>
<span id="cb3-21"><a href="#cb3-21"></a>preds <span class="op">=</span> bst.predict(dtest)</span>
<span id="cb3-22"><a href="#cb3-22"></a>labels <span class="op">=</span> dtest.get_label()</span>
<span id="cb3-23"><a href="#cb3-23"></a><span class="bu">print</span>(<span class="st">&#39;error=</span><span class="sc">%f</span><span class="st">&#39;</span> <span class="op">%</span> (<span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(preds)) <span class="cf">if</span> <span class="bu">int</span>(preds[i] <span class="op">&gt;</span> <span class="fl">0.5</span>) <span class="op">!=</span> labels[i]) <span class="op">/</span> <span class="bu">float</span>(<span class="bu">len</span>(preds))))</span>
<span id="cb3-24"><a href="#cb3-24"></a>bst.save_model(<span class="st">&#39;0001.model&#39;</span>)</span>
<span id="cb3-25"><a href="#cb3-25"></a><span class="co"># dump model</span></span>
<span id="cb3-26"><a href="#cb3-26"></a>bst.dump_model(<span class="st">&#39;dump.raw.txt&#39;</span>)</span>
<span id="cb3-27"><a href="#cb3-27"></a><span class="co"># dump model with feature map</span></span>
<span id="cb3-28"><a href="#cb3-28"></a>bst.dump_model(<span class="st">&#39;dump.nice.txt&#39;</span>, <span class="st">&#39;../data/featmap.txt&#39;</span>)</span>
<span id="cb3-29"><a href="#cb3-29"></a></span>
<span id="cb3-30"><a href="#cb3-30"></a><span class="co"># save dmatrix into binary buffer</span></span>
<span id="cb3-31"><a href="#cb3-31"></a>dtest.save_binary(<span class="st">&#39;dtest.buffer&#39;</span>)</span>
<span id="cb3-32"><a href="#cb3-32"></a><span class="co"># save model</span></span>
<span id="cb3-33"><a href="#cb3-33"></a>bst.save_model(<span class="st">&#39;xgb.model&#39;</span>)</span>
<span id="cb3-34"><a href="#cb3-34"></a><span class="co"># load model and data in</span></span>
<span id="cb3-35"><a href="#cb3-35"></a>bst2 <span class="op">=</span> xgb.Booster(model_file<span class="op">=</span><span class="st">&#39;xgb.model&#39;</span>)</span>
<span id="cb3-36"><a href="#cb3-36"></a>dtest2 <span class="op">=</span> xgb.DMatrix(<span class="st">&#39;dtest.buffer&#39;</span>)</span>
<span id="cb3-37"><a href="#cb3-37"></a>preds2 <span class="op">=</span> bst2.predict(dtest2)</span>
<span id="cb3-38"><a href="#cb3-38"></a><span class="co"># assert they are the same</span></span>
<span id="cb3-39"><a href="#cb3-39"></a><span class="cf">assert</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(preds2 <span class="op">-</span> preds)) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb3-40"><a href="#cb3-40"></a></span>
<span id="cb3-41"><a href="#cb3-41"></a><span class="co"># alternatively, you can pickle the booster</span></span>
<span id="cb3-42"><a href="#cb3-42"></a>pks <span class="op">=</span> pickle.dumps(bst2)</span>
<span id="cb3-43"><a href="#cb3-43"></a><span class="co"># load model and data in</span></span>
<span id="cb3-44"><a href="#cb3-44"></a>bst3 <span class="op">=</span> pickle.loads(pks)</span>
<span id="cb3-45"><a href="#cb3-45"></a>preds3 <span class="op">=</span> bst3.predict(dtest2)</span>
<span id="cb3-46"><a href="#cb3-46"></a><span class="co"># assert they are the same</span></span>
<span id="cb3-47"><a href="#cb3-47"></a><span class="cf">assert</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(preds3 <span class="op">-</span> preds)) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb3-48"><a href="#cb3-48"></a></span>
<span id="cb3-49"><a href="#cb3-49"></a><span class="co">###</span></span>
<span id="cb3-50"><a href="#cb3-50"></a><span class="co"># build dmatrix from scipy.sparse</span></span>
<span id="cb3-51"><a href="#cb3-51"></a><span class="bu">print</span>(<span class="st">&#39;start running example of build DMatrix from scipy.sparse CSR Matrix&#39;</span>)</span>
<span id="cb3-52"><a href="#cb3-52"></a>labels <span class="op">=</span> []</span>
<span id="cb3-53"><a href="#cb3-53"></a>row <span class="op">=</span> []<span class="op">;</span> col <span class="op">=</span> []<span class="op">;</span> dat <span class="op">=</span> []</span>
<span id="cb3-54"><a href="#cb3-54"></a>i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-55"><a href="#cb3-55"></a><span class="cf">for</span> l <span class="kw">in</span> <span class="bu">open</span>(<span class="st">&#39;../data/agaricus.txt.train&#39;</span>):</span>
<span id="cb3-56"><a href="#cb3-56"></a>    arr <span class="op">=</span> l.split()</span>
<span id="cb3-57"><a href="#cb3-57"></a>    labels.append(<span class="bu">int</span>(arr[<span class="dv">0</span>]))</span>
<span id="cb3-58"><a href="#cb3-58"></a>    <span class="cf">for</span> it <span class="kw">in</span> arr[<span class="dv">1</span>:]:</span>
<span id="cb3-59"><a href="#cb3-59"></a>        k,v <span class="op">=</span> it.split(<span class="st">&#39;:&#39;</span>)</span>
<span id="cb3-60"><a href="#cb3-60"></a>        row.append(i)<span class="op">;</span> col.append(<span class="bu">int</span>(k))<span class="op">;</span> dat.append(<span class="bu">float</span>(v))</span>
<span id="cb3-61"><a href="#cb3-61"></a>    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb3-62"><a href="#cb3-62"></a>csr <span class="op">=</span> scipy.sparse.csr_matrix((dat, (row, col)))</span>
<span id="cb3-63"><a href="#cb3-63"></a>dtrain <span class="op">=</span> xgb.DMatrix(csr, label<span class="op">=</span>labels)</span>
<span id="cb3-64"><a href="#cb3-64"></a>watchlist <span class="op">=</span> [(dtest, <span class="st">&#39;eval&#39;</span>), (dtrain, <span class="st">&#39;train&#39;</span>)]</span>
<span id="cb3-65"><a href="#cb3-65"></a>bst <span class="op">=</span> xgb.train(param, dtrain, num_round, watchlist)</span>
<span id="cb3-66"><a href="#cb3-66"></a></span>
<span id="cb3-67"><a href="#cb3-67"></a><span class="bu">print</span>(<span class="st">&#39;start running example of build DMatrix from scipy.sparse CSC Matrix&#39;</span>)</span>
<span id="cb3-68"><a href="#cb3-68"></a><span class="co"># we can also construct from csc matrix</span></span>
<span id="cb3-69"><a href="#cb3-69"></a>csc <span class="op">=</span> scipy.sparse.csc_matrix((dat, (row, col)))</span>
<span id="cb3-70"><a href="#cb3-70"></a>dtrain <span class="op">=</span> xgb.DMatrix(csc, label<span class="op">=</span>labels)</span>
<span id="cb3-71"><a href="#cb3-71"></a>watchlist <span class="op">=</span> [(dtest, <span class="st">&#39;eval&#39;</span>), (dtrain, <span class="st">&#39;train&#39;</span>)]</span>
<span id="cb3-72"><a href="#cb3-72"></a>bst <span class="op">=</span> xgb.train(param, dtrain, num_round, watchlist)</span>
<span id="cb3-73"><a href="#cb3-73"></a></span>
<span id="cb3-74"><a href="#cb3-74"></a><span class="bu">print</span>(<span class="st">&#39;start running example of build DMatrix from numpy array&#39;</span>)</span>
<span id="cb3-75"><a href="#cb3-75"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: npymat is numpy array, we will convert it into scipy.sparse.csr_matrix in internal implementation</span></span>
<span id="cb3-76"><a href="#cb3-76"></a><span class="co"># then convert to DMatrix</span></span>
<span id="cb3-77"><a href="#cb3-77"></a>npymat <span class="op">=</span> csr.todense()</span>
<span id="cb3-78"><a href="#cb3-78"></a>dtrain <span class="op">=</span> xgb.DMatrix(npymat, label<span class="op">=</span>labels)</span>
<span id="cb3-79"><a href="#cb3-79"></a>watchlist <span class="op">=</span> [(dtest, <span class="st">&#39;eval&#39;</span>), (dtrain, <span class="st">&#39;train&#39;</span>)]</span>
<span id="cb3-80"><a href="#cb3-80"></a>bst <span class="op">=</span> xgb.train(param, dtrain, num_round, watchlist)</span></code></pre></div>
<p>The parameters below are from their webpage <a href="https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters" class="uri">https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters</a></p>
<div id="learning-task-parameters" class="section">
<h2>
Learning Task Parameters<a class="headerlink" href="#learning-task-parameters" title="Permalink to this headline">¶</a>
</h2>
<p>
Specify the learning task and the corresponding learning objective. The objective options are below:
</p>
<ul class="simple">
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">objective</span></code> [default=reg:squarederror]
</p>
<ul>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">reg:squarederror</span></code>: regression with squared loss.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">reg:squaredlogerror</span></code>: regression with squared log loss <span class="math notranslate nohighlight"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-1-Frame" class="MathJax" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1" class="math" style="width: 17.593em; display: inline-block;"><span style="display: inline-block; position: relative; width: 14.163em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.587em, 1014.16em, 3.155em, -1000em); top: -2.621em; left: 0em;"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mfrac"><span style="display: inline-block; position: relative; width: 0.474em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.353em, 1000.28em, 4.133em, -1000em); top: -4.386em; left: 50%; margin-left: -0.177em;"><span id="MathJax-Span-4" class="mn" style="font-size: 70.7%; font-family: STIXGeneral;">1</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; clip: rect(3.353em, 1000.34em, 4.133em, -1000em); top: -3.599em; left: 50%; margin-left: -0.177em;"><span id="MathJax-Span-5" class="mn" style="font-size: 70.7%; font-family: STIXGeneral;">2</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; clip: rect(0.844em, 1000.47em, 1.21em, -1000em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.474em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.058em;"></span></span></span></span><span id="MathJax-Span-6" class="mo" style="font-family: STIXGeneral;">[</span><span id="MathJax-Span-7" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑙</span><span id="MathJax-Span-8" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑜</span><span id="MathJax-Span-9" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑔</span><span id="MathJax-Span-10" class="mo" style="font-family: STIXGeneral;">(</span><span id="MathJax-Span-11" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑝</span><span id="MathJax-Span-12" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑟</span><span id="MathJax-Span-13" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑒</span><span id="MathJax-Span-14" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑑</span><span id="MathJax-Span-15" class="mo" style="font-family: STIXGeneral; padding-left: 0.25em;">+</span><span id="MathJax-Span-16" class="mn" style="font-family: STIXGeneral; padding-left: 0.25em;">1</span><span id="MathJax-Span-17" class="mo" style="font-family: STIXGeneral;">)</span><span id="MathJax-Span-18" class="mo" style="font-family: STIXGeneral; padding-left: 0.25em;">−</span><span id="MathJax-Span-19" class="mi" style="font-family: STIXGeneral; font-style: italic; padding-left: 0.25em;">𝑙</span><span id="MathJax-Span-20" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑜</span><span id="MathJax-Span-21" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑔</span><span id="MathJax-Span-22" class="mo" style="font-family: STIXGeneral;">(</span><span id="MathJax-Span-23" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑙</span><span id="MathJax-Span-24" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑎</span><span id="MathJax-Span-25" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑏</span><span id="MathJax-Span-26" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑒</span><span id="MathJax-Span-27" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑙</span><span id="MathJax-Span-28" class="mo" style="font-family: STIXGeneral; padding-left: 0.25em;">+</span><span id="MathJax-Span-29" class="mn" style="font-family: STIXGeneral; padding-left: 0.25em;">1</span><span id="MathJax-Span-30" class="mo" style="font-family: STIXGeneral;">)</span><span class="msubsup" id="MathJax-Span-31"><span style="display: inline-block; position: relative; width: 0.762em; height: 0px;"><span style="position: absolute; clip: rect(3.169em, 1000.25em, 4.289em, -1000em); top: -3.982em; left: 0em;"><span class="mo" id="MathJax-Span-32" style="font-family: STIXGeneral;">]</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; top: -4.345em; left: 0.333em;"><span id="MathJax-Span-33" class="mn" style="font-size: 70.7%; font-family: STIXGeneral;">2</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.621em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.537em; border-left: 0px solid; width: 0px; height: 1.694em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">[</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>l</mi><mi>a</mi><mi>b</mi><mi>e</mi><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><msup><mo stretchy="false">]</mo><mn>2</mn></msup></math></span></span>
<script type="math/tex" id="MathJax-Element-1">\frac{1}{2}[log(pred + 1) - log(label + 1)]^2</script>
</span>. All input labels are required to be greater than -1. Also, see metric <code class="docutils literal notranslate"><span class="pre">rmsle</span></code> for possible issue with this objective.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">reg:logistic</span></code>: logistic regression
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">binary:logistic</span></code>: logistic regression for binary classification, output probability
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">binary:logitraw</span></code>: logistic regression for binary classification, output score before logistic transformation
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">binary:hinge</span></code>: hinge loss for binary classification. This makes predictions of 0 or 1, rather than producing probabilities.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">count:poisson</span></code> –poisson regression for count data, output mean of poisson distribution
</p>
<ul>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">max_delta_step</span></code> is set to 0.7 by default in poisson regression (used to safeguard optimization)
</p>
</li>
</ul>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">survival:cox</span></code>: Cox regression for right censored survival time data (negative values are considered right censored).
Note that predictions are returned on the hazard ratio scale (i.e., as HR = exp(marginal_prediction) in the proportional hazard function <code class="docutils literal notranslate"><span class="pre">h(t)</span> <span class="pre">=</span> <span class="pre">h0(t)</span> <span class="pre">*</span> <span class="pre">HR</span></code>).
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">multi:softmax</span></code>: set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes)
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">multi:softprob</span></code>: same as softmax, but output a vector of <code class="docutils literal notranslate"><span class="pre">ndata</span> <span class="pre"><em></span> <span class="pre">nclass</span></code>, which can be further reshaped to <code class="docutils literal notranslate"><span class="pre">ndata</span> <span class="pre"></em></span> <span class="pre">nclass</span></code> matrix. The result contains predicted probability of each data point belonging to each class.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">rank:pairwise</span></code>: Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">rank:ndcg</span></code>: Use LambdaMART to perform list-wise ranking where <a class="reference external" href="http://en.wikipedia.org/wiki/NDCG">Normalized Discounted Cumulative Gain (NDCG)</a> is maximized
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">rank:map</span></code>: Use LambdaMART to perform list-wise ranking where <a class="reference external" href="http://en.wikipedia.org/wiki/Mean_average_precision#Mean_average_precision">Mean Average Precision (MAP)</a> is maximized
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">reg:gamma</span></code>: gamma regression with log-link. Output is a mean of gamma distribution. It might be useful, e.g., for modeling insurance claims severity, or for any outcome that might be <a class="reference external" href="https://en.wikipedia.org/wiki/Gamma_distribution#Applications">gamma-distributed</a>.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">reg:tweedie</span></code>: Tweedie regression with log-link. It might be useful, e.g., for modeling total loss in insurance, or for any outcome that might be <a class="reference external" href="https://en.wikipedia.org/wiki/Tweedie_distribution#Applications">Tweedie-distributed</a>.
</p>
</li>
</ul>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">base_score</span></code> [default=0.5]
</p>
<ul>
<li>
<p>
The initial prediction score of all instances, global bias
</p>
</li>
<li>
<p>
For sufficient number of iterations, changing this value will not have too much effect.
</p>
</li>
</ul>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">eval_metric</span></code> [default according to objective]
</p>
<ul>
<li>
<p>
Evaluation metrics for validation data, a default metric will be assigned according to objective (rmse for regression, and error for classification, mean average precision for ranking)
</p>
</li>
<li>
<p>
User can add multiple evaluation metrics. Python users: remember to pass the metrics in as list of parameters pairs instead of map, so that latter <code class="docutils literal notranslate"><span class="pre">eval_metric</span></code> won’t override previous one
</p>
</li>
<li>
<p>
The choices are listed below:
</p>
<ul>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">rmse</span></code>: <a class="reference external" href="http://en.wikipedia.org/wiki/Root_mean_square_error">root mean square error</a>
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">rmsle</span></code>: root mean square log error: <span class="math notranslate nohighlight"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-2-Frame" class="MathJax" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msqrt&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mfrac&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/msqrt&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-34" class="math" style="width: 19.257em; display: inline-block;"><span style="display: inline-block; position: relative; width: 15.524em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.074em, 1015.52em, 3.223em, -1000em); top: -2.419em; left: 0em;"><span id="MathJax-Span-35" class="mrow"><span id="MathJax-Span-36" class="msqrt"><span style="display: inline-block; position: relative; width: 15.524em; height: 0px;"><span style="position: absolute; clip: rect(2.948em, 1014.44em, 4.499em, -1000em); top: -3.982em; left: 1.057em;"><span id="MathJax-Span-37" class="mrow"><span id="MathJax-Span-38" class="mfrac"><span style="display: inline-block; position: relative; width: 0.757em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.353em, 1000.28em, 4.133em, -1000em); top: -4.386em; left: 50%; margin-left: -0.177em;"><span id="MathJax-Span-39" class="mn" style="font-size: 70.7%; font-family: STIXGeneral;">1</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; clip: rect(3.369em, 1000.64em, 4.133em, -1000em); top: -3.616em; left: 50%; margin-left: -0.319em;"><span id="MathJax-Span-40" class="mi" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">𝑁<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.035em;"></span></span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; clip: rect(0.844em, 1000.76em, 1.21em, -1000em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.757em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.058em;"></span></span></span></span><span id="MathJax-Span-41" class="mo" style="font-family: STIXGeneral;">[</span><span id="MathJax-Span-42" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑙</span><span id="MathJax-Span-43" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑜</span><span id="MathJax-Span-44" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑔</span><span id="MathJax-Span-45" class="mo" style="font-family: STIXGeneral;">(</span><span id="MathJax-Span-46" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑝</span><span id="MathJax-Span-47" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑟</span><span id="MathJax-Span-48" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑒</span><span id="MathJax-Span-49" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑑</span><span id="MathJax-Span-50" class="mo" style="font-family: STIXGeneral; padding-left: 0.25em;">+</span><span id="MathJax-Span-51" class="mn" style="font-family: STIXGeneral; padding-left: 0.25em;">1</span><span id="MathJax-Span-52" class="mo" style="font-family: STIXGeneral;">)</span><span id="MathJax-Span-53" class="mo" style="font-family: STIXGeneral; padding-left: 0.25em;">−</span><span id="MathJax-Span-54" class="mi" style="font-family: STIXGeneral; font-style: italic; padding-left: 0.25em;">𝑙</span><span id="MathJax-Span-55" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑜</span><span id="MathJax-Span-56" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑔</span><span id="MathJax-Span-57" class="mo" style="font-family: STIXGeneral;">(</span><span id="MathJax-Span-58" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑙</span><span id="MathJax-Span-59" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑎</span><span id="MathJax-Span-60" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑏</span><span id="MathJax-Span-61" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑒</span><span id="MathJax-Span-62" class="mi" style="font-family: STIXGeneral; font-style: italic;">𝑙</span><span id="MathJax-Span-63" class="mo" style="font-family: STIXGeneral; padding-left: 0.25em;">+</span><span id="MathJax-Span-64" class="mn" style="font-family: STIXGeneral; padding-left: 0.25em;">1</span><span id="MathJax-Span-65" class="mo" style="font-family: STIXGeneral;">)</span><span class="msubsup" id="MathJax-Span-66"><span style="display: inline-block; position: relative; width: 0.762em; height: 0px;"><span style="position: absolute; clip: rect(3.169em, 1000.25em, 4.289em, -1000em); top: -3.982em; left: 0em;"><span class="mo" id="MathJax-Span-67" style="font-family: STIXGeneral;">]</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; top: -4.271em; left: 0.333em;"><span id="MathJax-Span-68" class="mn" style="font-size: 70.7%; font-family: STIXGeneral;">2</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; clip: rect(3.011em, 1014.47em, 3.363em, -1000em); top: -4.356em; left: 1.057em;"><span style="display: inline-block; position: relative; width: 14.467em; height: 0px;"><span style="position: absolute; font-family: STIXGeneral; top: -3.982em; left: 0em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; font-family: STIXGeneral; top: -3.982em; left: 13.967em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 0.426em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 0.878em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 1.329em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 1.78em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 2.232em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 2.683em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 3.134em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 3.586em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 4.037em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 4.488em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 4.94em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 5.391em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 5.842em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 6.294em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 6.745em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 7.197em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 7.648em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 8.099em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 8.551em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 9.002em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 9.453em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 9.905em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 10.356em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 10.807em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 11.259em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 11.71em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 12.161em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 12.613em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 13.064em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="font-family: STIXGeneral; position: absolute; top: -3.982em; left: 13.515em;">‾<span style="display: inline-block; width: 0px; height: 3.982em;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span><span style="position: absolute; clip: rect(2.279em, 1001.09em, 4.428em, -1000em); top: -3.624em; left: 0em;"><span style="font-family: STIXSizeOneSym;">√</span><span style="display: inline-block; width: 0px; height: 3.982em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.419em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.872em; border-left: 0px solid; width: 0px; height: 2.415em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msqrt><mfrac><mn>1</mn><mi>N</mi></mfrac><mo stretchy="false">[</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>l</mi><mi>a</mi><mi>b</mi><mi>e</mi><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><msup><mo stretchy="false">]</mo><mn>2</mn></msup></msqrt></math></span></span>
<script type="math/tex" id="MathJax-Element-2">\sqrt{\frac{1}{N}[log(pred + 1) - log(label + 1)]^2}</script>
</span>. Default metric of <code class="docutils literal notranslate"><span class="pre">reg:squaredlogerror</span></code> objective. This metric reduces errors generated by outliers in dataset. But because <code class="docutils literal notranslate"><span class="pre">log</span></code> function is employed, <code class="docutils literal notranslate"><span class="pre">rmsle</span></code> might output <code class="docutils literal notranslate"><span class="pre">nan</span></code> when prediction value is less than -1. See <code class="docutils literal notranslate"><span class="pre">reg:squaredlogerror</span></code> for other requirements.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">mae</span></code>: <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_absolute_error">mean absolute error</a>
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">logloss</span></code>: <a class="reference external" href="http://en.wikipedia.org/wiki/Log-likelihood">negative log-likelihood</a>
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">error</span></code>: Binary classification error rate. It is calculated as <code class="docutils literal notranslate"><span class="pre">#(wrong</span> <span class="pre">cases)/#(all</span> <span class="pre">cases)</span></code>. For the predictions, the evaluation will regard the instances with prediction value larger than 0.5 as positive instances, and the others as negative instances.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre"><a href="mailto:error@t" class="email">error@t</a></span></code>: a different than 0.5 binary classification threshold value could be specified by providing a numerical value through ‘t’.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">merror</span></code>: Multiclass classification error rate. It is calculated as <code class="docutils literal notranslate"><span class="pre">#(wrong</span> <span class="pre">cases)/#(all</span> <span class="pre">cases)</span></code>.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">mlogloss</span></code>: <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html">Multiclass logloss</a>.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">auc</span></code>: <a class="reference external" href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_curve">Area under the curve</a>
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">aucpr</span></code>: <a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall">Area under the PR curve</a>
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">ndcg</span></code>: <a class="reference external" href="http://en.wikipedia.org/wiki/NDCG">Normalized Discounted Cumulative Gain</a>
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">map</span></code>: <a class="reference external" href="http://en.wikipedia.org/wiki/Mean_average_precision#Mean_average_precision">Mean Average Precision</a>
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre"><a href="mailto:ndcg@n" class="email">ndcg@n</a></span></code>, <code class="docutils literal notranslate"><span class="pre"><a href="mailto:map@n" class="email">map@n</a></span></code>: ‘n’ can be assigned as an integer to cut off the top positions in the lists for evaluation.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">ndcg-</span></code>, <code class="docutils literal notranslate"><span class="pre">map-</span></code>, <code class="docutils literal notranslate"><span class="pre"><a href="mailto:ndcg@n-" class="email">ndcg@n-</a></span></code>, <code class="docutils literal notranslate"><span class="pre"><a href="mailto:map@n-" class="email">map@n-</a></span></code>: In XGBoost, NDCG and MAP will evaluate the score of a list without any positive samples as 1. By adding “-” in the evaluation metric XGBoost will evaluate these score as 0 to be consistent under some conditions.
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">poisson-nloglik</span></code>: negative log-likelihood for Poisson regression
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">gamma-nloglik</span></code>: negative log-likelihood for gamma regression
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">cox-nloglik</span></code>: negative partial log-likelihood for Cox proportional hazards regression
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">gamma-deviance</span></code>: residual deviance for gamma regression
</p>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">tweedie-nloglik</span></code>: negative log-likelihood for Tweedie regression (at a specified value of the <code class="docutils literal notranslate"><span class="pre">tweedie_variance_power</span></code> parameter)
</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>
<code class="docutils literal notranslate"><span class="pre">seed</span></code> [default=0]
</p>
<ul>
<li>
<p>
Random number seed. This parameter is ignored in R package, use <cite>set.seed()</cite> instead.
</p>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="MlAlgoSvm" class="section level2">
<h2><span class="header-section-number">7.4</span> Support Vector Machine (SVM) TBD</h2>
<p><span class="math display">\[maximize \(M\) \(\beta_{0}, \beta_{1}, \ldots, \beta_{p}\)
subject to \(\sum_{j=1}^{p} \beta_{j}^{2}=1\)
\(y_{i}\left(\beta_{0}+\beta_{1} x_{i 1}+\ldots+\beta_{p} x_{i p}\right) \geq M\)
for all \(i=1, \dots, N\)\]</span></p>
<p>### Python example for SVM</p>
<p>Two examples are given, both take images and classify them.</p>
<p>#### SVM face recognition</p>
<p>The following example is given at <a href="https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py">scikit-learn.org</a></p>
<p>It uses a SVM with</p>
<ul>
<li>rbf kernel</li>
<li>grid search for hyper parameter
<ul>
<li>C</li>
<li>gamma</li>
<li>using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">scikit-learn GridSearchCV</a></li>
</ul></li>
<li>PCA to create input features
<ul>
<li>150 dimensions</li>
</ul></li>
</ul>
<p>See below some examples of the resulting classification of the algorithm</p>
<p><img src="images/svmFaces.png" style="width:60.0%" /></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1"></a>Total dataset size:</span>
<span id="cb4-2"><a href="#cb4-2"></a>n_samples: 1288</span>
<span id="cb4-3"><a href="#cb4-3"></a>n_features: 1850</span>
<span id="cb4-4"><a href="#cb4-4"></a>n_classes: 7</span>
<span id="cb4-5"><a href="#cb4-5"></a>Extracting the top 150 eigenfaces from 966 faces</span>
<span id="cb4-6"><a href="#cb4-6"></a>done in 0.320s</span>
<span id="cb4-7"><a href="#cb4-7"></a>Projecting the input data on the eigenfaces orthonormal basis</span>
<span id="cb4-8"><a href="#cb4-8"></a>done in 0.013s</span>
<span id="cb4-9"><a href="#cb4-9"></a>Fitting the classifier to the training set</span>
<span id="cb4-10"><a href="#cb4-10"></a>done in 28.379s</span>
<span id="cb4-11"><a href="#cb4-11"></a>Best estimator found by grid search:</span>
<span id="cb4-12"><a href="#cb4-12"></a>SVC(C=1000.0, break_ties=False, cache_size=200, class_weight=&#39;balanced&#39;,</span>
<span id="cb4-13"><a href="#cb4-13"></a><span class="bn">    coef0=0.0, decision_function_shape=&#39;ovr&#39;, degree=3, gamma=0.005,</span></span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="bn">    kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None,</span></span>
<span id="cb4-15"><a href="#cb4-15"></a><span class="bn">    shrinking=True, tol=0.001, verbose=False)</span></span>
<span id="cb4-16"><a href="#cb4-16"></a>Predicting people&#39;s names on the test set</span>
<span id="cb4-17"><a href="#cb4-17"></a>done in 0.045s</span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="bn">                   precision    recall  f1-score   support</span></span>
<span id="cb4-19"><a href="#cb4-19"></a></span>
<span id="cb4-20"><a href="#cb4-20"></a><span class="bn">     Ariel Sharon       0.88      0.54      0.67        13</span></span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="bn">     Colin Powell       0.80      0.87      0.83        60</span></span>
<span id="cb4-22"><a href="#cb4-22"></a>  Donald Rumsfeld       0.94      0.63      0.76        27</span>
<span id="cb4-23"><a href="#cb4-23"></a><span class="bn">    George W Bush       0.83      0.98      0.90       146</span></span>
<span id="cb4-24"><a href="#cb4-24"></a>Gerhard Schroeder       0.91      0.80      0.85        25</span>
<span id="cb4-25"><a href="#cb4-25"></a><span class="bn">      Hugo Chavez       1.00      0.53      0.70        15</span></span>
<span id="cb4-26"><a href="#cb4-26"></a><span class="bn">       Tony Blair       0.96      0.75      0.84        36</span></span>
<span id="cb4-27"><a href="#cb4-27"></a></span>
<span id="cb4-28"><a href="#cb4-28"></a><span class="bn">         accuracy                           0.85       322</span></span>
<span id="cb4-29"><a href="#cb4-29"></a><span class="bn">        macro avg       0.90      0.73      0.79       322</span></span>
<span id="cb4-30"><a href="#cb4-30"></a><span class="bn">     weighted avg       0.86      0.85      0.84       322</span></span>
<span id="cb4-31"><a href="#cb4-31"></a></span>
<span id="cb4-32"><a href="#cb4-32"></a></span>
<span id="cb4-33"><a href="#cb4-33"></a>Confusion matrix</span>
<span id="cb4-34"><a href="#cb4-34"></a></span>
<span id="cb4-35"><a href="#cb4-35"></a>[[  7   1   0   5   0   0   0]</span>
<span id="cb4-36"><a href="#cb4-36"></a> [  1  52   0   7   0   0   0]</span>
<span id="cb4-37"><a href="#cb4-37"></a> [  0   3  17   7   0   0   0]</span>
<span id="cb4-38"><a href="#cb4-38"></a> [  0   3   0 143   0   0   0]</span>
<span id="cb4-39"><a href="#cb4-39"></a> [  0   1   0   3  20   0   1]</span>
<span id="cb4-40"><a href="#cb4-40"></a> [  0   4   0   2   1   8   0]</span>
<span id="cb4-41"><a href="#cb4-41"></a> [  0   1   1   6   1   0  27]]</span></code></pre></div>
<p>The python code is given below</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="im">import</span> logging</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb5-7"><a href="#cb5-7"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_lfw_people</span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb5-9"><a href="#cb5-9"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb5-10"><a href="#cb5-10"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb5-11"><a href="#cb5-11"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb5-12"><a href="#cb5-12"></a></span>
<span id="cb5-13"><a href="#cb5-13"></a></span>
<span id="cb5-14"><a href="#cb5-14"></a><span class="bu">print</span>(__doc__)</span>
<span id="cb5-15"><a href="#cb5-15"></a></span>
<span id="cb5-16"><a href="#cb5-16"></a><span class="co"># Display progress logs on stdout</span></span>
<span id="cb5-17"><a href="#cb5-17"></a>logging.basicConfig(level<span class="op">=</span>logging.INFO, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;</span><span class="sc">%(asctime)s</span><span class="st"> </span><span class="sc">%(message)s</span><span class="st">&#39;</span>)</span>
<span id="cb5-18"><a href="#cb5-18"></a></span>
<span id="cb5-19"><a href="#cb5-19"></a></span>
<span id="cb5-20"><a href="#cb5-20"></a><span class="co"># #############################################################################</span></span>
<span id="cb5-21"><a href="#cb5-21"></a><span class="co"># Download the data, if not already on disk and load it as numpy arrays</span></span>
<span id="cb5-22"><a href="#cb5-22"></a></span>
<span id="cb5-23"><a href="#cb5-23"></a>lfw_people <span class="op">=</span> fetch_lfw_people(min_faces_per_person<span class="op">=</span><span class="dv">70</span>, resize<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb5-24"><a href="#cb5-24"></a></span>
<span id="cb5-25"><a href="#cb5-25"></a><span class="co"># introspect the images arrays to find the shapes (for plotting)</span></span>
<span id="cb5-26"><a href="#cb5-26"></a>n_samples, h, w <span class="op">=</span> lfw_people.images.shape</span>
<span id="cb5-27"><a href="#cb5-27"></a></span>
<span id="cb5-28"><a href="#cb5-28"></a><span class="co"># for machine learning we use the 2 data directly (as relative pixel</span></span>
<span id="cb5-29"><a href="#cb5-29"></a><span class="co"># positions info is ignored by this model)</span></span>
<span id="cb5-30"><a href="#cb5-30"></a>X <span class="op">=</span> lfw_people.data</span>
<span id="cb5-31"><a href="#cb5-31"></a>n_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb5-32"><a href="#cb5-32"></a></span>
<span id="cb5-33"><a href="#cb5-33"></a><span class="co"># the label to predict is the id of the person</span></span>
<span id="cb5-34"><a href="#cb5-34"></a>y <span class="op">=</span> lfw_people.target</span>
<span id="cb5-35"><a href="#cb5-35"></a>target_names <span class="op">=</span> lfw_people.target_names</span>
<span id="cb5-36"><a href="#cb5-36"></a>n_classes <span class="op">=</span> target_names.shape[<span class="dv">0</span>]</span>
<span id="cb5-37"><a href="#cb5-37"></a></span>
<span id="cb5-38"><a href="#cb5-38"></a><span class="bu">print</span>(<span class="st">&quot;Total dataset size:&quot;</span>)</span>
<span id="cb5-39"><a href="#cb5-39"></a><span class="bu">print</span>(<span class="st">&quot;n_samples: </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> n_samples)</span>
<span id="cb5-40"><a href="#cb5-40"></a><span class="bu">print</span>(<span class="st">&quot;n_features: </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> n_features)</span>
<span id="cb5-41"><a href="#cb5-41"></a><span class="bu">print</span>(<span class="st">&quot;n_classes: </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> n_classes)</span>
<span id="cb5-42"><a href="#cb5-42"></a></span>
<span id="cb5-43"><a href="#cb5-43"></a></span>
<span id="cb5-44"><a href="#cb5-44"></a><span class="co"># #############################################################################</span></span>
<span id="cb5-45"><a href="#cb5-45"></a><span class="co"># Split into a training set and a test set using a stratified k fold</span></span>
<span id="cb5-46"><a href="#cb5-46"></a></span>
<span id="cb5-47"><a href="#cb5-47"></a><span class="co"># split into a training and testing set</span></span>
<span id="cb5-48"><a href="#cb5-48"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb5-49"><a href="#cb5-49"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-50"><a href="#cb5-50"></a></span>
<span id="cb5-51"><a href="#cb5-51"></a></span>
<span id="cb5-52"><a href="#cb5-52"></a><span class="co"># #############################################################################</span></span>
<span id="cb5-53"><a href="#cb5-53"></a><span class="co"># Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled</span></span>
<span id="cb5-54"><a href="#cb5-54"></a><span class="co"># dataset): unsupervised feature extraction / dimensionality reduction</span></span>
<span id="cb5-55"><a href="#cb5-55"></a>n_components <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb5-56"><a href="#cb5-56"></a></span>
<span id="cb5-57"><a href="#cb5-57"></a><span class="bu">print</span>(<span class="st">&quot;Extracting the top </span><span class="sc">%d</span><span class="st"> eigenfaces from </span><span class="sc">%d</span><span class="st"> faces&quot;</span></span>
<span id="cb5-58"><a href="#cb5-58"></a>      <span class="op">%</span> (n_components, X_train.shape[<span class="dv">0</span>]))</span>
<span id="cb5-59"><a href="#cb5-59"></a>t0 <span class="op">=</span> time()</span>
<span id="cb5-60"><a href="#cb5-60"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span>n_components, svd_solver<span class="op">=</span><span class="st">&#39;randomized&#39;</span>,</span>
<span id="cb5-61"><a href="#cb5-61"></a>          whiten<span class="op">=</span><span class="va">True</span>).fit(X_train)</span>
<span id="cb5-62"><a href="#cb5-62"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb5-63"><a href="#cb5-63"></a></span>
<span id="cb5-64"><a href="#cb5-64"></a>eigenfaces <span class="op">=</span> pca.components_.reshape((n_components, h, w))</span>
<span id="cb5-65"><a href="#cb5-65"></a></span>
<span id="cb5-66"><a href="#cb5-66"></a><span class="bu">print</span>(<span class="st">&quot;Projecting the input data on the eigenfaces orthonormal basis&quot;</span>)</span>
<span id="cb5-67"><a href="#cb5-67"></a>t0 <span class="op">=</span> time()</span>
<span id="cb5-68"><a href="#cb5-68"></a>X_train_pca <span class="op">=</span> pca.transform(X_train)</span>
<span id="cb5-69"><a href="#cb5-69"></a>X_test_pca <span class="op">=</span> pca.transform(X_test)</span>
<span id="cb5-70"><a href="#cb5-70"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb5-71"><a href="#cb5-71"></a></span>
<span id="cb5-72"><a href="#cb5-72"></a></span>
<span id="cb5-73"><a href="#cb5-73"></a><span class="co"># #############################################################################</span></span>
<span id="cb5-74"><a href="#cb5-74"></a><span class="co"># Train a SVM classification model</span></span>
<span id="cb5-75"><a href="#cb5-75"></a></span>
<span id="cb5-76"><a href="#cb5-76"></a><span class="bu">print</span>(<span class="st">&quot;Fitting the classifier to the training set&quot;</span>)</span>
<span id="cb5-77"><a href="#cb5-77"></a>t0 <span class="op">=</span> time()</span>
<span id="cb5-78"><a href="#cb5-78"></a>param_grid <span class="op">=</span> {<span class="st">&#39;C&#39;</span>: [<span class="fl">1e3</span>, <span class="fl">5e3</span>, <span class="fl">1e4</span>, <span class="fl">5e4</span>, <span class="fl">1e5</span>],</span>
<span id="cb5-79"><a href="#cb5-79"></a>              <span class="st">&#39;gamma&#39;</span>: [<span class="fl">0.0001</span>, <span class="fl">0.0005</span>, <span class="fl">0.001</span>, <span class="fl">0.005</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>], }</span>
<span id="cb5-80"><a href="#cb5-80"></a>clf <span class="op">=</span> GridSearchCV(</span>
<span id="cb5-81"><a href="#cb5-81"></a>    SVC(kernel<span class="op">=</span><span class="st">&#39;rbf&#39;</span>, class_weight<span class="op">=</span><span class="st">&#39;balanced&#39;</span>), param_grid</span>
<span id="cb5-82"><a href="#cb5-82"></a>)</span>
<span id="cb5-83"><a href="#cb5-83"></a>clf <span class="op">=</span> clf.fit(X_train_pca, y_train)</span>
<span id="cb5-84"><a href="#cb5-84"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb5-85"><a href="#cb5-85"></a><span class="bu">print</span>(<span class="st">&quot;Best estimator found by grid search:&quot;</span>)</span>
<span id="cb5-86"><a href="#cb5-86"></a><span class="bu">print</span>(clf.best_estimator_)</span>
<span id="cb5-87"><a href="#cb5-87"></a></span>
<span id="cb5-88"><a href="#cb5-88"></a></span>
<span id="cb5-89"><a href="#cb5-89"></a><span class="co"># #############################################################################</span></span>
<span id="cb5-90"><a href="#cb5-90"></a><span class="co"># Quantitative evaluation of the model quality on the test set</span></span>
<span id="cb5-91"><a href="#cb5-91"></a></span>
<span id="cb5-92"><a href="#cb5-92"></a><span class="bu">print</span>(<span class="st">&quot;Predicting people&#39;s names on the test set&quot;</span>)</span>
<span id="cb5-93"><a href="#cb5-93"></a>t0 <span class="op">=</span> time()</span>
<span id="cb5-94"><a href="#cb5-94"></a>y_pred <span class="op">=</span> clf.predict(X_test_pca)</span>
<span id="cb5-95"><a href="#cb5-95"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb5-96"><a href="#cb5-96"></a></span>
<span id="cb5-97"><a href="#cb5-97"></a><span class="bu">print</span>(classification_report(y_test, y_pred, target_names<span class="op">=</span>target_names))</span>
<span id="cb5-98"><a href="#cb5-98"></a><span class="bu">print</span>(confusion_matrix(y_test, y_pred, labels<span class="op">=</span><span class="bu">range</span>(n_classes)))</span>
<span id="cb5-99"><a href="#cb5-99"></a></span>
<span id="cb5-100"><a href="#cb5-100"></a></span>
<span id="cb5-101"><a href="#cb5-101"></a><span class="co"># #############################################################################</span></span>
<span id="cb5-102"><a href="#cb5-102"></a><span class="co"># Qualitative evaluation of the predictions using matplotlib</span></span>
<span id="cb5-103"><a href="#cb5-103"></a></span>
<span id="cb5-104"><a href="#cb5-104"></a><span class="kw">def</span> plot_gallery(images, titles, h, w, n_row<span class="op">=</span><span class="dv">3</span>, n_col<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb5-105"><a href="#cb5-105"></a>    <span class="co">&quot;&quot;&quot;Helper function to plot a gallery of portraits&quot;&quot;&quot;</span></span>
<span id="cb5-106"><a href="#cb5-106"></a>    plt.figure(figsize<span class="op">=</span>(<span class="fl">1.8</span> <span class="op">*</span> n_col, <span class="fl">2.4</span> <span class="op">*</span> n_row))</span>
<span id="cb5-107"><a href="#cb5-107"></a>    plt.subplots_adjust(bottom<span class="op">=</span><span class="dv">0</span>, left<span class="op">=</span>.<span class="dv">01</span>, right<span class="op">=</span>.<span class="dv">99</span>, top<span class="op">=</span>.<span class="dv">90</span>, hspace<span class="op">=</span>.<span class="dv">35</span>)</span>
<span id="cb5-108"><a href="#cb5-108"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_row <span class="op">*</span> n_col):</span>
<span id="cb5-109"><a href="#cb5-109"></a>        plt.subplot(n_row, n_col, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb5-110"><a href="#cb5-110"></a>        plt.imshow(images[i].reshape((h, w)), cmap<span class="op">=</span>plt.cm.gray)</span>
<span id="cb5-111"><a href="#cb5-111"></a>        plt.title(titles[i], size<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb5-112"><a href="#cb5-112"></a>        plt.xticks(())</span>
<span id="cb5-113"><a href="#cb5-113"></a>        plt.yticks(())</span>
<span id="cb5-114"><a href="#cb5-114"></a></span>
<span id="cb5-115"><a href="#cb5-115"></a></span>
<span id="cb5-116"><a href="#cb5-116"></a><span class="co"># plot the result of the prediction on a portion of the test set</span></span>
<span id="cb5-117"><a href="#cb5-117"></a></span>
<span id="cb5-118"><a href="#cb5-118"></a><span class="kw">def</span> title(y_pred, y_test, target_names, i):</span>
<span id="cb5-119"><a href="#cb5-119"></a>    pred_name <span class="op">=</span> target_names[y_pred[i]].rsplit(<span class="st">&#39; &#39;</span>, <span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-120"><a href="#cb5-120"></a>    true_name <span class="op">=</span> target_names[y_test[i]].rsplit(<span class="st">&#39; &#39;</span>, <span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-121"><a href="#cb5-121"></a>    <span class="cf">return</span> <span class="st">&#39;predicted: </span><span class="sc">%s</span><span class="ch">\n</span><span class="st">true:      </span><span class="sc">%s</span><span class="st">&#39;</span> <span class="op">%</span> (pred_name, true_name)</span>
<span id="cb5-122"><a href="#cb5-122"></a></span>
<span id="cb5-123"><a href="#cb5-123"></a>prediction_titles <span class="op">=</span> [title(y_pred, y_test, target_names, i)</span>
<span id="cb5-124"><a href="#cb5-124"></a>                     <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_pred.shape[<span class="dv">0</span>])]</span>
<span id="cb5-125"><a href="#cb5-125"></a></span>
<span id="cb5-126"><a href="#cb5-126"></a>plot_gallery(X_test, prediction_titles, h, w)</span>
<span id="cb5-127"><a href="#cb5-127"></a></span>
<span id="cb5-128"><a href="#cb5-128"></a><span class="co"># plot the gallery of the most significative eigenfaces</span></span>
<span id="cb5-129"><a href="#cb5-129"></a></span>
<span id="cb5-130"><a href="#cb5-130"></a>eigenface_titles <span class="op">=</span> [<span class="st">&quot;eigenface </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(eigenfaces.shape[<span class="dv">0</span>])]</span>
<span id="cb5-131"><a href="#cb5-131"></a>plot_gallery(eigenfaces, eigenface_titles, h, w)</span>
<span id="cb5-132"><a href="#cb5-132"></a></span>
<span id="cb5-133"><a href="#cb5-133"></a>plt.show()</span></code></pre></div>
<hr />
<div class="figure">
<img src="images/2880px-Kernel_Machine.svg.png" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from Alisneaky, svg version by User:Zirguezi [CC BY-SA (<a href="https://creativecommons.org/licenses/by-sa/4.0" class="uri">https://creativecommons.org/licenses/by-sa/4.0</a>)]</p>
</div>
<div id="svm-image-recognition" class="section level4">
<h4><span class="header-section-number">7.4.0.1</span> SVM Image recognition</h4>
<p>From the scikit-learn help page an example showing how the scikit-learn can be used to recognize images of hand-written digits.</p>
<p>The input data are hand written numbers</p>
<ul>
<li><p>Top: training data</p></li>
<li><p>Bottom: Prediction</p>
<p><img src="images/minstExample.png" style="width:60.0%" /></p>
<p>The confusion matrix is given below and shows for example that a true “3” is often mistaken as a “8” (see red circle)</p></li>
</ul>
<p><img src="images/ConfMatrixMinst.png" style="width:80.0%" /></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="bu">print</span>(__doc__)</span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="co"># Author: Gael Varoquaux &lt;gael dot varoquaux at normalesup dot org&gt;</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="co"># License: BSD 3 clause</span></span>
<span id="cb6-5"><a href="#cb6-5"></a></span>
<span id="cb6-6"><a href="#cb6-6"></a><span class="co"># Standard scientific Python imports</span></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-8"><a href="#cb6-8"></a></span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="co"># Import datasets, classifiers and performance metrics</span></span>
<span id="cb6-10"><a href="#cb6-10"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets, svm, metrics</span>
<span id="cb6-11"><a href="#cb6-11"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-12"><a href="#cb6-12"></a></span>
<span id="cb6-13"><a href="#cb6-13"></a><span class="co"># The digits dataset</span></span>
<span id="cb6-14"><a href="#cb6-14"></a>digits <span class="op">=</span> datasets.load_digits()</span>
<span id="cb6-15"><a href="#cb6-15"></a></span>
<span id="cb6-16"><a href="#cb6-16"></a><span class="co"># The data that we are interested in is made of 8x8 images of digits, let&#39;s</span></span>
<span id="cb6-17"><a href="#cb6-17"></a><span class="co"># have a look at the first 4 images, stored in the `images` attribute of the</span></span>
<span id="cb6-18"><a href="#cb6-18"></a><span class="co"># dataset.  If we were working from image files, we could load them using</span></span>
<span id="cb6-19"><a href="#cb6-19"></a><span class="co"># matplotlib.pyplot.imread.  Note that each image must have the same size. For these</span></span>
<span id="cb6-20"><a href="#cb6-20"></a><span class="co"># images, we know which digit they represent: it is given in the &#39;target&#39; of</span></span>
<span id="cb6-21"><a href="#cb6-21"></a><span class="co"># the dataset.</span></span>
<span id="cb6-22"><a href="#cb6-22"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb6-23"><a href="#cb6-23"></a>images_and_labels <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(digits.images, digits.target))</span>
<span id="cb6-24"><a href="#cb6-24"></a><span class="cf">for</span> ax, (image, label) <span class="kw">in</span> <span class="bu">zip</span>(axes[<span class="dv">0</span>, :], images_and_labels[:<span class="dv">4</span>]):</span>
<span id="cb6-25"><a href="#cb6-25"></a>    ax.set_axis_off()</span>
<span id="cb6-26"><a href="#cb6-26"></a>    ax.imshow(image, cmap<span class="op">=</span>plt.cm.gray_r, interpolation<span class="op">=</span><span class="st">&#39;nearest&#39;</span>)</span>
<span id="cb6-27"><a href="#cb6-27"></a>    ax.set_title(<span class="st">&#39;Training: </span><span class="sc">%i</span><span class="st">&#39;</span> <span class="op">%</span> label)</span>
<span id="cb6-28"><a href="#cb6-28"></a></span>
<span id="cb6-29"><a href="#cb6-29"></a><span class="co"># To apply a classifier on this data, we need to flatten the image, to</span></span>
<span id="cb6-30"><a href="#cb6-30"></a><span class="co"># turn the data in a (samples, feature) matrix:</span></span>
<span id="cb6-31"><a href="#cb6-31"></a>n_samples <span class="op">=</span> <span class="bu">len</span>(digits.images)</span>
<span id="cb6-32"><a href="#cb6-32"></a>data <span class="op">=</span> digits.images.reshape((n_samples, <span class="dv">-1</span>))</span>
<span id="cb6-33"><a href="#cb6-33"></a></span>
<span id="cb6-34"><a href="#cb6-34"></a><span class="co"># Create a classifier: a support vector classifier</span></span>
<span id="cb6-35"><a href="#cb6-35"></a>classifier <span class="op">=</span> svm.SVC(gamma<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb6-36"><a href="#cb6-36"></a></span>
<span id="cb6-37"><a href="#cb6-37"></a><span class="co"># Split data into train and test subsets</span></span>
<span id="cb6-38"><a href="#cb6-38"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb6-39"><a href="#cb6-39"></a>    data, digits.target, test_size<span class="op">=</span><span class="fl">0.5</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-40"><a href="#cb6-40"></a></span>
<span id="cb6-41"><a href="#cb6-41"></a><span class="co"># We learn the digits on the first half of the digits</span></span>
<span id="cb6-42"><a href="#cb6-42"></a>classifier.fit(X_train, y_train)</span>
<span id="cb6-43"><a href="#cb6-43"></a></span>
<span id="cb6-44"><a href="#cb6-44"></a><span class="co"># Now predict the value of the digit on the second half:</span></span>
<span id="cb6-45"><a href="#cb6-45"></a>predicted <span class="op">=</span> classifier.predict(X_test)</span>
<span id="cb6-46"><a href="#cb6-46"></a></span>
<span id="cb6-47"><a href="#cb6-47"></a>images_and_predictions <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(digits.images[n_samples <span class="op">//</span> <span class="dv">2</span>:], predicted))</span>
<span id="cb6-48"><a href="#cb6-48"></a><span class="cf">for</span> ax, (image, prediction) <span class="kw">in</span> <span class="bu">zip</span>(axes[<span class="dv">1</span>, :], images_and_predictions[:<span class="dv">4</span>]):</span>
<span id="cb6-49"><a href="#cb6-49"></a>    ax.set_axis_off()</span>
<span id="cb6-50"><a href="#cb6-50"></a>    ax.imshow(image, cmap<span class="op">=</span>plt.cm.gray_r, interpolation<span class="op">=</span><span class="st">&#39;nearest&#39;</span>)</span>
<span id="cb6-51"><a href="#cb6-51"></a>    ax.set_title(<span class="st">&#39;Prediction: </span><span class="sc">%i</span><span class="st">&#39;</span> <span class="op">%</span> prediction)</span>
<span id="cb6-52"><a href="#cb6-52"></a></span>
<span id="cb6-53"><a href="#cb6-53"></a><span class="bu">print</span>(<span class="st">&quot;Classification report for classifier </span><span class="sc">%s</span><span class="st">:</span><span class="ch">\n</span><span class="sc">%s</span><span class="ch">\n</span><span class="st">&quot;</span></span>
<span id="cb6-54"><a href="#cb6-54"></a>      <span class="op">%</span> (classifier, metrics.classification_report(y_test, predicted)))</span>
<span id="cb6-55"><a href="#cb6-55"></a>disp <span class="op">=</span> metrics.plot_confusion_matrix(classifier, X_test, y_test)</span>
<span id="cb6-56"><a href="#cb6-56"></a>disp.figure_.suptitle(<span class="st">&quot;Confusion Matrix&quot;</span>)</span>
<span id="cb6-57"><a href="#cb6-57"></a><span class="bu">print</span>(<span class="st">&quot;Confusion matrix:</span><span class="ch">\n</span><span class="sc">%s</span><span class="st">&quot;</span> <span class="op">%</span> disp.confusion_matrix)</span>
<span id="cb6-58"><a href="#cb6-58"></a></span>
<span id="cb6-59"><a href="#cb6-59"></a>plt.show()</span></code></pre></div>
</div>
</div>
<div id="neural-networks" class="section level2">
<h2><span class="header-section-number">7.5</span> Neural networks</h2>
<p>non linear</p>
<p>activation</p>
<p>softmax
types of layers siehe keras
fully connected</p>
<div id="convolutional-neural-network-cnn-tbd" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Convolutional Neural Network (CNN) TBD</h3>
<p>A Convolutional Neural Network is an neural network are mainly used to analyze image and audio data.</p>
<p>The following explanation is based on <strong>The learning machine</strong> tutorial “Classification
Convolutional Neural Network (CNN)” <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
<p>A classical CNN consists of</p>

<div class="rmdtip">
<ul>
<li>one or more convolutoional layers</li>
<li>one or more pooling layers</li>
<li>one or more fully connected layers</li>
</ul>
</div>

<p>A classical CNN is depicted in the image below</p>
<hr />
<div class="figure">
<img src="images/convNet.png" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
</div>
<hr />
<p>An image is an 3 dimensional array where the third dimension are for the colors red, green and blue, in case of an RGB image. An image can therefore be represented as shown below</p>
<hr />
<div class="figure">
<img src="images/rgbImage.png" class="external" style="width:60.0%" alt="" />
<p class="caption">Figure from <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
</div>
<hr />
<p>To analyze an image the spatial relation between different pixels hold important information. Therefore it is beneficial to use an algorithm which looks not only at one pixel but also at the neighbouring pixels. One way of doing so is to slide an 2 dimensional array over the image array as can be seen below</p>
<hr />
<div class="figure">
<img src="images/conv1Layer.gif" class="external" style="width:60.0%" alt="" />
<p class="caption">Figure from <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
</div>
<hr />
<p>The 2 dimensional array is called a <strong>kernel</strong> and is named depending on its dimensions. The kernel in the graph below is a <strong>“3 by 3 kernel”</strong>. Sliding the array across the image as gives a set of numbers as shown above. Those kernels can detect structures in images such as</p>
<ul>
<li>lines</li>
<li>boxes</li>
<li>circles</li>
</ul>
<p>and kernels in later layers in the CNN can detect more complex structures such as</p>
<ul>
<li>faces</li>
<li>wheels</li>
<li>trees</li>
</ul>
<hr />
<p><img src="images/kernelCnn.png" class="external" style="width:20.0%" /></p>
<hr />
<hr />
<div class="figure">
<img src="images/moveKernel.png" class="external" style="width:20.0%" alt="" />
<p class="caption">Figure from <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
</div>
<hr />
<p>A kernel has the same depth of the input, in a case of an RGB image, the depth of the kernel is 3.
The output of the kernels is added, for each of the positions of the kernels there is one value at the output.</p>
<p>The movement across the image is based on the stride parameters for x and y direction. In the case below the stride is as follows</p>
<ul>
<li>stride x-direction = 1</li>
<li>stride y-direction = 1</li>
</ul>
<p>Depending on stride with and image dimension it might be necessary to apply padding, for details on padding see <a href="https://deepai.org/machine-learning-glossary-and-terms/padding">deepAi</a></p>
<hr />
<div class="figure">
<img src="images/convOperation.gif" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
</div>
<hr />
<div id="pooling-layer" class="section level4">
<h4><span class="header-section-number">7.5.1.1</span> Pooling layer</h4>
<p>The pooling layer reduces the dimension as shown below. There are different types of pooling layers</p>
<ul>
<li>max</li>
<li>average</li>
</ul>
<p>below the working mechanism for a max pooling layer is shown. The stride for x and y is one, the dimension of the 5 by 5 input is reduced to 3 by 3</p>
<div class="figure">
<img src="images/poolingOps.gif" class="external" style="width:80.0%" alt="" />
<p class="caption">Figure from <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
</div>
<p>After one or more combination of convolutional and pooling layers one or more fully connected layers learn how to classify the image based on non-linear combinations of the high-level features learned by the previous layers. The fully connected layer with the soft-max activation at the end gives the probability of each category, often as a result the three to five classes with the highest probability are reported.</p>
<ul>
<li>convolutional and pooling layers =&gt; high-level features</li>
<li>fully connected layers =&gt; combine non-linear high level features for classification</li>
</ul>
<div class="figure">
<img src="images/fcLayerCnn.png" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from <a href="https://www.thelearningmachine.ai/cnn" class="uri">https://www.thelearningmachine.ai/cnn</a></p>
</div>
<p>The operating principle of a CNN is shown below</p>
<hr />
<p><img src="images/cnnOperatingPrinciple.png" style="width:90.0%" /></p>
<hr />
</div>
</div>
<div id="rnn-tbd" class="section level3">
<h3><span class="header-section-number">7.5.2</span> RNN TBD</h3>
</div>
<div id="gans" class="section level3">
<h3><span class="header-section-number">7.5.3</span> GANs</h3>
<p>GANs from Scratch 1: A deep introduction. With code in PyTorch and TensorFlow</p>
<p><a href="https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f" class="uri">https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f</a></p>
<hr />
<p><img src="images/GanExamples.png"  style="width:100%;"></p>
<hr />
<p>credit of the image <span class="citation">(Zhu et al. <a href="#ref-CycleGAN2017" role="doc-biblioref">2017</a>)</span></p>
<p>Generative models learn the intrinsic distribution function of the input data p(x) (or p(x,y) if there are multiple targets/classes in the dataset), allowing them to generate both synthetic inputs x’ and outputs/targets y’, typically given some hidden parameters.</p>
<p>GANs they have proven to be really succesfull in modeling and generating high dimensional data, which is why they’ve become so popular. Nevertheless they are not the only types of Generative Models, others include Variational Autoencoders (VAEs) and pixelCNN/pixelRNN and real NVP. Each model has its own tradeoffs.</p>
<p>Some of the most relevant GAN pros and cons for the are:</p>
<ul>
<li><p>They currently generate the sharpest images</p></li>
<li><p>They are easy to train (since no statistical inference is required), and only back-propogation is needed to obtain gradients</p></li>
<li><p>GANs are difficult to optimize due to unstable training dynamics.</p></li>
<li><p>No statistical inference can be done with them (except here):
GANs belong to the class of direct implicit density models; they model p(x) without explicitly defining the p.d.f.</p></li>
</ul>
<p>A neural network G(z, θ₁)</p>
<p>Jupyter notebook on github <a href="https://github.com/diegoalejogm/gans/blob/master/1.%20Vanilla%20GAN%20PyTorch.ipynb" class="uri">https://github.com/diegoalejogm/gans/blob/master/1.%20Vanilla%20GAN%20PyTorch.ipynb</a></p>
</div>
</div>
<div id="a-gentle-introduction-to-cyclegan-for-image-translation" class="section level2">
<h2><span class="header-section-number">7.6</span> A Gentle Introduction to CycleGAN for Image Translation</h2>
<p><a href="https://machinelearningmastery.com/what-is-cyclegan/" class="uri">https://machinelearningmastery.com/what-is-cyclegan/</a></p>
<div id="examples-for-gans" class="section level3">
<h3><span class="header-section-number">7.6.1</span> Examples for GANs</h3>
<div id="gans-awesome-applications" class="section level4">
<h4><span class="header-section-number">7.6.1.1</span> gans-awesome-applications</h4>
<p>a list of plenty of applications can be found at <a href="https://github.com/nashory/gans-awesome-applications" class="uri">https://github.com/nashory/gans-awesome-applications</a></p>
</div>
</div>
</div>
<div id="software-that-can-generate-photos-from-paintings-turn-horses-into-zebras-perform-style-transfer-and-more." class="section level2">
<h2><span class="header-section-number">7.7</span> Software that can generate photos from paintings, turn horses into zebras, perform style transfer, and more.</h2>
<p>with software to do style transfer
<a href="https://github.com/junyanz/CycleGAN" class="uri">https://github.com/junyanz/CycleGAN</a>
### Pix2pix framework</p>
<p>Jupyter notebook for Colab
<a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb" class="uri">https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb</a></p>
<p><a href="https://colab.research.google.com/github/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb#scrollTo=aDyGj8DmXCJI" class="uri">https://colab.research.google.com/github/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb#scrollTo=aDyGj8DmXCJI</a></p>
<p><img src="images/ColabPix2Pix.png"  style="width:30%;"></p>
</div>
<div id="transformers-tbd" class="section level2">
<h2><span class="header-section-number">7.8</span> Transformers TBD</h2>
<p>Attention Is All You Need <a href="https://arxiv.org/abs/1706.03762" class="uri">https://arxiv.org/abs/1706.03762</a></p>
<p><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a></p>
<p><a href="https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04">What is a Transformer?</a></p>
<p><a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></p>
</div>
</div>
<div id="food-for-the-algorithms-data" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Food for the algorithms: Data</h1>
<div id="discovering-millions-of-datasets-on-the-web" class="section level2">
<h2><span class="header-section-number">8.1</span> Discovering millions of datasets on the web</h2>
<p>Published Jan 23, 2020 by Google
Across the web, there are millions of datasets about nearly any subject that interests you. If you’re looking to buy a puppy, you could find datasets compiling complaints of puppy buyers or studies on puppy cognition. Or if you like skiing, you could find data on revenue of ski resorts or injury rates and participation numbers. Dataset Search has indexed almost 25 million of these datasets, giving you a single place to search for datasets and find links to where the data is. Over the past year, people have tried it out and provided feedback, and now Dataset Search is officially out of beta.</p>
<p><a href="https://blog.google/products/search/discovering-millions-datasets-web/" class="uri">https://blog.google/products/search/discovering-millions-datasets-web/</a></p>

</div>
</div>



<div id="ExplainableMl" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Explainable ML tbd</h1>
<p>adfdasf</p>
<div id="lime-tbd" class="section level2">
<h2><span class="header-section-number">9.1</span> Lime tbd</h2>
<p>First paper on <strong>LIME</strong> was <span class="citation">(Tulio Ribeiro, Singh, and Guestrin <a href="#ref-tulio2016should" role="doc-biblioref">2016</a>)</span></p>
</div>
<div id="alibi-tbd" class="section level2">
<h2><span class="header-section-number">9.2</span> alibi tbd</h2>
<p><a href="https://github.com/SeldonIO/alibi" class="uri">https://github.com/SeldonIO/alibi</a></p>
<p><a href="https://docs.seldon.io/projects/alibi/en/stable/overview/algorithms.html" class="uri">https://docs.seldon.io/projects/alibi/en/stable/overview/algorithms.html</a></p>
</div>
<div id="tf-explain-tbd" class="section level2">
<h2><span class="header-section-number">9.3</span> tf-explain tbd</h2>
<p><a href="https://github.com/sicara/tf-explain" class="uri">https://github.com/sicara/tf-explain</a></p>
</div>
<div id="keras-salient-object-visualization" class="section level2">
<h2><span class="header-section-number">9.4</span> keras-salient-object-visualization</h2>
<p>Keras implementation of nvidia paper ‘Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car’. The goal of the visualization is to explain what Donkey Car (<a href="https://github.com/wroscoe/donkey" class="uri">https://github.com/wroscoe/donkey</a>) learns and how it makes its decisions. The central idea in discerning the salient objects is finding parts of the image that correspond to locations where the feature maps of CNN layers have the greatest activations.</p>
<p>Original paper: <a href="https://arxiv.org/pdf/1704.07911.pdf" class="uri">https://arxiv.org/pdf/1704.07911.pdf</a>
<a href="https://arxiv.org/abs/1704.07911" class="uri">https://arxiv.org/abs/1704.07911</a></p>
<div id="explaining-how-a-deep-neural-network-trained-with-end-to-end-learning-steers-a-car" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car</h3>
<p><span class="citation">(Bojarski et al. <a href="#ref-bojarski2017explaining" role="doc-biblioref">2017</a>)</span></p>
<ul>
<li>Enable further system improvement</li>
<li>Create trust that the system is paying attention to the essential cues</li>
</ul>
</div>
<div id="visualbackprop-efficient-visualization-of-cnns" class="section level3">
<h3><span class="header-section-number">9.4.2</span> VisualBackProp: efficient visualization of CNNs</h3>
<p><span class="citation">(Bojarski et al. <a href="#ref-bojarski2016visualbackprop" role="doc-biblioref">2016</a>)</span></p>
<p><a href="https://arxiv.org/abs/1611.05418" class="uri">https://arxiv.org/abs/1611.05418</a></p>

</div>
</div>
</div>



<div id="MlResources" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> ML online resources</h1>
<div id="in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos" class="section level2">
<h2><span class="header-section-number">10.1</span> In-depth introduction to machine learning in 15 hours of expert videos</h2>
<p><a href="https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/" class="uri">https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/</a></p>
<div id="an-introduction-to-statistical-learning" class="section level3">
<h3><span class="header-section-number">10.1.1</span> An Introduction to Statistical Learning</h3>
<p>This book provides an introduction to statistical learning methods.<br />
<a href="http://faculty.marshall.usc.edu/gareth-james/ISL/" class="uri">http://faculty.marshall.usc.edu/gareth-james/ISL/</a></p>
</div>
</div>
<div id="the-learning-machine" class="section level2">
<h2><span class="header-section-number">10.2</span> The learning machine</h2>
<p><a href="https://www.thelearningmachine.ai" class="uri">https://www.thelearningmachine.ai</a></p>
<p>WELCOME TO TLM
TLM is a new open-source project that aims to create an interactive textbook containing A-Z explanations of concepts and methods, algorithms and their code implementations from the fields of data science, machine learning, deep learning, natural language processing, statistics, and more.</p>
</div>
<div id="deepai-the-front-page-of-a.i." class="section level2">
<h2><span class="header-section-number">10.3</span> DeepAI: The front page of A.I.</h2>
<p><a href="https://deepai.org" class="uri">https://deepai.org</a></p>
<p>The most popular research, guides, news
and more in artificial intelligence</p>

</div>
</div>



<div id="KaggleExamples" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Examples in Kaggle</h1>
<p>Kaggle is a platform for data scientists and machine learning practitioners which allows users to:</p>

<div class="rmdtip">
<ul>
<li><a href="https://www.kaggle.com/datasets">find datasets</a></li>
<li>publish datasets</li>
<li><a href="https://www.kaggle.com/notebooks">exlplore models on web-based data-science environment</a> in
<ul>
<li>Python</li>
<li>R</li>
<li>SQLite</li>
<li>Julia</li>
</ul></li>
<li><a href="https://www.kaggle.com/competitions">work with other machine learning practitioners on competitions</a>
<ul>
<li>379 (Feb 2020)</li>
</ul></li>
<li><a href="https://www.kaggle.com/host">Host competitions</a></li>
<li><a href="https://www.kaggle.com/discussion">engage in discussions</a></li>
<li><a href="https://www.kaggle.com/jobs">find jobs</a></li>
</ul>
</div>

<p>Same facts about Kaggle</p>

<div class="rmdtip">
<ul>
<li>Founded April 2010</li>
<li>Headquarter in San Francisco</li>
<li>More than 1 million member since March 2017</li>
</ul>
</div>

<p>Kinds of competitions</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1"></a>- <span class="st">Featured</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="st">    - generally commercially-purposed prediction problems</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="st">    - with up to $1.5 mio price money</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="st">    - 177 (Feb 2020)</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="st">        - 2 active</span></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="st">    - good opportunity to learn from the best</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="st">        </span></span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="st">- Research</span></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="st">    - more experimental than featured competition problems</span></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="st">    - with up to $50,000 price money</span></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="st">    - 94 (Feb 2020)</span></span>
<span id="cb7-12"><a href="#cb7-12"></a><span class="st">        - 2 active</span></span>
<span id="cb7-13"><a href="#cb7-13"></a></span>
<span id="cb7-14"><a href="#cb7-14"></a>- <span class="st">Recruitment</span></span>
<span id="cb7-15"><a href="#cb7-15"></a><span class="st">    - corporation-curated challenges</span></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="st">    - teams of size one</span></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="st">    - with up to $20,000 price money</span></span>
<span id="cb7-18"><a href="#cb7-18"></a><span class="st">    - 17 (Feb 2020)</span></span>
<span id="cb7-19"><a href="#cb7-19"></a><span class="st">        - 0 active</span></span>
<span id="cb7-20"><a href="#cb7-20"></a><span class="st">    - interested participants can upload their resume for consideration by the host</span></span>
<span id="cb7-21"><a href="#cb7-21"></a><span class="st">    - price: job interview</span></span>
<span id="cb7-22"><a href="#cb7-22"></a><span class="st">    </span></span>
<span id="cb7-23"><a href="#cb7-23"></a><span class="st">    </span></span>
<span id="cb7-24"><a href="#cb7-24"></a><span class="st">- Getting started</span></span>
<span id="cb7-25"><a href="#cb7-25"></a><span class="st">    - easiest, most approachable competitions</span></span>
<span id="cb7-26"><a href="#cb7-26"></a><span class="st">    - getting the foot in the door</span></span>
<span id="cb7-27"><a href="#cb7-27"></a><span class="st">    - 11 (Feb 2020)</span></span>
<span id="cb7-28"><a href="#cb7-28"></a><span class="st">        - 4 active</span></span>
<span id="cb7-29"><a href="#cb7-29"></a><span class="st">    </span></span>
<span id="cb7-30"><a href="#cb7-30"></a><span class="st">- Playground</span></span>
<span id="cb7-31"><a href="#cb7-31"></a><span class="st">    - one step above Getting Started in difficulty</span></span>
<span id="cb7-32"><a href="#cb7-32"></a><span class="st">    - with up to $30,000 price money</span></span>
<span id="cb7-33"><a href="#cb7-33"></a><span class="st">    - 60 (Feb 2020)</span></span>
<span id="cb7-34"><a href="#cb7-34"></a><span class="st">        - 2 active</span></span>
<span id="cb7-35"><a href="#cb7-35"></a><span class="st">- Masters</span></span>
<span id="cb7-36"><a href="#cb7-36"></a><span class="st">    - limited participation</span></span>
<span id="cb7-37"><a href="#cb7-37"></a><span class="st">    - only by invitation</span></span>
<span id="cb7-38"><a href="#cb7-38"></a><span class="st">    - with up to $125,000 price money</span></span>
<span id="cb7-39"><a href="#cb7-39"></a><span class="st">    - 6 (Feb 2020)</span></span>
<span id="cb7-40"><a href="#cb7-40"></a><span class="st">        - 0 active</span></span></code></pre></div>
<p>More details on how competitions are conducted can be found at <a href="https://www.kaggle.com/docs/competitions" class="uri">https://www.kaggle.com/docs/competitions</a></p>
</div>
<div id="melbourne-university-aesmathworksnih-seizure-prediction" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Melbourne University AES/MathWorks/NIH Seizure Prediction</h1>
<p>The competition was hosted in 2016 by at <a href="https://www.kaggle.com/c/melbourne-university-seizure-prediction" class="uri">https://www.kaggle.com/c/melbourne-university-seizure-prediction</a> and was subtitled “Predict seizures in long-term human intracranial EEG recordings”</p>
<p>The <strong>price money was $20,000</strong>, the competition ended 24.11.2016 and <strong>478 teams</strong> had submitted a solution.</p>
<p><img src="images/Seizure%20Prediction%20Graphic.png"  style="width:100%;"></p>
<p>The competition was sponsored by:</p>
<ul>
<li>MathWorks</li>
<li>National Institutes of Health (NINDS)</li>
<li>American Epilepsy Society</li>
<li>University of Melbourne</li>
</ul>
<p>and organized in partnership with:</p>
<ul>
<li>Alliance for Epilepsy Research</li>
<li>University of Pennsylvania</li>
<li>Mayo Clinic.</li>
</ul>

<div class="rmdtip">
<p>Challenge:</p>
<ul>
<li>Predict seizures 1h before they occur</li>
<li>Data
<ul>
<li>Ten minutes intracranial EEG (iEEG) clips</li>
</ul></li>
<li>Benefits
<ul>
<li>Seizure forecasting systems have the potential to help patients with epilepsy lead more normal lives.</li>
</ul></li>
</ul>
</div>

<p>The metric was <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">area under the ROC curve</a> between the predicted probability and the observed target.</p>
<p>The best possible score for perfect predictions is 1. The leader board look as follows:</p>

<div class="rmdtip">
<ul>
<li><p>
Leaderboard:<img src="images/rocAnimation.gif" alt="Smiley face" align="right" style="width:30%;">
</p></li>
<li>0.80701</li>
<li>0.79898</li>
<li>0.79652</li>
</ul>
</div>

<p>The winning solution is described in the next chapter</p>
<div id="winning-solution-1st" class="section level2">
<h2><span class="header-section-number">12.1</span> Winning solution (1st)</h2>
<p>The first placed team was a two man show, they present their solution at <a href="https://www.kaggle.com/c/melbourne-university-seizure-prediction/discussion/26310">Kaggle discussion</a></p>

<div class="rmdtip">
<p>The team consisted of:</p>
<ul>
<li>Four ML experts</li>
<li>Private team</li>
</ul>
</div>

<p>The team members build a total of 11 models which were blended by using an average of ranked predictions of each individual model. The weight of all models was 1.</p>

<div class="rmdtip">
<p>
Models:<img src="images/Scale.svg" alt="Smiley face" align="right" style="width:20%;">
</p>
<ul>
<li>11 models in total</li>
<li>Each weighted 1</li>
</ul>
</div>

<div id="alex-gilberto-models" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Alex / Gilberto models</h3>
<p>The <strong>two created 4 models</strong> which were selected for the final ensemble</p>
<div id="pre-processing" class="section level4">
<h4><span class="header-section-number">12.1.1.1</span> Pre-processing</h4>
<p>For all models of Alex and Gilberto the pre-processing was the same. The code can be found at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/master/Alex_Gilberto/preproc.py">GitHub</a></p>

<div class="rmdtip">
<p>
Pre-processing:<img src="images/segmentation.png" alt="Smiley face" align="right" style="width:30%;">
</p>
<ul>
<li>Segmentation of 10min segments into
<ul>
<li>non-overlapping</li>
<li>30 20s segments</li>
</ul></li>
<li>No filtering</li>
</ul>
</div>

</div>
<div id="software" class="section level4">
<h4><span class="header-section-number">12.1.1.2</span> Software</h4>
<p>The team used Python and several libraries</p>

<div class="rmdtip">
<p>
Software:<img src="images/ProgramIcon.svg" alt="Smiley face" align="right" style="width:30%;">
</p>
<ul>
<li>Python</li>
<li>scikit-learn</li>
<li>pyRiemann</li>
<li>xgboost</li>
<li>mne-python</li>
<li>pandas</li>
<li>pyyaml</li>
</ul>
</div>

</div>
<div id="model-1" class="section level4">
<h4><span class="header-section-number">12.1.1.3</span> Model 1</h4>
<p>The feature generation code is given at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/master/Alex_Gilberto/generate_features.py">GitHub</a></p>
<p>Model 1 used <strong>XGB algorithm</strong> and 96 features</p>

<div class="rmdtip">
<p>96 features:</p>
<ul>
<li>normalized log power
<ul>
<li>6 different frequency band (0.1 - 4 ; 4- 8 ; 8 - 15 ; 15 - 30 ; 30 - 90 ; 90 - 170 Hz)</li>
<li>for each channel</li>
</ul></li>
<li>Power spectral density
<ul>
<li>Welch’s method (window of 512 sample, 25% overlap)</li>
<li>averaged in each band</li>
<li>normalized by the total power</li>
<li>taking logarithm.</li>
</ul></li>
</ul>
</div>

</div>
<div id="model-2" class="section level4">
<h4><span class="header-section-number">12.1.1.4</span> Model 2</h4>
<p>Model 2 used <strong>XGB algorithm</strong> and 336 features</p>

<div class="rmdtip">
<p>336 features:</p>
<ul>
<li>relative log power as described above
-with the addition of various measures
-mean
- min
- max
- variance
- 90th
- 10th percentiles)</li>
<li>auto regressive error coefficient (order 5)</li>
<li><a href="https://en.wikipedia.org/wiki/Fractal_dimension">fractal dimension</a>
<ul>
<li>Petrosian</li>
<li>Higuchi</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Hurst_exponent">Hurst exponent</a></li>
</ul>
</div>

</div>
<div id="model-3" class="section level4">
<h4><span class="header-section-number">12.1.1.5</span> Model 3</h4>
<p>Model 3 used <strong>XGB algorithm</strong> and 576 features
Each of the autocorrelation matrices were projected into their respective riemannian tangent space (see <span class="citation">(Barachant et al. <a href="#ref-barachant2013classification" role="doc-biblioref">2013</a>)</span>, this operation can be seen as a kernel operation that unfold the natural structure of symmetric and positive define matrices) and vectorized to produce a single feature vector of 36 item.</p>

<div class="rmdtip">
<p>576 features:</p>
<ul>
<li>auto-correlation matrix
<ul>
<li>projected into their respective riemannian tangent space
<ul>
<li>kernel operation that unfold the natural structure of symmetric and positive define matrices</li>
</ul></li>
</ul></li>
</ul>
</div>

</div>
<div id="model-4" class="section level4">
<h4><span class="header-section-number">12.1.1.6</span> Model 4</h4>
<p>Model 4 used <strong>XGB algorithm</strong> and 336 features
This feature set is composed by cross-frequency coherence (in the same 6 sub-band as in the relative log power features) of each channels, i.e. the estimation of coherence is achieved between pairs of frequency of the same channel instead to be between pairs of channels for each frequency band. This produce set of 6x6 coherence matrices, that are then projected in their tangent space and vectorized.</p>

<div class="rmdtip">
<p>336 features:</p>
<ul>
<li>cross-frequency coherence
<ul>
<li>projected in their tangent space and vectorized</li>
</ul></li>
</ul>
</div>

</div>
</div>
<div id="feng-models" class="section level3">
<h3><span class="header-section-number">12.1.2</span> Feng models</h3>
<p><strong>Feng created 4 models</strong> which were selected for the final ensemble. Total training time (including feature extraction) is estimated to less than 6 hours for these 4 models on my 8 GB RAM MacBook Pro.</p>
<div id="pre-processing-1" class="section level4">
<h4><span class="header-section-number">12.1.2.1</span> Pre-processing</h4>
<p>The pre-processing was the same for all models</p>

<div class="rmdtip">
<p>
Pre-processing:<img src="images/segmentation.png" alt="Smiley face" align="right" style="width:30%;">
</p>
<ul>
<li>Butterworth filter (5th order with 0.1-180 HZ cutoff )</li>
<li>segmentation of 10min
-non-overlapping
<ul>
<li>30s windows</li>
</ul></li>
</ul>
</div>

</div>
<div id="features" class="section level4">
<h4><span class="header-section-number">12.1.2.2</span> Features</h4>
<p>Two different sets of features were produced and used in different combinations for the models. The script to generate the features can be found at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/00f937cc7710977dc812d9fc675864e2b8288658/Feng/make_features.py">GitHub</a></p>
<p>The parameters of the feature generation is organized in the json file <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/00f937cc7710977dc812d9fc675864e2b8288658/Feng/kaggle_SETTINGS.json">kaggle_SETTINGS.json</a></p>

<div class="rmdtip">
<p>Feature set 1:</p>
<ul>
<li>bands: (0.1–4 Hz), theta (4–8 Hz), alpha (8–12 Hz), beta (12–30 Hz), low gamma (30–70 Hz) and high gamma (70–180Hz)
<ul>
<li>standard deviation</li>
<li>average spectral power</li>
</ul></li>
</ul>
<p>Feature set 2:</p>
<ul>
<li>correlation
<ul>
<li>time domain</li>
<li>frequency domain</li>
<li>upper triangle values of correlation matrices</li>
<li>eigenvalues</li>
</ul></li>
</ul>
</div>

</div>
<div id="models" class="section level4">
<h4><span class="header-section-number">12.1.2.3</span> Models</h4>
<p>The models used different algorithms and either feature set 1 or both feature sets</p>

<div class="rmdtip">
<ul>
<li><p>Model 1: XGB with feature 1</p></li>
<li><p>Model 2: KNN with feature1</p></li>
<li><p>Model 3: KNN with feature1+feature2</p></li>
<li><p>Model 4: Logistic Regression with L2 penalty with feature1+feature2</p></li>
</ul>
</div>

</div>
</div>
<div id="andriy-models" class="section level3">
<h3><span class="header-section-number">12.1.3</span> Andriy models</h3>
<p><strong>Andriy created 3 models</strong> which were selected for the final ensemble</p>
<div id="pre-processing-2" class="section level4">
<h4><span class="header-section-number">12.1.3.1</span> Pre-processing</h4>
<p>For all models of Andriy the pre-processing was the same</p>

<div class="rmdtip">
<p>Pre-processing:</p>
<ul>
<li>demeaning the EEG signal</li>
<li>filtering of the EEG signal between 0.5 and 128 Hz with a notch filter set at 60Hz</li>
<li>downsampling to 256 Hz</li>
<li>segmentation of the 10 minutes segment
<ul>
<li>non-overlapping</li>
<li>30 seconds segment.</li>
</ul></li>
</ul>
</div>

</div>
<div id="features-1" class="section level4">
<h4><span class="header-section-number">12.1.3.2</span> Features</h4>
<p><strong>Andriy created 1965 features</strong> from which he choose by computing the <strong>feature importance</strong> using an XGB classifier.</p>
<p>The univarant features have been previously used in several EEG applications, including seizure detection in newborns and adults <span class="citation">(Temko, Thomas, Marnane, Lightbody, and Boylan <a href="#ref-temko2011eeg" role="doc-biblioref">2011</a><a href="#ref-temko2011eeg" role="doc-biblioref">a</a>)</span> and <span class="citation">(Temko, Thomas, Marnane, Lightbody, and Boylan <a href="#ref-temko2011performance" role="doc-biblioref">2011</a><a href="#ref-temko2011performance" role="doc-biblioref">b</a>)</span></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb8-1"><a href="#cb8-1"></a>per-channel feature (univariate): </span>
<span id="cb8-2"><a href="#cb8-2"></a></span>
<span id="cb8-3"><a href="#cb8-3"></a>- <span class="st">111 feature per channel =&gt; 11*16 = 1776</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="st">- peak frequency of spectrum</span></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="st">- spectral edge frequency (80%, 90%, 95%)</span></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="st">- fine spectral log-filterbank energies in 2Hz width sub-bands (0-2Hz, 1-3Hz, …30-32Hz)</span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="st">- coarse log filterbank energies in delta, theta, alpha, beta, gamma frequency bands</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="st">- normalised FBE in those sub-bands</span></span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="st">- wavelet energy</span></span>
<span id="cb8-10"><a href="#cb8-10"></a><span class="st">- curve length</span></span>
<span id="cb8-11"><a href="#cb8-11"></a><span class="st">- Number of maxima and minima</span></span>
<span id="cb8-12"><a href="#cb8-12"></a><span class="st">- RMS amplitude</span></span>
<span id="cb8-13"><a href="#cb8-13"></a><span class="st">- Hjorth parameters</span></span>
<span id="cb8-14"><a href="#cb8-14"></a><span class="st">- Zero crossings (raw epoch, Δ, ΔΔ)</span></span>
<span id="cb8-15"><a href="#cb8-15"></a><span class="st">- Skewness</span></span>
<span id="cb8-16"><a href="#cb8-16"></a><span class="st">- Kurtosis</span></span>
<span id="cb8-17"><a href="#cb8-17"></a><span class="st">- Nonlinear energy</span></span>
<span id="cb8-18"><a href="#cb8-18"></a><span class="st">- Variance (Δ, ΔΔ)</span></span>
<span id="cb8-19"><a href="#cb8-19"></a><span class="st">- Mean frequency</span></span>
<span id="cb8-20"><a href="#cb8-20"></a><span class="st">- band-width</span></span>
<span id="cb8-21"><a href="#cb8-21"></a><span class="st">- Shannon entropy</span></span>
<span id="cb8-22"><a href="#cb8-22"></a><span class="st">- Singular value decomposition entropy</span></span>
<span id="cb8-23"><a href="#cb8-23"></a><span class="st">- Fisher information</span></span>
<span id="cb8-24"><a href="#cb8-24"></a><span class="st">- Spectral entropy</span></span>
<span id="cb8-25"><a href="#cb8-25"></a><span class="st">- Autoregressive modelling error (model order 1-9)</span></span></code></pre></div>
<p>These multivariate were extracted for the five conventional EEG sub-bands (delta, theta, alpha, beta, gamma) for 6 different montages (horizontal, vertical, diagonal, etc</p>

<div class="rmdtip">
<p>cross-channel features (multivariate):</p>
<ul>
<li>180 features</li>
<li>lag of maximum cross correlation</li>
<li>correlation</li>
<li>brain asymmetry index</li>
<li>brain synchrony index</li>
<li>coherence</li>
<li>frequency of maximum coherence.</li>
</ul>
</div>

</div>
<div id="models-1" class="section level4">
<h4><span class="header-section-number">12.1.3.3</span> Models</h4>
<p>Out of the 1965 features listed above the first model computed the <strong>feature importance</strong> which was then used to select features for model 2 and 3</p>

<div class="rmdtip">
<ul>
<li><p>Model 1: All features were used in a bagged XGB classifier (XGB).</p></li>
<li><p>Model 2: Linear SVM was trained with top 300 features (SVM)</p></li>
<li><p>Model 3: GLM was trained with top 200 features (Glmnet)</p></li>
</ul>
</div>

</div>
</div>
<div id="code-on-github" class="section level3">
<h3><span class="header-section-number">12.1.4</span> Code on GitHub</h3>
<p>A detailed explanation of solution and code is given at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016">GitHub</a></p>
<div id="alex-gilberto-code" class="section level4">
<h4><span class="header-section-number">12.1.4.1</span> Alex / Gilberto code</h4>
<p>The code of Alex / Gilberto is analyzed below</p>
<div id="pre-processing-3" class="section level5">
<h5><span class="header-section-number">12.1.4.1.1</span> Pre-processing</h5>
<p>For all models of Alex and Gilberto the pre-processing was the same. The code can be found at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/master/Alex_Gilberto/preproc.py">GitHub</a></p>
</div>
<div id="feature-generation" class="section level5">
<h5><span class="header-section-number">12.1.4.1.2</span> Feature generation</h5>
<p>The feature generation code is given at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/master/Alex_Gilberto/generate_features.py">GitHub</a></p>
</div>
<div id="models-2" class="section level5">
<h5><span class="header-section-number">12.1.4.1.3</span> Models</h5>
<p>They use the XGB algorithm, the XGB hyperparameters are set in .yml files as follows</p>
<p><img src="images/ymlControl.png"  align="middle" style="width:60%;"></p>
<p>Yaml file:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode yml"><code class="sourceCode yaml"><span id="cb9-1"><a href="#cb9-1"></a><span class="fu">output</span><span class="kw">:</span><span class="at">  Alex_Gilberto_autocorrmat_TS_XGB</span></span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="fu">datasets</span><span class="kw">:</span></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="at">  </span><span class="kw">-</span><span class="at"> autocorrmat</span></span>
<span id="cb9-5"><a href="#cb9-5"></a></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="fu">n_jobs</span><span class="kw">:</span><span class="at"> </span><span class="dv">1</span></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="fu">safe_old</span><span class="kw">:</span><span class="at"> </span><span class="ch">True</span></span>
<span id="cb9-8"><a href="#cb9-8"></a></span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="fu">imports</span><span class="kw">:</span></span>
<span id="cb9-10"><a href="#cb9-10"></a><span class="at">  </span><span class="fu">models</span><span class="kw">:</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span class="at">    </span><span class="kw">-</span><span class="at"> CoherenceToTangent</span></span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="at">  </span><span class="fu">xgboost</span><span class="kw">:</span></span>
<span id="cb9-13"><a href="#cb9-13"></a><span class="at">    </span><span class="kw">-</span><span class="at"> XGBClassifier</span></span>
<span id="cb9-14"><a href="#cb9-14"></a><span class="at">  </span><span class="fu">sklearn.ensemble</span><span class="kw">:</span></span>
<span id="cb9-15"><a href="#cb9-15"></a><span class="at">    </span><span class="kw">-</span><span class="at"> BaggingClassifier</span></span>
<span id="cb9-16"><a href="#cb9-16"></a></span>
<span id="cb9-17"><a href="#cb9-17"></a><span class="fu">model</span><span class="kw">:</span></span>
<span id="cb9-18"><a href="#cb9-18"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">CoherenceToTangent</span><span class="kw">:</span></span>
<span id="cb9-19"><a href="#cb9-19"></a><span class="at">      </span><span class="fu">tsupdate</span><span class="kw">:</span><span class="at"> </span><span class="ch">False</span></span>
<span id="cb9-20"><a href="#cb9-20"></a><span class="at">      </span><span class="fu">metric</span><span class="kw">:</span><span class="at"> </span><span class="st">&#39;&quot;identity&quot;&#39;</span></span>
<span id="cb9-21"><a href="#cb9-21"></a><span class="at">      </span><span class="fu">n_jobs</span><span class="kw">:</span><span class="at"> </span><span class="dv">8</span></span>
<span id="cb9-22"><a href="#cb9-22"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">BaggingClassifier</span><span class="kw">:</span></span>
<span id="cb9-23"><a href="#cb9-23"></a><span class="at">      </span><span class="fu">max_samples</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.99</span></span>
<span id="cb9-24"><a href="#cb9-24"></a><span class="at">      </span><span class="fu">max_features</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.99</span></span>
<span id="cb9-25"><a href="#cb9-25"></a><span class="at">      </span><span class="fu">random_state</span><span class="kw">:</span><span class="at"> </span><span class="dv">666</span></span>
<span id="cb9-26"><a href="#cb9-26"></a><span class="at">      </span><span class="fu">n_estimators</span><span class="kw">:</span><span class="at"> </span><span class="dv">4</span></span>
<span id="cb9-27"><a href="#cb9-27"></a><span class="at">      </span><span class="fu">base_estimator</span><span class="kw">:</span><span class="at"> XGBClassifier(n_estimators=500, learning_rate=0.01, max_depth=4, subsample=0.50, colsample_bytree=0.50, colsample_bylevel=1.00, min_child_weight=2, seed=42)</span></span></code></pre></div>
<p>The models were than called within a shell script:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1"></a></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="kw">for</span> <span class="ex">entry</span> in <span class="st">&quot;models&quot;</span>/*.yml</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="kw">do</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>  <span class="bu">echo</span> config file <span class="st">&quot;</span><span class="va">$entry</span><span class="st">&quot;</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>  <span class="ex">python</span> generate_submission.py  -c <span class="st">&quot;</span><span class="va">$entry</span><span class="st">&quot;</span> -p</span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="kw">done</span></span></code></pre></div>
</div>
</div>
<div id="feng-code" class="section level4">
<h4><span class="header-section-number">12.1.4.2</span> Feng code</h4>
<p>The code of Feng is analyzed below</p>
<div id="pre-processing-4" class="section level5">
<h5><span class="header-section-number">12.1.4.2.1</span> Pre-processing</h5>
<p>The scripts for pre-processing are given at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/tree/00f937cc7710977dc812d9fc675864e2b8288658/Feng/preprocessors">GitHub</a></p>
</div>
<div id="features-2" class="section level5">
<h5><span class="header-section-number">12.1.4.2.2</span> Features</h5>
<p>The script to generate the features can be found at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/00f937cc7710977dc812d9fc675864e2b8288658/Feng/make_features.py">GitHub</a></p>
<p>The parameters of the feature generation is organized in the json file <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/00f937cc7710977dc812d9fc675864e2b8288658/Feng/kaggle_SETTINGS.json">kaggle_SETTINGS.json</a></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">{</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>        <span class="dt">&quot;path&quot;</span><span class="fu">:{</span></span>
<span id="cb11-3"><a href="#cb11-3"></a>        <span class="dt">&quot;root&quot;</span> <span class="fu">:</span> <span class="st">&quot;../&quot;</span><span class="fu">,</span></span>
<span id="cb11-4"><a href="#cb11-4"></a>        <span class="dt">&quot;raw_data_path&quot;</span> <span class="fu">:</span> <span class="st">&quot;../data&quot;</span><span class="fu">,</span></span>
<span id="cb11-5"><a href="#cb11-5"></a>        <span class="dt">&quot;processed_data_path&quot;</span> <span class="fu">:</span><span class="st">&quot;./postprocessedfile&quot;</span><span class="fu">,</span></span>
<span id="cb11-6"><a href="#cb11-6"></a>        <span class="dt">&quot;submission_path&quot;</span> <span class="fu">:</span> <span class="st">&quot;../submissions&quot;</span> </span>
<span id="cb11-7"><a href="#cb11-7"></a>    <span class="fu">},</span></span>
<span id="cb11-8"><a href="#cb11-8"></a></span>
<span id="cb11-9"><a href="#cb11-9"></a>    <span class="dt">&quot;preprocessor&quot;</span><span class="fu">:{</span></span>
<span id="cb11-10"><a href="#cb11-10"></a>        <span class="dt">&quot;highcut&quot;</span> <span class="fu">:</span> <span class="dv">180</span><span class="fu">,</span></span>
<span id="cb11-11"><a href="#cb11-11"></a>        <span class="dt">&quot;lowcut&quot;</span> <span class="fu">:</span> <span class="fl">0.1</span><span class="fu">,</span></span>
<span id="cb11-12"><a href="#cb11-12"></a>        <span class="dt">&quot;nfreq_bands&quot;</span><span class="fu">:</span> <span class="dv">6</span><span class="fu">,</span></span>
<span id="cb11-13"><a href="#cb11-13"></a>        <span class="dt">&quot;win_length_sec&quot;</span><span class="fu">:</span> <span class="dv">30</span><span class="fu">,</span></span>
<span id="cb11-14"><a href="#cb11-14"></a>        <span class="dt">&quot;features&quot;</span><span class="fu">:</span> <span class="st">&quot;meanlog_std&quot;</span><span class="fu">,</span></span>
<span id="cb11-15"><a href="#cb11-15"></a>        <span class="dt">&quot;stride_sec&quot;</span><span class="fu">:</span> <span class="dv">30</span></span>
<span id="cb11-16"><a href="#cb11-16"></a>    <span class="fu">}</span></span>
<span id="cb11-17"><a href="#cb11-17"></a></span>
<span id="cb11-18"><a href="#cb11-18"></a><span class="fu">}</span></span></code></pre></div>
</div>
<div id="models-3" class="section level5">
<h5><span class="header-section-number">12.1.4.2.3</span> Models</h5>
<p>The code for the <strong>GLM model:</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">def</span> train(subject, data_path, plot<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb12-2"><a href="#cb12-2"></a>    d <span class="op">=</span> load_train_data_lasso(data_path, subject)</span>
<span id="cb12-3"><a href="#cb12-3"></a>    x, y <span class="op">=</span> d[<span class="st">&#39;x&#39;</span>], d[<span class="st">&#39;y&#39;</span>]</span>
<span id="cb12-4"><a href="#cb12-4"></a>    <span class="bu">print</span> <span class="st">&#39;n_preictal&#39;</span>, np.<span class="bu">sum</span>(y)</span>
<span id="cb12-5"><a href="#cb12-5"></a>    <span class="bu">print</span> <span class="st">&#39;n_inetrictal&#39;</span>, np.<span class="bu">sum</span>(<span class="dv">1</span><span class="op">-</span>y)</span>
<span id="cb12-6"><a href="#cb12-6"></a>    n_channels <span class="op">=</span> x.shape[<span class="dv">1</span>]</span>
<span id="cb12-7"><a href="#cb12-7"></a>    n_fbins <span class="op">=</span> x.shape[<span class="dv">2</span>]</span>
<span id="cb12-8"><a href="#cb12-8"></a></span>
<span id="cb12-9"><a href="#cb12-9"></a>    x, y <span class="op">=</span> reshape_data(x, y)</span>
<span id="cb12-10"><a href="#cb12-10"></a>    x[np.isneginf(x)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-11"><a href="#cb12-11"></a>    data_scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb12-12"><a href="#cb12-12"></a>    x <span class="op">=</span> data_scaler.fit_transform(x) <span class="co">## Normalizaiton</span></span>
<span id="cb12-13"><a href="#cb12-13"></a>    logreg <span class="op">=</span> linear_model.LogisticRegression(penalty<span class="op">=</span><span class="st">&#39;l2&#39;</span>,C<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb12-14"><a href="#cb12-14"></a>    logreg.fit(x, y)</span>
<span id="cb12-15"><a href="#cb12-15"></a>    <span class="cf">return</span> logreg, data_scaler</span></code></pre></div>
<p>The code for the <strong>KNN model:</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="kw">def</span> train(subject,data_path):</span>
<span id="cb13-3"><a href="#cb13-3"></a>    d<span class="op">=</span>load_train_data_knn(data_path,subject)</span>
<span id="cb13-4"><a href="#cb13-4"></a>    x,y<span class="op">=</span>reshape_data(d[<span class="st">&#39;x&#39;</span>],d[<span class="st">&#39;y&#39;</span>])</span>
<span id="cb13-5"><a href="#cb13-5"></a>    x[np.isneginf(x)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>    x[np.isnan(x)]<span class="op">=</span><span class="dv">0</span></span>
<span id="cb13-7"><a href="#cb13-7"></a>    data_scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb13-8"><a href="#cb13-8"></a>    x <span class="op">=</span> data_scaler.fit_transform(x)</span>
<span id="cb13-9"><a href="#cb13-9"></a>    clf <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">40</span>, weights<span class="op">=</span><span class="st">&#39;distance&#39;</span>,metric<span class="op">=</span><span class="st">&#39;manhattan&#39;</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb13-10"><a href="#cb13-10"></a>    clf.fit(x, y)</span>
<span id="cb13-11"><a href="#cb13-11"></a>    <span class="cf">return</span> clf</span></code></pre></div>
<p>The code for the <strong>XGB model:</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a></span>
<span id="cb14-2"><a href="#cb14-2"></a>params <span class="op">=</span> {</span>
<span id="cb14-3"><a href="#cb14-3"></a>        <span class="st">&quot;objective&quot;</span>: <span class="st">&quot;binary:logistic&quot;</span>,</span>
<span id="cb14-4"><a href="#cb14-4"></a>        <span class="st">&quot;booster&quot;</span> : <span class="st">&quot;gbtree&quot;</span>,</span>
<span id="cb14-5"><a href="#cb14-5"></a>        <span class="st">&quot;eval_metric&quot;</span>: <span class="st">&quot;auc&quot;</span>,</span>
<span id="cb14-6"><a href="#cb14-6"></a>        <span class="st">&quot;eta&quot;</span>: <span class="fl">0.22</span>,<span class="co">##0.22</span></span>
<span id="cb14-7"><a href="#cb14-7"></a>        <span class="st">&quot;max_depth&quot;</span>: <span class="dv">3</span>,</span>
<span id="cb14-8"><a href="#cb14-8"></a>        <span class="st">&quot;subsample&quot;</span>: <span class="fl">0.80</span>,</span>
<span id="cb14-9"><a href="#cb14-9"></a>        <span class="st">&quot;colsample_bytree&quot;</span>: <span class="fl">0.78</span>,</span>
<span id="cb14-10"><a href="#cb14-10"></a>        <span class="st">&quot;silent&quot;</span>: <span class="dv">1</span>,</span>
<span id="cb14-11"><a href="#cb14-11"></a>    }</span>
<span id="cb14-12"><a href="#cb14-12"></a></span>
<span id="cb14-13"><a href="#cb14-13"></a><span class="kw">def</span> train(subject,data_path,params):</span>
<span id="cb14-14"><a href="#cb14-14"></a>    d<span class="op">=</span>load_train_data_xgb(data_path,subject)</span>
<span id="cb14-15"><a href="#cb14-15"></a>    x,y<span class="op">=</span>reshape_data(d[<span class="st">&#39;x&#39;</span>],d[<span class="st">&#39;y&#39;</span>])</span>
<span id="cb14-16"><a href="#cb14-16"></a>    dtrain<span class="op">=</span>xgb.DMatrix(x,y)</span>
<span id="cb14-17"><a href="#cb14-17"></a>    gbm<span class="op">=</span>xgb.train(params,dtrain,num_boost_round<span class="op">=</span><span class="dv">500</span>,verbose_eval<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb14-18"><a href="#cb14-18"></a>    <span class="cf">return</span> gbm</span>
<span id="cb14-19"><a href="#cb14-19"></a></span></code></pre></div>
</div>
</div>
<div id="andriy-code" class="section level4">
<h4><span class="header-section-number">12.1.4.3</span> Andriy code</h4>
<p>The code of Andriy is analyzed below</p>
<div id="pre-processing-5" class="section level5">
<h5><span class="header-section-number">12.1.4.3.1</span> Pre-processing</h5>
<p>Pre-processing is done in Matlab scripts on <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/blob/00f937cc7710977dc812d9fc675864e2b8288658/Andriy/data_preprocess.m">GitHub</a></p>
</div>
<div id="feature-generation-1" class="section level5">
<h5><span class="header-section-number">12.1.4.3.2</span> Feature generation</h5>
<p>The feature generation is also done in 4 Matlab scripts at <a href="https://github.com/alexandrebarachant/kaggle-seizure-prediction-challenge-2016/tree/00f937cc7710977dc812d9fc675864e2b8288658/Andriy">GitHub</a></p>
<ul>
<li>FE_main_AR.m</li>
<li>FE_main_CONN.m</li>
<li>FE_main_CSP_AR.m</li>
<li>FE_main_F.m</li>
</ul>
</div>
<div id="models-4" class="section level5">
<h5><span class="header-section-number">12.1.4.3.3</span> Models</h5>
<p>The files for the models are:</p>

<div class="rmdtip">
<p>-GLM model
- mod_glmnet_5_3.R</p>
<p>Creates SVM model and submission</p>
<p>-SVM model
-mod_svm_5_7.R</p>
<p>-XGB model
- mod_xgb_7_5.R</p>
</div>

<p>Code for the XGB model</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a>  param &lt;-<span class="st"> </span><span class="kw">list</span>(  <span class="dt">objective           =</span> <span class="st">&quot;binary:logistic&quot;</span>, </span>
<span id="cb15-2"><a href="#cb15-2"></a>                  <span class="dt">booster             =</span> <span class="st">&quot;gbtree&quot;</span>,</span>
<span id="cb15-3"><a href="#cb15-3"></a>                  <span class="dt">eval_metric         =</span> <span class="st">&quot;auc&quot;</span>,</span>
<span id="cb15-4"><a href="#cb15-4"></a>                  <span class="dt">eta                 =</span> <span class="fl">0.3</span>,</span>
<span id="cb15-5"><a href="#cb15-5"></a>                  <span class="dt">max_depth           =</span> <span class="dv">3</span>,</span>
<span id="cb15-6"><a href="#cb15-6"></a>                  <span class="dt">subsample           =</span> <span class="fl">0.8</span>,</span>
<span id="cb15-7"><a href="#cb15-7"></a>                  <span class="dt">colsample_bytree    =</span> <span class="dv">1</span>,</span>
<span id="cb15-8"><a href="#cb15-8"></a>                  <span class="dt">num_parallel_tree   =</span> <span class="dv">2</span></span>
<span id="cb15-9"><a href="#cb15-9"></a>  )</span>
<span id="cb15-10"><a href="#cb15-10"></a>  </span>
<span id="cb15-11"><a href="#cb15-11"></a>  <span class="kw">cat</span>(<span class="st">&#39;model1...&#39;</span>)</span>
<span id="cb15-12"><a href="#cb15-12"></a>  <span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb15-13"><a href="#cb15-13"></a>  model1 &lt;-<span class="st"> </span><span class="kw">xgb.train</span>(   <span class="dt">params              =</span> param, </span>
<span id="cb15-14"><a href="#cb15-14"></a>                         <span class="dt">data                =</span> dtrain, </span>
<span id="cb15-15"><a href="#cb15-15"></a>                         <span class="dt">nrounds             =</span>  <span class="dv">1000</span>)</span>
<span id="cb15-16"><a href="#cb15-16"></a>                         </span>
<span id="cb15-17"><a href="#cb15-17"></a>  importance &lt;-<span class="st"> </span><span class="kw">xgb.importance</span>(<span class="dt">model =</span> model1)</span>
<span id="cb15-18"><a href="#cb15-18"></a>  </span></code></pre></div>
</div>
</div>
</div>
</div>
<div id="solution4th-place" class="section level2">
<h2><span class="header-section-number">12.2</span> Solution(4th place)</h2>
<p>The 4th placed team was a one man show, he presented his solution at <a href="https://www.kaggle.com/c/melbourne-university-seizure-prediction/discussion/26098">Kaggle discussion</a>
The solution got a AUC of 0.79457 compared to the winning solution of 0.80701</p>
<div id="pre-processing-6" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Pre-processing</h3>

<div class="rmdtip">
<p>Pre-processing:
- Splitting into 75s windows
- Resampled to 100Hz</p>
</div>

</div>
<div id="features-3" class="section level3">
<h3><span class="header-section-number">12.2.2</span> Features</h3>

<div class="rmdtip">
<p>Features:</p>
<ul>
<li>Divide frequency spectrum
<ul>
<li>50 bands</li>
<li>0.67 - 46.67Hz</li>
<li>take power of bands</li>
<li>correlation matrix between channels</li>
<li>eingenvalues of correlation matrix</li>
</ul></li>
<li>Divide frequency spectrum
<ul>
<li>5 bands delta (0.1-4Hz), theta (4-8Hz), alpha (8-12Hz), beta (12-30Hz), low-gamma (30-50Hz)</li>
<li>take power of bands</li>
<li>entropy of bands</li>
</ul></li>
<li>original signal
<ul>
<li>correlation matrix</li>
<li>eigenvalues</li>
</ul></li>
<li>square all above features as additionals features<br />
</li>
</ul>
</div>

</div>
<div id="model" class="section level3">
<h3><span class="header-section-number">12.2.3</span> Model</h3>
<p>A single XGB model was used</p>
</div>
<div id="github-code" class="section level3">
<h3><span class="header-section-number">12.2.4</span> GitHub code</h3>
<p>The code is hosted on <a href="https://github.com/GainaTang/Melbourne-University-AES-MathWorks-NIH-Seizure-Prediction-4th-solution-">GitHub</a></p>
</div>
</div>
</div>
<div id="bosch-production-line-performance" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Bosch Production Line Performance</h1>
<p>This competition was hosted in 2016 by Bosch at <a href="https://www.kaggle.com/c/bosch-production-line-performance" class="uri">https://www.kaggle.com/c/bosch-production-line-performance</a> and was subtitled “Reduce manufacturing failures”</p>
<p>The price money was $30,000, the competition ended 11.11.2016 and 1373 teams had submitted a solution.</p>

<div class="rmdtip">
<p>Challenge:</p>
<ul>
<li>Predict internal failures<br />
</li>
<li>Data anonymized
<ul>
<li>measurements<br />
</li>
<li>tests<br />
</li>
</ul></li>
<li>Benefit
<ul>
<li>reduce manufacturing failures</li>
</ul></li>
</ul>
</div>

<p>The metric was <a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient"><strong>Matthews correlation coefficient (MCC)</strong></a> between the predicted and the observed response. The MCC is given by:</p>

<div class="rmdmath">
<p><span class="math display">\[MCC = score=\frac{\left(TP*TN\right) - \left(FP*FN\right) }{\sqrt{\left(TP*FP\right) \left(TP*FN\right) \left(TN*FP\right) \left(TN*FN\right)}} \]</span>
where:</p>
<ul>
<li>TP: number of true postive<br />
</li>
<li>FP: number of false positive<br />
</li>
<li>TN: number of true negative<br />
</li>
<li>FN: number of false negative<br />
</li>
</ul>
</div>

<p>The best possible score for perfect predictions is 1. The leader board look as follows:</p>

<div class="rmdtip">
<ol style="list-style-type: decimal">
<li>0.52401</li>
<li>0.51847</li>
<li>0.51621</li>
</ol>
</div>

<p>The winning solution is described in the next chapter</p>
<div id="st-place-solution" class="section level2">
<h2><span class="header-section-number">13.1</span> 1st place solution</h2>
<p>The first placed team was a two man show, they present their solution at <a href="https://www.kaggle.com/c/bosch-production-line-performance/discussion/25434">Kaggle discussion</a></p>

<div class="rmdtip">
<p>The team consisted of</p>
<ul>
<li>Two ML experts</li>
<li>Private team</li>
</ul>
</div>

<div id="data-exploration" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Data exploration</h3>
<p>Two weeks were invested to explore the data regarding:</p>

<div class="rmdtip">
<ul>
<li>Statistics</li>
<li>Correlation</li>
</ul>
</div>

</div>
<div id="hand-crafted-features" class="section level3">
<h3><span class="header-section-number">13.1.2</span> Hand crafted features</h3>
<p>The team created their own features</p>

<div class="rmdtip">
<p>Time features are:</p>
<ul>
<li>StartStationTimes</li>
<li>StartTime, EndTime, Duration</li>
<li>StationTimeDiff</li>
<li>Start/End part of week (mod 1680)</li>
<li>Number of records in next/last 2.5h, 24h, 168h for each station</li>
<li>Number of records in the same time (6 mins)</li>
<li>MeanTimeDiff since last 1/5/10 failure(s)</li>
<li>MeanTimeDiff till next 1/5/10 failure(s)<br />
</li>
</ul>
</div>


<div class="rmdtip">
<p>Numeric features are:</p>
<ul>
<li><p>Raw numeric features (most of the time we used the raw numeric features or simple subsets based on xgb feature importance)</p></li>
<li><p>Z-scaled features for each week</p></li>
<li><p>Count encoding for each value</p></li>
<li><p>Feature combinations (f1 + - * f2)</p>
</div></li>
</ul>
</div>
<div id="hardware" class="section level3">
<h3><span class="header-section-number">13.1.3</span> Hardware</h3>
<p>Since there was no usage of NN the hardware cold be rather modest</p>

<div class="rmdtip">
<ul>
<li>Desktop machine (16GB RAM)</li>
</ul>
</div>

</div>
</div>
<div id="rd-place-solution-tbd" class="section level2">
<h2><span class="header-section-number">13.2</span> 3rd place solution TBD</h2>
<p>discussion not very elaborated</p>
<p>On <a href="https://www.kaggle.com/c/bosch-production-line-performance/discussion/25359">Kaggle discussion</a></p>
</div>
<div id="th-place-solution-with-github" class="section level2">
<h2><span class="header-section-number">13.3</span> 8th place solution with GitHub</h2>
<p>The eighth placed team was a team of eighth, they present their solution at <a href="https://www.kaggle.com/c/bosch-production-line-performance/discussion/25382">Kaggle discussion</a></p>

<div class="rmdtip">
<p>The team consisted of</p>
<ul>
<li>Eigth people</li>
<li>Private group</li>
<li>Organised via the net
</div></li>
</ul>
<div id="overall-architecture" class="section level3">
<h3><span class="header-section-number">13.3.1</span> Overall architecture</h3>
<p>A variety of model were combined</p>

<div class="rmdtip">
<ul>
<li>LightGBM (gbm)</li>
<li>xgboost (xgb)</li>
<li>Random Forest (rf)</li>
<li>Neural Networks (didn’t get picked up on level 2, so they were removed)
</div></li>
</ul>
</div>
<div id="input-data-sets" class="section level3">
<h3><span class="header-section-number">13.3.2</span> Input data sets</h3>
<p>The team created different data sets and used them with different models</p>

<div class="rmdtip">
<p>Level 1 data set:</p>
<ul>
<li>Data set 1 (0.477 gbm): order, raw numeric, date, categorical</li>
<li>Data set 2 (0.482 gbm, 0.477 xgb, 0.473 rf): order, path, raw numeric, date</li>
<li>Data set 3 (0.479 gbm, 0.473 xgb): order, path, numeric, date, refined categorical</li>
<li>Data set 4 (0.469 xgb, 0.442 rf): has features sorted by numeric values + date features + path, unsupervised nearest neighbors (L1 = Manhattan / L2 = Euclidean distances) per label</li>
<li>Data set 5 (0.43 xgb): path, unsupervised nearest neighbors</li>
</ul>
</div>

<p>The model was two staged, the second stage was as given below</p>

<div class="rmdtip">
<p>Level 2 data set:</p>
<ul>
<li>Level 1 predictions (we had 12 predictions from level 1)</li>
<li>Data set 5</li>
<li>Duplicate feature (count and position)</li>
</ul>
</div>

</div>
<div id="ensembling" class="section level3">
<h3><span class="header-section-number">13.3.3</span> Ensembling</h3>
<p>Often a better performance can be achieved when ensembling several model together, good practice is it to use models which a dissimilar because the variance helps to improve the overall performance.</p>

<div class="rmdtip">
<ul>
<li>30% weighted xgboost gbtree (~0.488 CV)</li>
<li>70% weighted Random Forest (~0.485 CV)</li>
</ul>
</div>

</div>
<div id="features-4" class="section level3">
<h3><span class="header-section-number">13.3.4</span> Features</h3>
<div id="features-used" class="section level4">
<h4><span class="header-section-number">13.3.4.1</span> Features used</h4>
<p>Features were created using several methods</p>

<div class="rmdtip">
<ul>
<li>Maximum</li>
<li>Minimum</li>
<li><a href="https://en.wikipedia.org/wiki/Kurtosis">Kurtosis</a></li>
<li>Lead</li>
<li>Lag</li>
<li>One-hot encoded
</div></li>
</ul>
</div>
</div>
<div id="validation-method" class="section level3">
<h3><span class="header-section-number">13.3.5</span> Validation method</h3>
<p>The validation method used was 5-fold cross validation</p>
</div>
<div id="software-1" class="section level3">
<h3><span class="header-section-number">13.3.6</span> Software</h3>
<p>The team used a variety of programming languages and tools</p>

<div class="rmdtip">
<ul>
<li>Programming language
<ul>
<li>R</li>
<li>Python</li>
</ul></li>
<li>Tools
<ul>
<li>LightGBM through <a href="https://github.com/Laurae2/Laurae">Laurae package</a></li>
<li><a href="https://github.com/dmlc/xgboost">xgboost</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">Random Forest scikit-learn</a></li>
<li><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html">H2O Random Forest</a></li>
<li><a href="https://keras.io">Keras Neural Networks</a></li>
<li>Markdown</li>
<li>Rmarkdown</li>
<li>RStudio for R,</li>
<li>Spyder for Python</li>
</ul></li>
</ul>
</div>

</div>
<div id="code-on-github-1" class="section level3">
<h3><span class="header-section-number">13.3.7</span> Code on GitHub</h3>
<p>A detailed explanation of the code is given on <a href="https://github.com/joostgp/kaggle_bosch">GitHub</a></p>

<div class="rmdtip">
<p>The scripts for:</p>
<ul>
<li>Pre-processing</li>
<li>Feature engineering</li>
<li>Modeling scripts</li>
<li>Hyperparameter optimization using HyperOpt</li>
</ul>
</div>

<div id="level-1-model-scripts" class="section level4">
<h4><span class="header-section-number">13.3.7.1</span> Level 1 model scripts</h4>
<p>Lets look into some of the model scripts</p>
<div id="gbm-model" class="section level5">
<h5><span class="header-section-number">13.3.7.1.1</span> <a href="https://github.com/joostgp/kaggle_bosch/blob/master/model_lgbm.R">GBM Model</a></h5>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a></span>
<span id="cb16-2"><a href="#cb16-2"></a>temp_model &lt;-<span class="st"> </span><span class="kw">lgbm.cv</span>(<span class="dt">y_train =</span> label,</span>
<span id="cb16-3"><a href="#cb16-3"></a>                      <span class="dt">x_train =</span> train,</span>
<span id="cb16-4"><a href="#cb16-4"></a>                      <span class="dt">x_test =</span> test,</span>
<span id="cb16-5"><a href="#cb16-5"></a>                      <span class="dt">data_has_label =</span> <span class="ot">TRUE</span>,</span>
<span id="cb16-6"><a href="#cb16-6"></a>                      <span class="dt">NA_value =</span> <span class="st">&quot;nan&quot;</span>,</span>
<span id="cb16-7"><a href="#cb16-7"></a>                      <span class="dt">lgbm_path =</span> my_lgbm_is_at,</span>
<span id="cb16-8"><a href="#cb16-8"></a>                      <span class="dt">workingdir =</span> my_script_is_using,</span>
<span id="cb16-9"><a href="#cb16-9"></a>                      <span class="dt">files_exist =</span> <span class="ot">TRUE</span>,</span>
<span id="cb16-10"><a href="#cb16-10"></a>                      <span class="dt">save_binary =</span> <span class="ot">FALSE</span>,</span>
<span id="cb16-11"><a href="#cb16-11"></a>                      <span class="dt">validation =</span> <span class="ot">TRUE</span>,</span>
<span id="cb16-12"><a href="#cb16-12"></a>                      <span class="dt">folds =</span> folds,</span>
<span id="cb16-13"><a href="#cb16-13"></a>                      <span class="dt">predictions =</span> <span class="ot">TRUE</span>,</span>
<span id="cb16-14"><a href="#cb16-14"></a>                      <span class="dt">importance =</span> <span class="ot">TRUE</span>,</span>
<span id="cb16-15"><a href="#cb16-15"></a>                      <span class="dt">full_quiet =</span> <span class="ot">FALSE</span>,</span>
<span id="cb16-16"><a href="#cb16-16"></a>                      <span class="dt">verbose =</span> <span class="ot">FALSE</span>,</span>
<span id="cb16-17"><a href="#cb16-17"></a>                      <span class="dt">num_threads =</span> threads, <span class="co"># The number of threads to run for LightGBM.</span></span>
<span id="cb16-18"><a href="#cb16-18"></a>                      <span class="dt">application =</span> <span class="st">&quot;binary&quot;</span>,</span>
<span id="cb16-19"><a href="#cb16-19"></a>                      <span class="dt">learning_rate =</span> eta, <span class="co"># The shrinkage rate applied to each iteration</span></span>
<span id="cb16-20"><a href="#cb16-20"></a>                      <span class="dt">num_iterations =</span> <span class="dv">5000</span>, <span class="co"># The number of boosting iterations </span></span>
<span id="cb16-21"><a href="#cb16-21"></a>                      <span class="dt">early_stopping_rounds =</span> <span class="dv">700</span>, <span class="co"># The number of boosting iterations whose validation metric is lower than the best is required for LightGBM to automatically stop</span></span>
<span id="cb16-22"><a href="#cb16-22"></a>                      <span class="dt">num_leaves =</span> leaves, <span class="co"># The number of leaves in one tree</span></span>
<span id="cb16-23"><a href="#cb16-23"></a>                      <span class="dt">min_data_in_leaf =</span> min_sample, <span class="co"># Minimum number of data in one leaf</span></span>
<span id="cb16-24"><a href="#cb16-24"></a>                      <span class="dt">min_sum_hessian_in_leaf =</span> min_hess, <span class="co"># Minimum sum of hessians in one leaf to allow a split</span></span>
<span id="cb16-25"><a href="#cb16-25"></a>                      <span class="dt">max_bin =</span> <span class="dv">255</span>, <span class="co"># The maximum number of bins created per feature</span></span>
<span id="cb16-26"><a href="#cb16-26"></a>                      <span class="dt">feature_fraction =</span> colsample, <span class="co"># Column subsampling percentage. For instance, 0.5 means selecting 50% of features randomly for each iteration</span></span>
<span id="cb16-27"><a href="#cb16-27"></a>                      <span class="dt">bagging_fraction =</span> subsample, <span class="co"># Row subsampling percentage. For instance, 0.5 means selecting 50% of rows randomly for each iteration.</span></span>
<span id="cb16-28"><a href="#cb16-28"></a>                      <span class="dt">bagging_freq =</span> sampling_freq, <span class="co"># The frequency of row subsampling </span></span>
<span id="cb16-29"><a href="#cb16-29"></a>                      <span class="dt">is_unbalance =</span> <span class="ot">FALSE</span>, <span class="co">#  For binary classification, setting this to TRUE might be useful when the training data is unbalanced</span></span>
<span id="cb16-30"><a href="#cb16-30"></a>                      <span class="dt">metric =</span> <span class="st">&quot;auc&quot;</span>,</span>
<span id="cb16-31"><a href="#cb16-31"></a>                      <span class="dt">is_training_metric =</span> <span class="ot">TRUE</span>, <span class="co">#  Whether to report the training metric in addition to the validation metric</span></span>
<span id="cb16-32"><a href="#cb16-32"></a>                      <span class="dt">is_sparse =</span> <span class="ot">FALSE</span>) <span class="co"># Whether sparse optimization is enabled</span></span>
<span id="cb16-33"><a href="#cb16-33"></a></span></code></pre></div>
</div>
<div id="xgboost-model" class="section level5">
<h5><span class="header-section-number">13.3.7.1.2</span> <a href="https://github.com/joostgp/kaggle_bosch/blob/master/model_xgb.R">XGBoost model</a></h5>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a></span>
<span id="cb17-2"><a href="#cb17-2"></a>temp_model &lt;-<span class="st"> </span><span class="kw">xgb.train</span>(<span class="dt">data =</span> dtrain,</span>
<span id="cb17-3"><a href="#cb17-3"></a>                        <span class="dt">nthread =</span> <span class="dv">12</span>,</span>
<span id="cb17-4"><a href="#cb17-4"></a>                        <span class="dt">nrounds =</span> <span class="kw">floor</span>(best_iter <span class="op">*</span><span class="st"> </span><span class="fl">1.1</span>), <span class="co"># max number of boosting iterations.</span></span>
<span id="cb17-5"><a href="#cb17-5"></a>                        <span class="dt">eta =</span> <span class="fl">0.05</span>, <span class="co"># control the learning rate: scale the contribution of each tree by a factor of 0 &lt; eta &lt; 1 when it is added to the current approximation</span></span>
<span id="cb17-6"><a href="#cb17-6"></a>                        <span class="dt">depth =</span> <span class="dv">7</span>, <span class="co"># maximum depth of a tree</span></span>
<span id="cb17-7"><a href="#cb17-7"></a>                        <span class="co">#gamma = 20, #  minimum loss reduction required to make a further partition on a leaf node of the tree.</span></span>
<span id="cb17-8"><a href="#cb17-8"></a>                        <span class="dt">subsample =</span> <span class="fl">0.9</span>, <span class="co"># Setting it to 0.5 means that xgboost randomly collected half of the data instances to grow trees </span></span>
<span id="cb17-9"><a href="#cb17-9"></a>                        <span class="dt">colsample_bytree =</span> <span class="fl">0.7</span>, <span class="co"># subsample ratio of columns when constructing each tree</span></span>
<span id="cb17-10"><a href="#cb17-10"></a>                        <span class="dt">min_child_weight =</span> <span class="dv">50</span>, <span class="co"># minimum sum of instance weight (hessian) needed in a child</span></span>
<span id="cb17-11"><a href="#cb17-11"></a>                        <span class="dt">booster =</span> <span class="st">&quot;gbtree&quot;</span>, <span class="co"># which booster to use, can be gbtree or gblinear</span></span>
<span id="cb17-12"><a href="#cb17-12"></a>                        <span class="co">#feval = mcc_eval_nofail,</span></span>
<span id="cb17-13"><a href="#cb17-13"></a>                        <span class="dt">eval_metric =</span> <span class="st">&quot;auc&quot;</span>,</span>
<span id="cb17-14"><a href="#cb17-14"></a>                        <span class="dt">maximize =</span> <span class="ot">TRUE</span>,</span>
<span id="cb17-15"><a href="#cb17-15"></a>                        <span class="dt">objective =</span> <span class="st">&quot;binary:logistic&quot;</span>,</span>
<span id="cb17-16"><a href="#cb17-16"></a>                        <span class="dt">verbose =</span> <span class="ot">TRUE</span>,</span>
<span id="cb17-17"><a href="#cb17-17"></a>                        <span class="dt">prediction =</span> <span class="ot">TRUE</span>,</span>
<span id="cb17-18"><a href="#cb17-18"></a>                        <span class="dt">watchlist =</span> <span class="kw">list</span>(<span class="dt">test =</span> dtrain))</span>
<span id="cb17-19"><a href="#cb17-19"></a>                        </span></code></pre></div>
</div>
</div>
<div id="level-2-model-scripts" class="section level4">
<h4><span class="header-section-number">13.3.7.2</span> Level 2 model scripts</h4>
<div id="weighted-random-forest-0.485-cv" class="section level5">
<h5><span class="header-section-number">13.3.7.2.1</span> <a href="https://github.com/joostgp/kaggle_bosch/blob/master/model_rf_lv2_v3.R">70% weighted Random Forest (~0.485 CV)</a></h5>
<p>First read in the <strong>results of level 1 models</strong> which are now the <strong>features for the level 2 model</strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>train &lt;-<span class="st"> </span><span class="kw">read_feather</span>(<span class="st">&quot;Shubin/retrain_material/train.feather&quot;</span>)</span>
<span id="cb18-2"><a href="#cb18-2"></a>test &lt;-<span class="st"> </span><span class="kw">read_feather</span>(<span class="st">&quot;Shubin/retrain_material/test.feather&quot;</span>)</span>
<span id="cb18-3"><a href="#cb18-3"></a>train[, <span class="st">&quot;xgb_jay_joost_v2&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161110_xgb_jayjoost_fix2/aaa_stacker_preds_train_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-4"><a href="#cb18-4"></a>test[, <span class="st">&quot;xgb_jay_joost_v2&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161110_xgb_jayjoost_fix2/aaa_stacker_preds_test_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-5"><a href="#cb18-5"></a>train[, <span class="st">&quot;gbm_jay_joost_v2&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161111_lgbm_jayjoost/aaa_stacker_preds_train_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-6"><a href="#cb18-6"></a>test[, <span class="st">&quot;gbm_jay_joost_v2&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161111_lgbm_jayjoost/aaa_stacker_preds_test_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-7"><a href="#cb18-7"></a>train[, <span class="st">&quot;gbm_jay&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161111_lgbm_jay/aaa_stacker_preds_train_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-8"><a href="#cb18-8"></a>test[, <span class="st">&quot;gbm_jay&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161111_lgbm_jay/aaa_stacker_preds_test_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-9"><a href="#cb18-9"></a>train[, <span class="st">&quot;gbm_mike&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161110_lgbm_mike/aaa_stacker_preds_train_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-10"><a href="#cb18-10"></a>test[, <span class="st">&quot;gbm_mike&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161110_lgbm_mike/aaa_stacker_preds_test_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-11"><a href="#cb18-11"></a>train[, <span class="st">&quot;xgb_mike&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161110_xgb_mike/aaa_stacker_preds_train_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span>
<span id="cb18-12"><a href="#cb18-12"></a>test[, <span class="st">&quot;xgb_mike&quot;</span>] &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;Laurae/20161110_xgb_mike/aaa_stacker_preds_test_headerY_scale.csv&quot;</span>)<span class="op">$</span>x</span></code></pre></div>
<p>then train the <strong>level 2 model</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a>  temp_model &lt;-<span class="st"> </span><span class="kw">h2o.randomForest</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">12</span>,</span>
<span id="cb19-2"><a href="#cb19-2"></a>                                 <span class="dt">y =</span> <span class="st">&quot;Response&quot;</span>,</span>
<span id="cb19-3"><a href="#cb19-3"></a>                                 <span class="dt">training_frame =</span> my_train[[i]],</span>
<span id="cb19-4"><a href="#cb19-4"></a>                                 <span class="dt">ntrees =</span> <span class="dv">200</span>, <span class="co"># Number of trees</span></span>
<span id="cb19-5"><a href="#cb19-5"></a>                                 <span class="dt">max_depth =</span> <span class="dv">12</span>, <span class="co"># Maximum tree depth</span></span>
<span id="cb19-6"><a href="#cb19-6"></a>                                 <span class="dt">min_rows =</span> <span class="dv">20</span>, <span class="co"># Fewest allowed (weighted) observations in a leaf</span></span>
<span id="cb19-7"><a href="#cb19-7"></a>                                 <span class="dt">seed =</span> <span class="dv">11111</span>)</span></code></pre></div>
</div>
<div id="hyperparameter-optimization-using-hyperopt" class="section level5">
<h5><span class="header-section-number">13.3.7.2.2</span> Hyperparameter optimization using HyperOpt</h5>
<p>The models have been implemented in R, the hyperparameter optimizsation is implemented in Python.</p>
<p>Define parameters to be optimized</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="co"># Random Forest Params</span></span>
<span id="cb20-2"><a href="#cb20-2"></a>params <span class="op">=</span> {<span class="st">&#39;n_estimators&#39;</span>: <span class="dv">100</span>}</span>
<span id="cb20-3"><a href="#cb20-3"></a>params[<span class="st">&#39;random_state&#39;</span>] <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb20-4"><a href="#cb20-4"></a>params[<span class="st">&#39;max_features&#39;</span>] <span class="op">=</span> hp.choice(<span class="st">&#39;max_features&#39;</span>, <span class="bu">range</span>(<span class="dv">10</span>, <span class="dv">199</span>))</span>
<span id="cb20-5"><a href="#cb20-5"></a>params[<span class="st">&#39;max_depth&#39;</span>] <span class="op">=</span> hp.choice(<span class="st">&#39;max_depth&#39;</span>, <span class="bu">range</span>(<span class="dv">7</span>,<span class="dv">30</span>))</span>
<span id="cb20-6"><a href="#cb20-6"></a>params[<span class="st">&#39;verbose&#39;</span>] <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb20-7"><a href="#cb20-7"></a>params[<span class="st">&#39;n_jobs&#39;</span>] <span class="op">=</span> <span class="dv">-1</span></span>
<span id="cb20-8"><a href="#cb20-8"></a></span></code></pre></div>
<p>Run optimizer from the library <a href="http://hyperopt.github.io/hyperopt/">Hyperopt</a></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a></span>
<span id="cb21-2"><a href="#cb21-2"></a><span class="co"># Hyperopt</span></span>
<span id="cb21-3"><a href="#cb21-3"></a>trials <span class="op">=</span> Trials()</span>
<span id="cb21-4"><a href="#cb21-4"></a>counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-5"><a href="#cb21-5"></a>best <span class="op">=</span> fmin(score_rf, </span>
<span id="cb21-6"><a href="#cb21-6"></a>                    params, </span>
<span id="cb21-7"><a href="#cb21-7"></a>                    algo<span class="op">=</span>tpe.suggest, <span class="co"># search algorithm</span></span>
<span id="cb21-8"><a href="#cb21-8"></a>                    max_evals<span class="op">=</span><span class="dv">200</span>, </span>
<span id="cb21-9"><a href="#cb21-9"></a>                    trials<span class="op">=</span>trials)</span></code></pre></div>
<p>choosing the trials option gives back a dictionary with</p>
<ul>
<li>trials.trials - a list of dictionaries representing everything about the search</li>
<li>trials.results - a list of dictionaries returned by ‘objective’ during the search</li>
<li>trials.losses() - a list of losses (float for each ‘ok’ trial)</li>
<li>trials.statuses() - a list of status strings</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="corporación-favorita-grocery-sales-forecasting" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> Corporación Favorita Grocery Sales Forecasting</h1>
<p><a href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting" class="uri">https://www.kaggle.com/c/favorita-grocery-sales-forecasting</a></p>
<div id="st-place-solution-1" class="section level2">
<h2><span class="header-section-number">14.1</span> 1st place solution</h2>
<p>The first place solution is described at <a href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582">Kaggle discussion</a></p>
</div>
<div id="th-place-solution-overview" class="section level2">
<h2><span class="header-section-number">14.2</span> 4th-Place Solution Overview</h2>
<p>On <a href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47529">Kaggle discussion</a></p>
<p>A similar code used in a different competition was shared on <a href="https://github.com/sjvasquez/web-traffic-forecasting">GitHub</a></p>
</div>
<div id="th-place-solution" class="section level2">
<h2><span class="header-section-number">14.3</span> 5th Place Solution</h2>
<p>On <a href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47556">Kaggle discussion</a></p>
<p>The code was shared on <a href="https://github.com/LenzDu/Kaggle-Competition-Favorita">GitHub</a></p>
</div>
</div>
<div id="severstal-steel-defect-detection" class="section level1">
<h1><span class="header-section-number">Chapter 15</span> Severstal: Steel Defect Detection</h1>
<p><a href="https://www.kaggle.com/c/severstal-steel-defect-detection" class="uri">https://www.kaggle.com/c/severstal-steel-defect-detection</a></p>
<p><img src="images/SteelCompetition.dms"  style="width:40%;"></p>
</div>
<div id="lyft-3d-object-detection-for-autonomous-vehicles" class="section level1">
<h1><span class="header-section-number">Chapter 16</span> Lyft 3D Object Detection for Autonomous Vehicles</h1>
<p><a href="https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles" class="uri">https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles</a></p>
<div id="rd-place-solution" class="section level2">
<h2><span class="header-section-number">16.1</span> 3rd place solution</h2>
<p><a href="https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles/discussion/117269#latest-679717" class="uri">https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles/discussion/117269#latest-679717</a></p>
</div>
</div>
<div id="aptos-2019-blindness-detection" class="section level1">
<h1><span class="header-section-number">Chapter 17</span> APTOS 2019 Blindness Detection</h1>
<p><a href="https://www.kaggle.com/c/aptos2019-blindness-detection" class="uri">https://www.kaggle.com/c/aptos2019-blindness-detection</a></p>
<div id="st-place-solution-summary" class="section level2">
<h2><span class="header-section-number">17.1</span> 1st place solution summary</h2>
<p><a href="https://www.kaggle.com/c/aptos2019-blindness-detection/discussion/108065#latest-673088" class="uri">https://www.kaggle.com/c/aptos2019-blindness-detection/discussion/108065#latest-673088</a></p>
</div>
</div>
<div id="predicting-molecular-properties" class="section level1">
<h1><span class="header-section-number">Chapter 18</span> Predicting Molecular Properties</h1>
<p>The competition was hosted by a group of UK universities as a featured competition at <a href="https://www.kaggle.com/c/champs-scalar-coupling" class="uri">https://www.kaggle.com/c/champs-scalar-coupling</a>
and was subtitled “Can you measure the magnetic interactions between a pair of atoms?”</p>

<div class="rmdtip">
<ul>
<li>Hosts:
<ul>
<li><strong>CH</strong>emistry <strong>a</strong>nd <strong>M</strong>athematics in <strong>P</strong>hase <strong>S</strong>pace (CHAMPS) University of Bristol</li>
<li>Cardiff University</li>
<li>Imperial College</li>
<li>University of Leeds</li>
</ul></li>
</ul>
</div>

<p>The price money was $30,000, the competition ended 21.08.2019 and 2,749 teams had submitted a solution.</p>

<div class="rmdtip">
<ul>
<li>Challenge
<ul>
<li>Develop algorithm that can predict the <strong>magnetic interaction between two atoms in a molecule</strong></li>
</ul></li>
<li>Data
<ul>
<li>dipole moments</li>
<li>magnetic shielding tensor</li>
<li>mulliken charge</li>
<li>potential energy</li>
</ul></li>
<li>Benefit
<ul>
<li>designing molecules to carry out specific cellular tasks</li>
<li>designing better drug molecules</li>
</ul></li>
</ul>
</div>

<p>The metric was <strong>Log of the Mean Absolute Error (MAE)</strong>, calculated for each scalar coupling type, and then averaged across types, so that a 1% decrease in MAE for one type provides the same improvement in score as a 1% decrease for another type.</p>

<div class="rmdmath">
<p><span class="math display">\[Log MAE = score=\frac{1}{T} \sum_{t=1}^{T} \log \left(\frac{1}{n_{t}} \sum_{i=1}^{n_{t}}\left|y_{i}-\hat{y}_{i}\right|\right)\]</span></p>
<pre><code>Where:</code></pre>
<ul>
<li><span class="math inline">\(T\)</span> is the number of scalar coupling types</li>
<li><span class="math inline">\(n_t\)</span>: is the number of observations of type <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(y_i\)</span>: is the actual scalar coupling constant for the observation</li>
<li><span class="math inline">\(\hat{y}_{i}\)</span> is the predicted scalar coupling constant for the observation</li>
</ul>
</div>

<p>The <strong>best possible score</strong> for perfect predictions is <strong>approximately -20.7232</strong>.
The leader board look as follows:</p>

<div class="rmdtip">
<ol style="list-style-type: decimal">
<li>-3.23968</li>
<li>-3.22349</li>
<li>-3.19498</li>
</ol>
</div>

<p>The winning solution is described in the next chapter</p>
<div id="solution---hybrid" class="section level2">
<h2><span class="header-section-number">18.1</span> #1 Solution - hybrid</h2>
<p>The winning team was from Bosch Research, they present their solution at <a href="https://www.kaggle.com/c/champs-scalar-coupling/discussion/106575#latest-635305.">Kaggle discussion</a></p>

<div class="rmdtip">
<p>The team consisted of</p>
<ul>
<li>Two Bosch research groups
<ul>
<li>Bosch Corporate Research</li>
<li>Bosch Center for AI (BCAI, Pittsburgh)</li>
</ul></li>
<li>Domain experts</li>
<li>ML experts
</div></li>
</ul>
<div id="overall-architecture-1" class="section level3">
<h3><span class="header-section-number">18.1.1</span> Overall architecture</h3>
<p>The winning team used a neural network</p>

<div class="rmdtip">
<ul>
<li>Wrote NN model from scratch</li>
<li>Model processes an entire molecule at once
<ul>
<li>simultaneously making a prediction for each of the scalar couplings in the molecule</li>
</ul></li>
</ul>
<h3 id="input-features-and-embeddings"><span class="header-section-number">18.1.1</span> Input features and embeddings</h3>
</div>


<div class="rmdtip">
<ul>
<li>Embeddings</li>
<li>Plus two scalar constants</li>
</ul>
</div>

</div>
<div id="ensembling-1" class="section level3">
<h3><span class="header-section-number">18.1.2</span> Ensembling</h3>
<p>Often a better performance can be achieved when ensembling several model together, good practice is it to use models which a dissimilar because the variance helps to improve the overall performance.</p>

<div class="rmdtip">
<ul>
<li>Trained 13 models
<ul>
<li>iterations and versions of same basic structure</li>
</ul></li>
<li>Best single model: -3.08</li>
<li>Straight median across predictions: ~-3.22</li>
<li>More involved blending: -3.245<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></li>
</ul>
</div>

</div>
<div id="hardware-1" class="section level3">
<h3><span class="header-section-number">18.1.3</span> Hardware</h3>
<p>The variety of models were trained on different machines, each running a <strong>Linux OS:</strong></p>

<div class="rmdtip">
<ul>
<li>5 machines had 4 GPUs, each a NVIDIA GeForce RTX 2080 Ti</li>
<li>2 machines had 1 GPU NVIDIA Tesla V100 with 32 GB memory</li>
<li>6 machines had 1 GPU NVIDIA Tesla V100 with 16 GB memory</li>
</ul>
</div>

</div>
<div id="software-2" class="section level3">
<h3><span class="header-section-number">18.1.4</span> Software</h3>
<p>The team did not use any of the popular ML frameworks but coded their models from scratch</p>

<div class="rmdtip">
<ul>
<li>Python 3.5+</li>
<li>PyTorch<br />
</li>
<li>CUDA 10.1</li>
<li>NVIDIA APEX (Only available through the repo at this phase)</li>
</ul>
</div>

</div>
<div id="code-on-github-2" class="section level3">
<h3><span class="header-section-number">18.1.5</span> Code on GitHub</h3>
<p>A detailed explanation of the principle setup of the code for pre-processing and for the models is given at <a href="https://github.com/boschresearch/BCAI_kaggle_CHAMPS" class="uri">https://github.com/boschresearch/BCAI_kaggle_CHAMPS</a></p>
</div>
</div>
<div id="solution-quantum-uncertainty" class="section level2">
<h2><span class="header-section-number">18.2</span> #2 solution 🤖 Quantum Uncertainty 🤖</h2>
<p>The second placed team was a two man show, they present their solution at <a href="https://www.kaggle.com/c/champs-scalar-coupling/discussion/106468#latest-685920">Kaggle discussion</a></p>

<div class="rmdtip">
<p>The team consisted of</p>
<ul>
<li>No domain experts</li>
<li>ML experts</li>
<li>Private team</li>
</ul>
</div>

<div id="overall-architecture-2" class="section level3">
<h3><span class="header-section-number">18.2.1</span> Overall architecture</h3>
<p>Since the team had no domain knowledge and <em>“obviously we were at a disadvantage if we tried to become quantum experts in 1 month”</em> they needed the model to build the features.</p>

<div class="rmdtip">
<ul>
<li>Deep learning
<ul>
<li>Dimension 512 to 2048</li>
<li>Layers 6 to 24</li>
<li>Parameters from ~12M to ~100M</li>
</ul></li>
<li>Letting the model build the features</li>
</ul>
</div>

</div>
<div id="input-features-and-embeddings-1" class="section level3">
<h3><span class="header-section-number">18.2.2</span> Input features and embeddings</h3>

<div class="rmdtip">
<ul>
<li>Three input arrays of dimension 29 (maximum number of atoms)
<ul>
<li>x,y,z position of each atom</li>
<li>atom type index (C=0, H=1, etc…)</li>
<li>j-coupling type index (1JHC=0,’2JHH=1,etc.)</li>
</ul></li>
<li>No manually engineered features<br />
</li>
</ul>
</div>

</div>
<div id="data-augmentation" class="section level3">
<h3><span class="header-section-number">18.2.3</span> Data augmentation</h3>
<p>Data augmentation helps to increase the data basis by producing new samples. Depending on how the augmentation is done it can also be a way of making the model more robust to disturbance, e.g. createing artificially shadow in images makes model less susceptible to lightning conditions</p>

<div class="rmdtip">
<ul>
<li>Rotations (though not used in final model)</li>
<li>J-coupling symmetriy as described <a href="https://www.kaggle.com/c/champs-scalar-coupling/discussion/94706#latest-563148">here</a></li>
</ul>
</div>

</div>
<div id="ensembling-2" class="section level3">
<h3><span class="header-section-number">18.2.4</span> Ensembling</h3>
<p>Often a better performance can be achieved when ensembling several model together, good practice is it to use models which a dissimilar because the variance helps to improve the overall performance.</p>

<div class="rmdtip">
<ul>
<li>Trained 14 models
<ul>
<li>iterations and versions of same basic structure</li>
</ul></li>
<li>Best single model: -3.16234</li>
</ul>
</div>

</div>
<div id="hardware-2" class="section level3">
<h3><span class="header-section-number">18.2.5</span> Hardware</h3>
<p>On permise as well as rented hardware was used by the team.</p>

<div class="rmdtip">
<ul>
<li>3 x 2080 Ti + 128 Gb RAM + 16c32t processor</li>
<li>2 x 1080 Ti + 64 Gb RAM + 8c16t processor</li>
<li>Rented 8+ 2080 Ti + 64 Gb RAM + 16c32t processor (multiple machines rented as needed)</li>
</ul>
</div>

</div>
<div id="software-3" class="section level3">
<h3><span class="header-section-number">18.2.6</span> Software</h3>
<p>The team did not use any of the popular ML frameworks but coded their models from scratch</p>

<div class="rmdtip">
<ul>
<li>PyTorch</li>
<li>FastAi<br />
</li>
</ul>
</div>

</div>
<div id="code-on-github-3" class="section level3">
<h3><span class="header-section-number">18.2.7</span> Code on GitHub</h3>
<p>The code is shared at <a href="https://github.com/antorsae/champs-scalar-coupling" class="uri">https://github.com/antorsae/champs-scalar-coupling</a>.
The jupyter notebook using FastAi is at <a href="https://github.com/antorsae/champs-scalar-coupling/blob/master/atom-transfomer.ipynb" class="uri">https://github.com/antorsae/champs-scalar-coupling/blob/master/atom-transfomer.ipynb</a></p>
<p>In the “Model” section the transformer is defined as follows:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="kw">class</span> AtomTransformer(Module):</span>
<span id="cb23-2"><a href="#cb23-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,n_layers,n_heads,d_model,embed_p:<span class="bu">float</span><span class="op">=</span><span class="dv">0</span>,final_p:<span class="bu">float</span><span class="op">=</span><span class="dv">0</span>,d_head<span class="op">=</span><span class="va">None</span>,deep_decoder<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb23-3"><a href="#cb23-3"></a>                 dense_out<span class="op">=</span><span class="va">False</span>, <span class="op">**</span>kwargs):</span>
<span id="cb23-4"><a href="#cb23-4"></a>        </span>
<span id="cb23-5"><a href="#cb23-5"></a>        <span class="va">self</span>.d_model <span class="op">=</span> d_model</span>
<span id="cb23-6"><a href="#cb23-6"></a>        d_head <span class="op">=</span> ifnone(d_head, d_model<span class="op">//</span>n_heads)</span>
<span id="cb23-7"><a href="#cb23-7"></a>        <span class="va">self</span>.transformer <span class="op">=</span> Transformer(n_layers<span class="op">=</span>n_layers,n_heads<span class="op">=</span>n_heads,d_model<span class="op">=</span>d_model,d_head<span class="op">=</span>d_head,</span>
<span id="cb23-8"><a href="#cb23-8"></a>                                       final_p<span class="op">=</span>final_p,dense_out<span class="op">=</span>dense_out,<span class="op">**</span>kwargs)</span>
<span id="cb23-9"><a href="#cb23-9"></a>        </span>
<span id="cb23-10"><a href="#cb23-10"></a>        channels_out <span class="op">=</span> d_model<span class="op">*</span>n_layers <span class="cf">if</span> dense_out <span class="cf">else</span> d_model</span>
<span id="cb23-11"><a href="#cb23-11"></a>        channels_out_scalar <span class="op">=</span> channels_out <span class="op">+</span> n_types <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb23-12"><a href="#cb23-12"></a>        <span class="cf">if</span> deep_decoder:</span>
<span id="cb23-13"><a href="#cb23-13"></a>            sl <span class="op">=</span> [<span class="bu">int</span>(channels_out_scalar<span class="op">/</span>(<span class="dv">2</span><span class="op">**</span>d)) <span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">int</span>(math.ceil(np.log2(channels_out_scalar<span class="op">/</span><span class="dv">4</span>)<span class="op">-</span><span class="dv">1</span>)))]</span>
<span id="cb23-14"><a href="#cb23-14"></a>            <span class="va">self</span>.scalar <span class="op">=</span> nn.Sequential(<span class="op">*</span>(<span class="bu">list</span>(itertools.chain.from_iterable(</span>
<span id="cb23-15"><a href="#cb23-15"></a>                [[nn.Conv1d(sl[i],sl[i<span class="op">+</span><span class="dv">1</span>],<span class="dv">1</span>),nn.ReLU(),nn.BatchNorm1d(sl[i<span class="op">+</span><span class="dv">1</span>])] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(sl)<span class="op">-</span><span class="dv">1</span>)])) <span class="op">+</span> </span>
<span id="cb23-16"><a href="#cb23-16"></a>                [nn.Conv1d(sl[<span class="op">-</span><span class="dv">1</span>], <span class="dv">4</span>, <span class="dv">1</span>)]))</span>
<span id="cb23-17"><a href="#cb23-17"></a>        <span class="cf">else</span>:</span>
<span id="cb23-18"><a href="#cb23-18"></a>            <span class="va">self</span>.scalar <span class="op">=</span> nn.Conv1d(channels_out_scalar, <span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb23-19"><a href="#cb23-19"></a></span>
<span id="cb23-20"><a href="#cb23-20"></a>        <span class="va">self</span>.magnetic  <span class="op">=</span> nn.Conv1d(channels_out, <span class="dv">9</span>, <span class="dv">1</span>)</span>
<span id="cb23-21"><a href="#cb23-21"></a>        <span class="va">self</span>.dipole    <span class="op">=</span> nn.Linear(channels_out, <span class="dv">3</span>)</span>
<span id="cb23-22"><a href="#cb23-22"></a>        <span class="va">self</span>.potential <span class="op">=</span> nn.Linear(channels_out, <span class="dv">1</span>)</span>
<span id="cb23-23"><a href="#cb23-23"></a>        </span>
<span id="cb23-24"><a href="#cb23-24"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.AdaptiveAvgPool1d(<span class="dv">1</span>)</span>
<span id="cb23-25"><a href="#cb23-25"></a>        </span>
<span id="cb23-26"><a href="#cb23-26"></a>        n_atom_embedding <span class="op">=</span> d_model<span class="op">//</span><span class="dv">2</span></span>
<span id="cb23-27"><a href="#cb23-27"></a>        n_type_embedding <span class="op">=</span> d_model <span class="op">-</span> n_atom_embedding <span class="op">-</span> <span class="dv">3</span> <span class="co">#- 1 - 1 </span></span>
<span id="cb23-28"><a href="#cb23-28"></a>        <span class="va">self</span>.type_embedding <span class="op">=</span> nn.Embedding(<span class="bu">len</span>(types)<span class="op">+</span><span class="dv">1</span>,n_type_embedding)</span>
<span id="cb23-29"><a href="#cb23-29"></a>        <span class="va">self</span>.atom_embedding <span class="op">=</span> nn.Embedding(<span class="bu">len</span>(atoms)<span class="op">+</span><span class="dv">1</span>,n_atom_embedding)</span>
<span id="cb23-30"><a href="#cb23-30"></a>        <span class="va">self</span>.drop_type, <span class="va">self</span>.drop_atom <span class="op">=</span> nn.Dropout(embed_p), nn.Dropout(embed_p)</span>
<span id="cb23-31"><a href="#cb23-31"></a>            </span>
<span id="cb23-32"><a href="#cb23-32"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,xyz,<span class="bu">type</span>,ext,atom,mulliken,coulomb,mask_atoms,n_atoms):</span>
<span id="cb23-33"><a href="#cb23-33"></a>        bs, _, n_pts <span class="op">=</span> xyz.shape        </span>
<span id="cb23-34"><a href="#cb23-34"></a>        t <span class="op">=</span> <span class="va">self</span>.drop_type(<span class="va">self</span>.type_embedding((<span class="bu">type</span><span class="op">+</span><span class="dv">1</span>).squeeze(<span class="dv">1</span>)))</span>
<span id="cb23-35"><a href="#cb23-35"></a>        a <span class="op">=</span> <span class="va">self</span>.drop_atom(<span class="va">self</span>.atom_embedding((atom<span class="op">+</span><span class="dv">1</span>).squeeze(<span class="dv">1</span>)))</span>
<span id="cb23-36"><a href="#cb23-36"></a>        </span>
<span id="cb23-37"><a href="#cb23-37"></a><span class="co">#        x = torch.cat([xyz, mulliken, ext, mask_atoms.type_as(xyz)], dim=1)</span></span>
<span id="cb23-38"><a href="#cb23-38"></a>        <span class="co">#x = torch.cat([xyz, mask_atoms.type_as(xyz)], dim=1)</span></span>
<span id="cb23-39"><a href="#cb23-39"></a>        x <span class="op">=</span> xyz</span>
<span id="cb23-40"><a href="#cb23-40"></a>        x <span class="op">=</span> torch.cat([x.transpose(<span class="dv">1</span>,<span class="dv">2</span>), t, a], dim<span class="op">=-</span><span class="dv">1</span>) <span class="op">*</span> math.sqrt(<span class="va">self</span>.d_model) <span class="co"># B,N(29),d_model</span></span>
<span id="cb23-41"><a href="#cb23-41"></a></span>
<span id="cb23-42"><a href="#cb23-42"></a>        mask <span class="op">=</span> (coulomb <span class="op">==</span> <span class="dv">0</span>).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb23-43"><a href="#cb23-43"></a>        x <span class="op">=</span> <span class="va">self</span>.transformer(x, mask).transpose(<span class="dv">1</span>,<span class="dv">2</span>).contiguous()</span>
<span id="cb23-44"><a href="#cb23-44"></a>        </span>
<span id="cb23-45"><a href="#cb23-45"></a>        t_one_hot <span class="op">=</span> torch.zeros(bs,n_types<span class="op">+</span><span class="dv">1</span>,n_pts,device<span class="op">=</span><span class="bu">type</span>.device,dtype<span class="op">=</span>x.dtype).scatter_(<span class="dv">1</span>,<span class="bu">type</span><span class="op">+</span><span class="dv">1</span>, <span class="fl">1.</span>)</span>
<span id="cb23-46"><a href="#cb23-46"></a>        </span>
<span id="cb23-47"><a href="#cb23-47"></a>        scalar    <span class="op">=</span> <span class="va">self</span>.scalar(torch.cat([x, t_one_hot], dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb23-48"><a href="#cb23-48"></a>        magnetic  <span class="op">=</span> <span class="va">self</span>.magnetic(x) </span>
<span id="cb23-49"><a href="#cb23-49"></a>        px <span class="op">=</span> <span class="va">self</span>.pool(x).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb23-50"><a href="#cb23-50"></a>        dipole    <span class="op">=</span> <span class="va">self</span>.dipole(px)</span>
<span id="cb23-51"><a href="#cb23-51"></a>        potential <span class="op">=</span> <span class="va">self</span>.potential(px)</span>
<span id="cb23-52"><a href="#cb23-52"></a>                </span>
<span id="cb23-53"><a href="#cb23-53"></a>        <span class="cf">return</span> <span class="bu">type</span>,ext,scalar,magnetic,dipole,potential</span>
<span id="cb23-54"><a href="#cb23-54"></a>    </span>
<span id="cb23-55"><a href="#cb23-55"></a>    <span class="kw">def</span> reset(<span class="va">self</span>): <span class="cf">pass</span></span></code></pre></div>
<p>The model is instantiated</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>net, learner <span class="op">=</span> <span class="va">None</span>,<span class="va">None</span></span>
<span id="cb24-2"><a href="#cb24-2"></a>gc.collect()</span>
<span id="cb24-3"><a href="#cb24-3"></a>torch.cuda.empty_cache()</span>
<span id="cb24-4"><a href="#cb24-4"></a></span>
<span id="cb24-5"><a href="#cb24-5"></a>n_layers<span class="op">=</span><span class="dv">6</span></span>
<span id="cb24-6"><a href="#cb24-6"></a>n_heads<span class="op">=</span><span class="dv">16</span></span>
<span id="cb24-7"><a href="#cb24-7"></a>d_model<span class="op">=</span><span class="dv">1024</span></span>
<span id="cb24-8"><a href="#cb24-8"></a>d_inner<span class="op">=</span><span class="dv">2048</span><span class="op">*</span><span class="dv">2</span></span>
<span id="cb24-9"><a href="#cb24-9"></a></span>
<span id="cb24-10"><a href="#cb24-10"></a>deep_decoder <span class="op">=</span> <span class="va">False</span></span>
<span id="cb24-11"><a href="#cb24-11"></a>dense_out <span class="op">=</span> <span class="va">False</span></span>
<span id="cb24-12"><a href="#cb24-12"></a></span>
<span id="cb24-13"><a href="#cb24-13"></a>net <span class="op">=</span> AtomTransformer(n_layers<span class="op">=</span>n_layers, n_heads<span class="op">=</span>n_heads,d_model<span class="op">=</span>d_model,d_inner<span class="op">=</span>d_inner,</span>
<span id="cb24-14"><a href="#cb24-14"></a>                      resid_p<span class="op">=</span><span class="fl">0.</span>, attn_p<span class="op">=</span><span class="fl">0.</span>, ff_p<span class="op">=</span><span class="fl">0.</span>, embed_p<span class="op">=</span><span class="dv">0</span>, final_p<span class="op">=</span><span class="fl">0.</span>,</span>
<span id="cb24-15"><a href="#cb24-15"></a>                      deep_decoder<span class="op">=</span>deep_decoder, dense_out<span class="op">=</span>dense_out)</span>
<span id="cb24-16"><a href="#cb24-16"></a></span>
<span id="cb24-17"><a href="#cb24-17"></a>learner <span class="op">=</span> Learner(data,net, loss_func<span class="op">=</span>LMAEMaskedLoss(),)</span>
<span id="cb24-18"><a href="#cb24-18"></a>learner.callbacks.extend([</span>
<span id="cb24-19"><a href="#cb24-19"></a>    SaveModelCallback(learner, monitor<span class="op">=</span><span class="st">&#39;👉🏻LMAE👈🏻&#39;</span>, mode<span class="op">=</span><span class="st">&#39;min&#39;</span>),</span>
<span id="cb24-20"><a href="#cb24-20"></a>    LMAEMetric(learner)])</span></code></pre></div>
</div>
</div>
</div>
<div id="local-examples" class="section level1">
<h1><span class="header-section-number">Chapter 19</span> Local examples</h1>
<div id="university-suttgart-indoor-ortung-mit-mobilfunk" class="section level2">
<h2><span class="header-section-number">19.1</span> University Suttgart: Indoor-Ortung mit Mobilfunk</h2>
<ul>
<li>University Stuttgart Institute of Telecommunications</li>
<li>Leveraging 5G Infrastructure for a Robust Positioning System</li>
<li>Using neural networks</li>
</ul>
<p>More information on the work can be found in <span class="citation">(Widmaier et al. <a href="#ref-widmaier2019towards" role="doc-biblioref">2019</a>)</span></p>
</div>
<div id="bionic-learning-network" class="section level2">
<h2><span class="header-section-number">19.2</span> Bionic Learning Network</h2>
<p>Inspiration for factory and process automation</p>
<p>IT-Designers Gruppe</p>
<p><a href="http://www.it-designers-gruppe.de/unternehmens-gruppe/it-designers-gmbh/" class="uri">http://www.it-designers-gruppe.de/unternehmens-gruppe/it-designers-gmbh/</a></p>

</div>
</div>



<div id="RealWorld" class="section level1">
<h1><span class="header-section-number">Chapter 20</span> Real world example</h1>
<p>This ESA funded project was conducted in 2018/19.
The question asked was: <strong>How can the system be made faster and more reliable?</strong></p>
<div id="subject-of-the-project" class="section level2">
<h2><span class="header-section-number">20.1</span> Subject of the project</h2>
<div id="depending-from-where-you-were-looking" class="section level3 unnumbered">
<h3>Depending from where you were looking:</h3>
<hr />
<p><img src="images/AimSignalDetection.png" style="width:60.0%" /></p>
<hr />
</div>
<div id="looking-from-the-perspective-of-machine-learning-expert" class="section level3 unnumbered">
<h3>Looking from the perspective of machine learning expert</h3>
<hr />
<p><img src="images/TaskDesc.png" style="width:90.0%" /></p>
<hr />
</div>
</div>
<div id="project-phases" class="section level2">
<h2><span class="header-section-number">20.2</span> Project phases</h2>
<div id="the-main-project-phases-are" class="section level3 unnumbered">
<h3>The main project phases are:</h3>
<hr />
<p><img src="images/MlProsess.png" style="width:50.0%" /></p>
<hr />
</div>
<div id="after-data-gathering-iteration-is-trump-1" class="section level3 unnumbered">
<h3>After data gathering iteration is trump</h3>
<hr />
<div class="figure">
<img src="images/MLprocess.svg" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from <a href="http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process" class="uri">http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process</a> (Image Credit: Owlsmcgee [Public domain] )</p>
</div>
<hr />
<p>EDA =&gt; exploratory data analysis<br />
source <a href="http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process" class="uri">http://www.feat.engineering/intro-intro.html#the-model-versus-the-modeling-process</a>]</p>

<div class="rmdtip">
<ul>
<li><p>
Exploratory data analysis
</p>
<ul>
<li>Find correlations or mutial depence</li>
</ul></li>
<li>Quantiative analysis
<ul>
<li>Check distribution
<ul>
<li>Long tail =&gt; log of variable</li>
</ul></li>
</ul></li>
<li>Feature engineering<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>
<ul>
<li>Create and select meaningful features</li>
</ul></li>
<li>Model fit
<ul>
<li>Selecting a few suited models</li>
</ul></li>
<li>Model tuning
<ul>
<li>Vary model <strong>hyperpparameters</strong></li>
</ul></li>
</ul>
</div>

</div>
<div id="feature-engineering-2" class="section level3">
<h3><span class="header-section-number">20.2.1</span> Feature engineering</h3>
<p>Variables that go into model are called:</p>

<div class="rmdtip">
<ul>
<li><p>
Predictors<img src="images/In.png" alt="Smiley face" align="right" style="width:10%;">
</p></li>
<li>Features</li>
<li>Independent variables</li>
</ul>
</div>

<p>Quantity being modeled called:</p>

<div class="rmdtip">
<ul>
<li><p>
Prediction<img src="images/Out.png" alt="Smiley face" align="right" style="width:10%;">
</p></li>
<li>Outcome</li>
<li>Response</li>
<li>Dependent variable</li>
</ul>
</div>

<p>From input to output</p>

<div class="rmdtip">
<p><span class="math display">\[ outcome = f(features) = f(X_1, X_2, \dots, Xp) = f(X)  \]</span></p>
<p><span class="math display">\[ \hat{Y} = \hat{f}(X)\]</span></p>
</div>

</div>
</div>
<div id="algorithm-selection" class="section level2">
<h2><span class="header-section-number">20.3</span> Algorithm selection</h2>
<p>The following algorithms were meant to be investigated following the rule to start with the least complex one. This is even more important since the algorithm was to be run on a satellite which where computing power is more limited than on earth</p>
<p><img src="images/AlgorithmSubset.png" style="width:90.0%" /></p>

<div class="important">
<p>Start with <strong>simple model</strong></p>
</div>

<div id="logistic-regression" class="section level3">
<h3><span class="header-section-number">20.3.1</span> Logistic regression</h3>
<p>Logistic regression is the algorithm with the lowest computational complexity and therefore it was the algorithm with which the investigation for the suitable model would start</p>

<div class="rmdtip">
<ul>
<li>Lowest computational complexity</li>
<li>Start algorithm to determine suitable algorithm</li>
<li>Details of algorithm are given in chapter <a href="#MlAlgoLogReg">7.2</a></li>
</ul>
</div>

<p><img src="Figs/logsiticFunciton-1.png" width="1152" /></p>

<div class="rmdmath">
<p><span class="math display">\[ logistic(\eta) = \frac{1}{1+exp^{-\eta}}\]</span></p>
<p><span class="math display">\[P(Y = 1 \vert X_i = x_i) = \frac{1}{1+exp^{-(\beta_0 + \beta_1X_1+ \dots \beta_n X_n)}}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\beta_n\)</span> are the coeffcients we are searching</li>
<li><span class="math inline">\(X_n\)</span> are the features</li>
</ul>
</div>

</div>
<div id="tree-based-tbd" class="section level3">
<h3><span class="header-section-number">20.3.2</span> Tree based TBD</h3>
<p>Two dominant concepts are used for tree based algorithms:</p>
<hr />
<p><img src="images/TreeAlogo.png" style="width:90.0%" /></p>
<p>Details on the algorithms are given at</p>

<div class="rmdtip">
<ul>
<li>Random forest in chapter <a href="#MlAlgoTreesRandomForest">7.3.3</a></li>
<li>Gradient boosted trees in chapter <a href="#MlAlgoTreesGBM">7.3.4</a></li>
</ul>
</div>

</div>
<div id="support-vector-machine-svm-tbd" class="section level3">
<h3><span class="header-section-number">20.3.3</span> Support Vector Machine (SVM) TBD</h3>
<ul>
<li>Support vector machine in chapter <a href="#MlAlgoSvm">7.4</a></li>
</ul>
<p><span class="math display">\[maximize \(M\) \(\beta_{0}, \beta_{1}, \ldots, \beta_{p}\)
subject to \(\sum_{j=1}^{p} \beta_{j}^{2}=1\)
\(y_{i}\left(\beta_{0}+\beta_{1} x_{i 1}+\ldots+\beta_{p} x_{i p}\right) \geq M\)
for all \(i=1, \dots, N\)\]</span></p>
<hr />
<div class="figure">
<img src="images/2880px-Kernel_Machine.svg.png" class="external" style="width:100.0%" alt="" />
<p class="caption">Figure from Alisneaky, svg version by User:Zirguezi [CC BY-SA (<a href="https://creativecommons.org/licenses/by-sa/4.0" class="uri">https://creativecommons.org/licenses/by-sa/4.0</a>)]</p>
</div>
<p><span class="math inline">\(〖 𝑅〗_𝑡=∑_(𝑖=𝑡)^∞▒〖γ^𝑖 𝑟_𝑖 〗=γ^𝑡 𝑟_𝑡+γ^(𝑡+1) 𝑟_(𝑡+1)…+γ^(𝑡+𝑛) 𝑟_(𝑡+𝑛)+ …\)</span></p>
</div>
</div>
<div id="performance-measurement" class="section level2">
<h2><span class="header-section-number">20.4</span> Performance measurement</h2>
<p>The performance for a classification task is measured with a confusion matrix</p>
<p><img src="images/ConfusionMatrix.png" style="width:90.0%" /></p>

<div class="rmdtip">
<p>For more serios scenarios the false predictions can have severe impact:</p>
<ul>
<li>FP: False prediction
<ul>
<li>Healthy person is unesseary troubled</li>
</ul></li>
<li>FN: False negative
<ul>
<li>Ill person does not get necessary treatment</li>
</ul></li>
</ul>
</div>

<p>Based on the four elements of the confusion matrix <strong>various metrics are defined</strong>, for details check <a href="https://en.wikipedia.org/wiki/Confusion_matrix" class="uri">https://en.wikipedia.org/wiki/Confusion_matrix</a></p>
<div id="sensitivity-and-specificity" class="section level3">
<h3><span class="header-section-number">20.4.1</span> Sensitivity and specificity</h3>
<p>Two metrics which are derived from the confusion matrix are:</p>
<p><strong>Sensitivity</strong> is the proportion of cats which have been identified as cats, or the proportion of people with the illness that have been identified as being ill. It is therefore also called <strong>probability of detection</strong></p>

<div class="rmdmath">
<p><strong>Sensitivity</strong> =&gt; P(cat predicted | cat given)</p>
<hr />
<p><span class="math display">\[
\
Sensitivity = \frac
{\text{Sample with cat and predicted cat}}
{\text{Samples having cat}} = \frac{TP}{TP+FN}
\]</span></p>
</div>

<p><strong>Specificity</strong> is the proportion of non-cats which have been identified as non-cats, or the proportion of healthy people which have been identified as healthy.</p>

<div class="rmdmath">
<p><strong>Specificity</strong> =&gt; P(non-cat predicted | non-cat observed)</p>
<hr />
<p><span class="math display">\[
\
Specificity = \frac
{\text{Sample with non-cat and predicted as non-cat}}
{\text{Samples with non-cat}} = \frac{TN}{TN+FP}
\]</span></p>
</div>

</div>
<div id="receiver-operating-characteristic-roc" class="section level3">
<h3><span class="header-section-number">20.4.2</span> Receiver operating characteristic (ROC)</h3>
<p>The result of a classification with two classes (binary classification) is given as a percentage value of how sure the algorithm is that the sample belongs to a class. Depending on the the overall project target the threshold upon which the class is rated as identified is set. If a false positive is to be avoided than the threshold for classifying a positive is set high</p>

<div class="rmdtip">
<ul>
<li>Used to set the probability threshold of detection</li>
<li>Visual representation of confusion matrix</li>
<li>Includes for various probability thresholds
<ul>
<li>Sensitivity</li>
<li>Specificity</li>
</ul></li>
<li>AUC =&gt; area under curve
<ul>
<li>The higher the better</li>
<li>0 &lt; AUC &lt; 1</li>
</ul></li>
</ul>
</div>

<p><img src="Figs/rocImage-1.png" width="1920" /></p>
</div>
</div>
<div id="confusion-matrix-and-roc-for-pulse" class="section level2">
<h2><span class="header-section-number">20.5</span> Confusion matrix and ROC for pulse</h2>
<p><img src="Figs/unnamed-chunk-108-1.png" width="1920" /></p>
<div id="r-plots" class="section level3">
<h3><span class="header-section-number">20.5.1</span> R Plots</h3>
<p><img src="images/rocAnimation.gif" style="width:100.0%" /></p>
</div>
</div>
<div id="create-augmented-labeled-data" class="section level2">
<h2><span class="header-section-number">20.6</span> Create augmented labeled data</h2>
<p>How to label data as being positive?</p>

<div class="rmdtip">
<ul>
<li><p>Create augmented hits</p></li>
<li><p>Vary parameters</p></li>
</ul>
</div>

<p>On the left hand side are the pulses which have to be detected amid noise as shown in the right hand side image. <strong>Note</strong>, the y-axis have the same scaling, i.e. the pulse signal strengths is lower than the noise.</p>
<p><img src="images/HitZoomed.png" style="width:45.0%" /> <img src="images/NoHitPlot.png" style="width:45.0%" /></p>
<div id="features-of-time-signals" class="section level3">
<h3><span class="header-section-number">20.6.1</span> Features of time signals</h3>
<p><img src="images/SlidingWindow.gif" style="width:100.0%" /></p>
</div>
</div>
<div id="features-generated" class="section level2">
<h2><span class="header-section-number">20.7</span> Features generated</h2>

<div class="rmdtip">
<ul>
<li><p>Sample values of window</p></li>
<li><p>Dynamic time warp (window)</p></li>
<li><p>Min(window)</p></li>
<li><p>Max(window)</p></li>
<li><p>Median(window)</p></li>
<li><p>Variance(window)</p></li>
</ul>
</div>

<div id="analysis-of-generated-features" class="section level3">
<h3><span class="header-section-number">20.7.1</span> Analysis of generated features</h3>
<p><img src="images/ExtraFeaturesViolinPlot.png" style="width:100.0%" /></p>
</div>
<div id="dynamic-time-warp-dtw-for-signal" class="section level3">
<h3><span class="header-section-number">20.7.2</span> Dynamic time warp (DTW) for signal</h3>
<p><img src="images/windowingDtw-1.gif" style="width:100.0%" /></p>
</div>
</div>
<div id="algorithm" class="section level2">
<h2><span class="header-section-number">20.8</span> Algorithm</h2>
<p>Determination which algorithm is best suited depends on</p>

<div class="rmdtip">
<ul>
<li><p>Start with simplest algorithm</p></li>
<li><p>Use simple algorithm for feature engineering</p></li>
<li><p>Use more complex algorithm if result is unsatisfactory</p></li>
</ul>
</div>

</div>
<div id="confusion-matrix-results-logistic-regression-for-measured-data" class="section level2">
<h2><span class="header-section-number">20.9</span> Confusion matrix results logistic regression for measured data</h2>
<p><img src="images/RealValData.png" style="width:80.0%" /></p>
<p><img src="images/RealTestData.png" style="width:80.0%" /></p>
<p><img src="images/RealTestData.png" style="width:80.0%" /></p>
<div id="roc-results-for-measured-data" class="section level3">
<h3><span class="header-section-number">20.9.1</span> ROC results for measured data</h3>

<div class="rmdtip">
<ul>
<li><p>ROC of logistic regression</p></li>
<li><p>Perfect separation of two classes</p></li>
<li><p>No need for more complex algorithm</p></li>
</ul>
</div>

<p><img src="images/RocForLogisticRegression.png" style="width:100.0%" /></p>
</div>
</div>
<div id="several-algorithms-results-for-snr-18db" class="section level2">
<h2><span class="header-section-number">20.10</span> Several algorithms results for SNR = 18dB</h2>
<p><img src="images/snr18Results.png" style="width:100.0%" /></p>
<div id="roc-results-for-snr-18db" class="section level3">
<h3><span class="header-section-number">20.10.1</span> ROC results for SNR 18dB</h3>

<div class="rmdtip">
<ul>
<li><p>ROC of logistic regression</p>
<ul>
<li><p>Not perfect separation of two classes</p></li>
<li><p>Need more complex algorithm =&gt; Gradient boosted trees</p></li>
</ul></li>
</ul>
</div>

<p><img src="images/Snr18GlmRoc.png" style="width:100.0%" /></p>
<p>Depending on ROC characteristic choosing the threshold value which leads to the <strong>highest available profit</strong> is not easy</p>
<p><img src="images/ProfitAninmation.gif" style="width:100.0%" /></p>
<p><img src="images/ProfitAninmation.gif" style="width:100.0%" /></p>
</div>
</div>
<div id="compare-models-for-snr-18db" class="section level2">
<h2><span class="header-section-number">20.11</span> Compare models for SNR = 18dB</h2>
<ul>
<li><strong>ROC, Sensitivity and Specificity</strong> for gradient boosted trees (GBM) and logistic regression (LogReg) and support vector machine (SVM) vs cross validation</li>
</ul>
<p><img src="images/ModelCompBoxPlot.png" style="width:100.0%" /></p>
</div>
<div id="optimize-ml-hyper-parameter" class="section level2">
<h2><span class="header-section-number">20.12</span> Optimize ML hyper parameter</h2>
<p><img src="images/OptHyperPara.png" style="width:80.0%" /></p>

<div class="rmdtip">

</div>


</div>
</div>



<div id="CloudBasedMl" class="section level1">
<h1><span class="header-section-number">Chapter 21</span> Cloud-based machine learning</h1>
<p>Build your own Robust Deep Learning Environment in Minutes</p>
<p><a href="https://towardsdatascience.com/build-your-own-robust-deep-learning-environment-in-minutes-354cf140a5a6" class="uri">https://towardsdatascience.com/build-your-own-robust-deep-learning-environment-in-minutes-354cf140a5a6</a></p>
<ul>
<li><a href="https://colab.research.google.com/">Google Colaboratory</a>
<ul>
<li>Pricing information =&gt; For free</li>
</ul></li>
<li><a href="https://www.paperspace.com/gradient">Paperspace Gradient</a>
<ul>
<li><a href="https://gradient.paperspace.com/pricing">Pricing information</a></li>
</ul></li>
<li><a href="https://www.floydhub.com/product/build">FloydHub Workspace</a>
<ul>
<li><a href="https://www.floydhub.com/pricing">Pricing information</a></li>
</ul></li>
<li><a href="https://lambdalabs.com/service/gpu-cloud">Lambda GPU Cloud</a>
<ul>
<li><a href="https://lambdalabs.com/service/gpu-cloud">Pricing information</a></li>
</ul></li>
<li><a href="https://aws.amazon.com/machine-learning/amis/">AWS Deep Learning AMIs</a>
<ul>
<li><a href="https://aws.amazon.com/sagemaker/pricing/">Pricing information</a>, select <strong>EU (Frankfurt)</strong></li>
</ul></li>
<li><a href="https://cloud.google.com/deep-learning-vm">GCP Deep Learning VM Images</a>
<ul>
<li><a href="https://cloud.google.com/pricing">Pricing information</a></li>
</ul></li>
</ul>

</div>



<div id="KaggleSurvey" class="section level1">
<h1><span class="header-section-number">Chapter 22</span> Kaggle survey introduction</h1>
<p>Kaggle is a platform for data scientists and machine learning practitioners which allows users to</p>
<ul>
<li><a href="https://www.kaggle.com/datasets">find datasets</a></li>
<li>publish datasets</li>
<li><a href="https://www.kaggle.com/notebooks">exlplore models on web-based data-science environment</a> in
<ul>
<li>Python</li>
<li>R</li>
<li>SQLite</li>
<li>Julia</li>
</ul></li>
<li><a href="https://www.kaggle.com/competitions">work with other machine learning practitioners on competitions</a></li>
<li><a href="https://www.kaggle.com/host">Host competitions</a></li>
</ul>
<div id="kaggle-survey-details" class="section level2">
<h2><span class="header-section-number">22.1</span> Kaggle survey details</h2>
<p>This is an <strong>analysis based on Kaggle survey data</strong>,
details are at <a href="https://www.kaggle.com/c/kaggle-survey-2019" class="uri">https://www.kaggle.com/c/kaggle-survey-2019</a>. Kaggle is a subsidiary of Google LLC online community of data scientists machine learners with more than 1Mio members.</p>
<p>It offers data sets, a no-setup, customizable, Jupyter Notebooks environment, machine learning competitions and access free GPUs and a huge repository of community published data &amp; code.</p>
<ul>
<li><p>The survey <strong>received 19,717 usable respondents</strong> from <strong>171 countries and territories</strong>. If a country or territory received less than 50 respondents, they were grouped and named “Other” for anonymity.</p></li>
<li><p>The survey was live from <strong>October 8th to October 28th 2019.</strong></p></li>
<li><p>The median response time for those who participated in the survey was <strong>approximately 10 minutes.</strong></p></li>
</ul>
<p>An overview of the world wide participation is given in the map below. The first three countries are</p>
<ul>
<li>India</li>
<li>USA</li>
<li>Brazil</li>
</ul>
<p><img src="Figs/histo_age-1.png" width="1152" /></p>
<hr />
<p>All numbers of all countries are given in the interactive table below. To find a specific country, type the name in the search field.
Surprising facts:</p>
<ul>
<li>Almost as many participants from Saudi Arabia (50) and Norway (51)</li>
<li>Peru (74) higher than Belgium (70)</li>
<li>Iran (96) higher than Sweden (92)</li>
</ul>
<hr />
<div id="htmlwidget-6ab62b41ede853aee543" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6ab62b41ede853aee543">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56"],["India","USA","Brazil","Japan","China","Russia","Germany","UK","Canada","Spain","Nigeria","France","Taiwan","Turkey","Italy","Australia","South Korea","Poland","Pakistan","Mexico","Ukraine","Colombia","Indonesia","Netherlands","Singapore","Bangladesh","Vietnam","Argentina","Morocco","Egypt","South Africa","Kenya","Portugal","Greece","Israel","Switzerland","Iran","Sweden","Chile","Ireland","Malaysia","Peru","Belgium","Belarus","Tunisia","Thailand","Philippines","Algeria","Czech Republic","Romania","Hungary","Denmark","Austria","New Zealand","Norway","Saudi Arabia"],[4786,3085,728,673,638,626,531,482,450,399,395,386,301,288,271,269,255,212,210,195,191,168,167,161,156,136,128,123,123,122,120,114,114,108,104,97,96,92,91,89,80,74,70,68,68,67,65,58,58,58,56,55,53,51,51,50]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Country<\/th>\n      <th>No. of participants<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":2},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<hr />
<p>The word frequency <strong>word cloud</strong> shows that software engineers and data scientist are heavily involved the field of machine learning</p>
<hr />
<p><img src="Figs/WordCloud-1.png" width="1152" /></p>
<hr />
<p>Easy histogram plots of all questions can be created in R as shown at <a href="https://www.kaggle.com/paultimothymooney/how-to-explore-the-2019-kaggle-survey-data" class="uri">https://www.kaggle.com/paultimothymooney/how-to-explore-the-2019-kaggle-survey-data</a></p>
</div>
<div id="purpose" class="section level2">
<h2><span class="header-section-number">22.2</span> Purpose</h2>
<p>The purpose of the survey analysis is to create insight into which</p>
<ul>
<li>algorithms</li>
<li>tools</li>
<li>platforms</li>
</ul>
<p>are used in the field of machine learning. Contrary to public opinion machine learning is not mainly focused on neural networks.</p>
</div>
<div id="navigation-and-handling" class="section level2">
<h2><span class="header-section-number">22.3</span> Navigation and handling</h2>
<p>To navigate between results use arrow keys or click on sidebar entry</p>
<p>Further information on handling can be obtained by clicking on the <strong>“i”</strong> at the left hand side on top of the page</p>
</div>
</div>
<div id="results" class="section level1">
<h1><span class="header-section-number">Chapter 23</span> Results</h1>
<p>The results are presented by graphs relating parameters either vs time or vs other parameters.</p>
<div id="survey-participants-education-level" class="section level2">
<h2><span class="header-section-number">23.1</span> Survey participants education level</h2>
<p>The following plot shows survey participants education level. Very few participants have a non-academic background. By <strong>no means a academic background is a pre-requisit to use machine learning,</strong> however, two skills are very helpful</p>
<ul>
<li>Coding experience</li>
<li>Statistical knowledge</li>
</ul>
<hr />
<p><img src="Figs/Education-1.png" width="1152" /></p>
<hr />
<p>Coding experience speeds up the process to implement the machine learning ideas and concepts. Most effort during a machine learning project will go into</p>
<ul>
<li>Data pre-processing</li>
<li>Model tuning</li>
</ul>
<p>The actual implementation of the <strong>algorithm is often a matter of 10 - 20 lines of code</strong>. Below the neural network definition for a self driving RC model car of the <a href="https://www.donkeycar.com">donkey car framework</a>.</p>
<p>The neural network is defined using the <a href="https://keras.io">Keras API</a> which sits on top of <a href="https://www.tensorflow.org">Tensorflow</a>, the program is written in <a href="https://www.python.org">Python</a></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>    img_in <span class="op">=</span> Input(shape<span class="op">=</span>input_shape, name<span class="op">=</span><span class="st">&#39;img_in&#39;</span>)          </span>
<span id="cb25-2"><a href="#cb25-2"></a>    x <span class="op">=</span> img_in</span>
<span id="cb25-3"><a href="#cb25-3"></a>    x <span class="op">=</span> Convolution2D(<span class="dv">24</span>, (<span class="dv">5</span>,<span class="dv">5</span>), strides<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;conv2d_1&quot;</span>)(x)      </span>
<span id="cb25-4"><a href="#cb25-4"></a>    x <span class="op">=</span> Dropout(drop)(x)                                                    </span>
<span id="cb25-5"><a href="#cb25-5"></a>    x <span class="op">=</span> Convolution2D(<span class="dv">32</span>, (<span class="dv">5</span>,<span class="dv">5</span>), strides<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;conv2d_2&quot;</span>)(x)     </span>
<span id="cb25-6"><a href="#cb25-6"></a>    x <span class="op">=</span> Dropout(drop)(x)                                              </span>
<span id="cb25-7"><a href="#cb25-7"></a>    <span class="cf">if</span> input_shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">32</span> :</span>
<span id="cb25-8"><a href="#cb25-8"></a>        x <span class="op">=</span> Convolution2D(<span class="dv">64</span>, (<span class="dv">5</span>,<span class="dv">5</span>), strides<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;conv2d_3&quot;</span>)(x)    </span>
<span id="cb25-9"><a href="#cb25-9"></a>    <span class="cf">else</span>:</span>
<span id="cb25-10"><a href="#cb25-10"></a>        x <span class="op">=</span> Convolution2D(<span class="dv">64</span>, (<span class="dv">3</span>,<span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">1</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;conv2d_3&quot;</span>)(x)    </span>
<span id="cb25-11"><a href="#cb25-11"></a>    <span class="cf">if</span> input_shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">64</span> :</span>
<span id="cb25-12"><a href="#cb25-12"></a>        x <span class="op">=</span> Convolution2D(<span class="dv">64</span>, (<span class="dv">3</span>,<span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;conv2d_4&quot;</span>)(x)    </span>
<span id="cb25-13"><a href="#cb25-13"></a>    <span class="cf">elif</span> input_shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">32</span> :</span>
<span id="cb25-14"><a href="#cb25-14"></a>        x <span class="op">=</span> Convolution2D(<span class="dv">64</span>, (<span class="dv">3</span>,<span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">1</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;conv2d_4&quot;</span>)(x)   </span>
<span id="cb25-15"><a href="#cb25-15"></a>    x <span class="op">=</span> Dropout(drop)(x)                                             </span>
<span id="cb25-16"><a href="#cb25-16"></a>    x <span class="op">=</span> Convolution2D(<span class="dv">64</span>, (<span class="dv">3</span>,<span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">1</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;conv2d_5&quot;</span>)(x)      </span>
<span id="cb25-17"><a href="#cb25-17"></a></span>
<span id="cb25-18"><a href="#cb25-18"></a>    x <span class="op">=</span> Flatten(name<span class="op">=</span><span class="st">&#39;flattened&#39;</span>)(x)            </span>
<span id="cb25-19"><a href="#cb25-19"></a>    x <span class="op">=</span> Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;fc_1&quot;</span>)(x)  </span>
<span id="cb25-20"><a href="#cb25-20"></a>    x <span class="op">=</span> Dropout(drop)(x)                              </span>
<span id="cb25-21"><a href="#cb25-21"></a>    x <span class="op">=</span> Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&quot;fc_2&quot;</span>)(x)  </span>
<span id="cb25-22"><a href="#cb25-22"></a>    x <span class="op">=</span> Dropout(drop)(x)            </span>
<span id="cb25-23"><a href="#cb25-23"></a>    angle_out <span class="op">=</span> Dense(<span class="dv">15</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>, name<span class="op">=</span><span class="st">&#39;angle_out&#39;</span>)(x)      </span>
<span id="cb25-24"><a href="#cb25-24"></a>    throttle_out <span class="op">=</span> Dense(<span class="dv">20</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>, name<span class="op">=</span><span class="st">&#39;throttle_out&#39;</span>)(x)      </span>
<span id="cb25-25"><a href="#cb25-25"></a>    </span>
<span id="cb25-26"><a href="#cb25-26"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>[img_in], outputs<span class="op">=</span>[angle_out, throttle_out])</span></code></pre></div>
</div>
<div id="who-uses-which-algorithm" class="section level2">
<h2><span class="header-section-number">23.2</span> Who uses which algorithm</h2>
<p>There are plenty of machine learning algorithms in use, some have been around for quite some time already, others are quite new. Especially in the field of <strong>neural networks there is plenty of research ongoing</strong> as can be seen by a search with the keywords <a href="https://arxiv.org/search/?query=neural+network&amp;searchtype=all&amp;source=header">“neural network” on the moderated but not peer reviewed electronic preprint platform <strong>Arxiv</strong></a>.</p>
<hr />
<p><img src="Figs/AlgoEducation-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<p>Splitting the graphs up for each category of education and plotting the percentage of usage for the given education level gives an insight into how the <strong>usage of algorithms differs over levels of education</strong></p>
<hr />
<p><img src="Figs/AlgoEducationPercent-1.png" width="1152" /></p>
<hr />
<p>The graph above shows that <strong>regression and tree-based algorithms are very popular</strong></p>
<p>They are:</p>
<ul>
<li>Less computationally intensive than neural networks</li>
<li>Available in the de facto standard machine learning library in Python, <a href="https://scikit-learn.org/stable/">scikit-learn</a>.</li>
</ul>
<p>Below <strong>historical data to some the algorithms</strong> are given, together with links to the Wikipedia article on the algorithm.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Linear_regression">Linear regression</a>
<ul>
<li>Legendre, 1805</li>
<li>Gauss, 1809</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic regression</a>
<ul>
<li>Pierre Francois Verhulst, 1830s</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Random_forest">Random forest</a>
<ul>
<li>Ho, 1995</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Gradient_boosting">Gradient boosting trees</a>
<ul>
<li>L. Breiman, 1997</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional neural networks</a>
<ul>
<li>Kunihiko Fukushima, 1980</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent neural networks</a>
<ul>
<li>David Rumelhart, 1986</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Neural_network">Dense neural networks</a>
<ul>
<li>Independently proposed by Alexander Bain, 1873 and William James, 1890</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">Generative adversarial networks</a>
<ul>
<li>Goodfellow, 2010-2014</li>
</ul></li>
</ul>
</div>
<div id="machine-learning-experience-and-algorithms" class="section level2">
<h2><span class="header-section-number">23.3</span> Machine learning experience and algorithms</h2>
<p>Most of the <strong>survey participants have less than 3 years machine learning experience</strong> as can be seen in the graph below. Due to fact that the number in each category differs a lot a <strong>representation of percentages is beneficial for some analysis.</strong></p>
<hr />
<p><img src="Figs/Experience-1.png" width="1152" /></p>
<hr />
<p>The usage of algorithms for different duration of experience is given in the graph below.</p>
<hr />
<p><img src="Figs/AlgoExperience-1.png" width="1152" /></p>
<hr />
<p>Splitting the graphs up for each category of experience and plotting the percentage of usage for the given experience level gives an insight into how the usage of algorithms differs over levels of experience</p>
<hr />
<p><img src="Figs/AlgoExperienceFacet-1.png" width="1152" /></p>
<hr />
<ul>
<li>Regression and trees are popular at all level of experience</li>
<li>Neural networks are more popular for less experienced</li>
<li>20% of very experienced use no algorithm</li>
</ul>
</div>
<div id="experience-and-new-algorithms" class="section level2">
<h2><span class="header-section-number">23.4</span> Experience and new algorithms</h2>
<p>Newer algorithms there are:</p>
<ul>
<li>Evolutionary Approaches</li>
<li>Transformer Networks (BERT, gpt-2, etc)</li>
<li>Generative Adversarial Networks</li>
</ul>
<p>where evolutionary approaches have been around for quite some time but the usage of them in machine learning is rather recent.</p>
<hr />
<p><img src="Figs/AlgoExperienceReduced-1.png" width="1152" /></p>
<hr />
<p>Splitting the graphs up for each category of experience and plotting the percentage of usage for the given experience level gives an insight into how the usage of <em>new</em> algorithms differs over levels of experience</p>
<hr />
<p><img src="Figs/AlgoExperienceReducedFacet-1.png" width="1152" /></p>
<hr />
<p>From the above graph it can be deducted that:</p>
<ul>
<li>Very experienced use new algorithms less often</li>
<li>Newbies embrace them</li>
<li>Evolutionary approaches are popular for medium experienced</li>
</ul>
</div>
<div id="role-of-participants" class="section level2">
<h2><span class="header-section-number">23.5</span> Role of participants</h2>
<p>The role of the participants is shown in the graph below</p>
<hr />
<p><img src="Figs/Role-1.png" width="1152" /></p>
<hr />
<p>The numbers for certain categories certainly have to be taken with a grain of salt since it is not clear how well participants will differentiate e.g. “Data Scientist” and “Data Analyst”. However, it is clear that students are quite active on Kaggle. This might influence the later data since students tend to use freeware more than professionals.</p>
<p>Also there are:</p>
<ul>
<li>Many Software engineers</li>
<li>Very few Statistician</li>
</ul>
</div>
<div id="company-size" class="section level2">
<h2><span class="header-section-number">23.6</span> Company size</h2>
<p>The company size of the participants is shown in the graph below</p>
<hr />
<p><img src="Figs/CompanySize-1.png" width="1152" /></p>
<hr />
<ul>
<li>Largest group of participants are from small companies</li>
<li>Second largest group of participants are from small companies</li>
</ul>
</div>
<div id="company-incorporation-of-machine-learning" class="section level2">
<h2><span class="header-section-number">23.7</span> Company incorporation of machine learning</h2>
<p>The degree of machine learning utilization in the companies of the participants is shown in the graph below</p>
<hr />
<p><img src="Figs/CompanyIncorporationML-1.png" width="1536" /></p>
<hr />
<p><strong>All participants of companies with &gt; 10,000 employees declare that <em>"We have well established ML methods (i.e., models in production for more than 2 years)</em>"</strong></p>
<p>Splitting the graphs up for each category of company size and plotting the incorporation of machine learning shows this even more clearly</p>
<hr />
<p><img src="Figs/CompanyIncorporationMLFacet-1.png" width="1152" /></p>
<hr />
<p>Leaving out the “&gt; 10,000 employees” category for better comparison</p>
<hr />
<p><img src="Figs/CompanyIncorporationMLFacetZoom-1.png" width="1152" /></p>
<hr />
<ul>
<li>More companies explore machine learning than having it established</li>
<li>Many companies don’t use machine learning
<ul>
<li>However, their employees invest in ML</li>
<li>Danger of loosing employees</li>
<li>Maybe companies are slow to discover ML potential</li>
</ul></li>
</ul>
</div>
<div id="favourite-media-sources-on-data-science-topics" class="section level2">
<h2><span class="header-section-number">23.8</span> Favourite media sources on data science topics</h2>
<p>The Favourite media sources on data science topics are shown in the graph below</p>
<hr />
<p><img src="Figs/MediaSourcesDataScience-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<p>Those sources offer information about:
- Algorithms
- New publications
- Projects
- Releases of new software versions
- Recommended courses, popular platforms see <a href="#favourite-online-course-platform">Favourite online course platform</a></p>
<p>A few links to sources are given below</p>
<ul>
<li><a href="https://www.kaggle.com">Kaggle</a></li>
<li><a href="https://www.fast.ai">forums.fast.ai</a></li>
<li><a href="https://medium.com">medium blog</a></li>
</ul>
</div>
<div id="favourite-online-course-platform" class="section level2">
<h2><span class="header-section-number">23.9</span> Favourite online course platform</h2>
<p>Platforms on which survey participants have begun or completed data science courses are shown in the graph below</p>
<hr />
<p><img src="Figs/OnlineCourse-1.png" width="1152" /></p>
<hr />
<p>All levels of academics are active on online course platforms. Below there are links to some of the platforms:</p>
<ul>
<li><a href="https://www.coursera.org">Coursera</a></li>
<li><a href="https://www.kaggle.com/learn/overview">Kaggle Courses</a></li>
<li><a href="https://www.udemy.com">Udemy</a></li>
<li><a href="https://www.udacity.com">Udacity</a></li>
<li><a href="https://www.fast.ai">Fast.ai</a></li>
</ul>
</div>
<div id="favourite-data-analyzing-tool" class="section level2">
<h2><span class="header-section-number">23.10</span> Favourite data analyzing tool</h2>
<p>Participants primary tool to analyze data are shown in the graph below</p>
<hr />
<p><img src="Figs/DataAnalyTool-1.png" width="1152" /></p>
<hr />
<p>Most like to use free tools using the programming language “R” and “Python”</p>
</div>
<div id="experience-in-data-analysis-coding" class="section level2">
<h2><span class="header-section-number">23.11</span> Experience in data analysis coding</h2>
<p>The duration of participants writing code to analyze data is shown in the graph below</p>
<hr />
<p><img src="Figs/CodingDataAnal-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<ul>
<li>Most have less than 5 years coding experience in data analysis</li>
<li>Data analysis can be done without writing code</li>
</ul>
</div>
<div id="favourite-integrated-development-environments-ides" class="section level2">
<h2><span class="header-section-number">23.12</span> Favourite integrated development environments (IDE’s)</h2>
<p>Favourite integrated development environments (IDE’s) are shown in the graph below</p>
<hr />
<p><img src="Figs/IDE-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<p>Below a list of some IDEs, all of them are free except for Matlab.</p>
<ul>
<li><a href="https://jupyter.org">Jupyter Notebook</a>
<ul>
<li>Works with Python, R, Julia, C++, Ruby</li>
</ul></li>
<li><a href="https://code.visualstudio.com">Visual Studio Code</a>
<ul>
<li>Works with Python, R, Julia, C++, Ruby , SQL, XML, Swift, JSON, Perl, Sass…</li>
<li>Debugger</li>
<li>Variable viewer</li>
<li>Console</li>
</ul></li>
<li><a href="https://rstudio.com">RStudio</a>
<ul>
<li>Mainly for R</li>
<li>Debugger</li>
<li>Variable viewer</li>
<li>Console</li>
</ul></li>
<li><a href="https://www.jetbrains.com/pycharm/">PyCharm</a>
<ul>
<li>For Python</li>
<li>Debugger</li>
<li>Variable viewer</li>
</ul></li>
<li><a href="https://www.mathworks.com/products/matlab.html">Matlab</a>
<ul>
<li>Very well established in industry</li>
<li>Originally for control tasks</li>
<li>Commercial tool</li>
<li>Own syntax</li>
</ul></li>
</ul>
</div>
<div id="favourite-hosted-notebook-products" class="section level2">
<h2><span class="header-section-number">23.13</span> Favourite hosted notebook products</h2>
<p>Favourite hosted notebook products are shown in the graph below</p>
<hr />
<p><img src="Figs/HostedNotebook-1.png" width="1152" />
The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<p>Hosted notebooks offer a very easy and comfortable start into writing machine learning code. Some of them are free. Some of them provide many examples from which valuable techniques can be learned.</p>
<ul>
<li><a href="https://www.kaggle.com/kernels">Kaggle Notebooks</a>
<ul>
<li>Great place to find machine learning examples</li>
</ul></li>
<li><a href="https://colab.research.google.com/notebooks/welcome.ipynb">Google Colab</a>
<ul>
<li>Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud</li>
</ul></li>
<li><a href="https://mybinder.org">Binder</a>
<ul>
<li>Open notebooks in executable environment</li>
</ul></li>
<li><a href="https://notebooks.azure.com">Microsoft Azure Notebooks</a>
<ul>
<li>Develop and run code from anywhere with Jupyter notebooks on Azure</li>
</ul></li>
<li><a href="https://www.paperspace.com">Paperspace</a>
<ul>
<li>Powering next-generation applications and cloud ML/AI pipelines.</li>
</ul></li>
</ul>
</div>
<div id="favourite-programming-languages" class="section level2">
<h2><span class="header-section-number">23.14</span> Favourite programming languages</h2>
<p>Favourite programming languages are shown in the graph below</p>
<hr />
<p><img src="Figs/PrgrammingLanguage-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<p>Hands down the <strong>most popular programming language for machine learning is Python</strong>. If <strong>speed matters C++</strong> is the way to go, but still, Python can be used for prototyping.</p>
</div>
<div id="recommended-entry-programming-language" class="section level2">
<h2><span class="header-section-number">23.15</span> Recommended entry programming language</h2>
<p>Recommended programming language for aspiring data scientist to learn first are shown in the graph below</p>
<hr />
<p><img src="Figs/FirstPrgrammingLanguage-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<p>As Python is the most popular machine learning programming language it is not surprising that it is also the most recommended one for beginners.</p>
</div>
<div id="favourite-data-visualization-libraries-or-tools" class="section level2">
<h2><span class="header-section-number">23.16</span> Favourite data visualization libraries or tools</h2>
<p>Favourite data visualization libraries or tools are shown in the graph below</p>
<hr />
<p><img src="Figs/visualizationLibraries-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<p>With Matplotlib there is a clear winner, however, ggplot2 is the clear <strong>Favourite in the R world</strong>.</p>
<ul>
<li><a href="https://matplotlib.org">Matplotlib</a>
<ul>
<li>Matplotlib is a <strong>Python</strong> 2D plotting library which produces publication quality figures in a variety of hard copy formats and interactive environments across platforms</li>
</ul></li>
<li><a href="https://seaborn.pydata.org">Seaborn</a>
<ul>
<li>Seaborn is a <strong>Python</strong> data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.</li>
</ul></li>
<li><a href="https://ggplot2.tidyverse.org">ggplot2</a>
<ul>
<li>ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics</li>
<li>Available for <strong>R</strong> and <strong>Python</strong></li>
</ul></li>
<li><a href="https://plot.ly">Plotly</a>
<ul>
<li>Interactive plots</li>
<li>Available for <strong>R</strong> and <strong>Python</strong></li>
</ul></li>
<li><a href="https://d3js.org">D3.js</a>
<ul>
<li>Data-Driven Documents</li>
<li>Javascript based</li>
<li>Can be used from <strong>R</strong> and <strong>Python</strong></li>
</ul></li>
<li><a href="https://docs.bokeh.org/en/latest/index.html">Bokeh</a>
<ul>
<li>Bokeh is an interactive visualization library for modern web browsers.</li>
</ul></li>
</ul>
</div>
<div id="favourite-specialized-hardware" class="section level2">
<h2><span class="header-section-number">23.17</span> Favourite specialized hardware</h2>
<p>Favourite specialized hardware are shown in the graph below</p>
<hr />
<p><img src="Figs/spezializedHardware-1.png" width="1152" />
The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<ul>
<li><strong>CPU</strong> =&gt; Central Processing Unit
<ul>
<li>Performs basic arithmetic, logic, and input output instructions</li>
<li>Heart of every computing device</li>
</ul></li>
<li><strong>GPU</strong> =&gt; Graphics Processing Unit
<ul>
<li>Optimized processor for graphics</li>
<li>Very fast matrix multiplication =&gt; speeds up neural network computation</li>
</ul></li>
<li><strong>TPU</strong> =&gt; Tensor Processing Unit
<ul>
<li>A tensor processing unit (TPU) is an AI accelerator application-specific integrated circuit (ASIC) <strong>developed by Google specifically for neural network machine learning.</strong></li>
<li>Edge TPU
<ul>
<li>4 TOPs<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></li>
<li>2W</li>
</ul></li>
</ul></li>
</ul>
<p>In <span class="citation">Wei, Brooks, and others (<a href="#ref-wei2019benchmarking" role="doc-biblioref">2019</a>)</span> a comparison of the three processors with respect to machine learning capabilities is given:</p>
<blockquote>
<p>• TPU is highly-optimized for large batches and CNNs, and has the highest training throughput</p>
</blockquote>
<blockquote>
<p>• GPU shows better flexibility and programmability for irregular computations, such as small batches and non- MatMul computations. The training of large FC models also benefits from its sophisticated memory system and higher bandwidth.</p>
</blockquote>
<blockquote>
<p>• CPU has the best programmability, so it achieves the highest FLOPS utilization for RNNs, and it supports the largest model because of large memory capacity.</p>
</blockquote>
</div>
<div id="favourite-machine-learning-frameworks" class="section level2">
<h2><span class="header-section-number">23.18</span> Favourite machine learning frameworks</h2>
<p>Favourite machine learning frameworks are shown in the graph below</p>
<hr />
<p><img src="Figs/MlFrameworks-1.png" width="1152" />
The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<ul>
<li><a href="https://scikit-learn.org/stable/">Scikit-learn</a>
<ul>
<li>Machine Learning in Python</li>
<li>Open source, commercially usable - BSD license</li>
</ul></li>
<li><a href="https://www.tensorflow.org">TensorFlow</a>
<ul>
<li>An end-to-end open source machine learning platform</li>
</ul></li>
<li><a href="https://keras.io">Keras</a>
<ul>
<li>Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.</li>
</ul></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">RandomForest</a>
<ul>
<li>A random forest classifier</li>
</ul></li>
<li><a href="https://xgboost.readthedocs.io/en/latest/">Xgboost</a>
<ul>
<li>XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable.</li>
</ul></li>
<li><a href="https://pytorch.org">PyTorch</a>
<ul>
<li>An open source machine learning framework that accelerates the path from research prototyping to production deployment.</li>
<li>On 30.01.2020 OpenAI announced <a href="https://openai.com/blog/openai-pytorch/">OpenAI → PyTorch</a></li>
</ul></li>
<li><a href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a>
<ul>
<li>LightGBM is a gradient boosting framework that uses tree based learning algorithms.</li>
</ul></li>
<li><a href="http://topepo.github.io/caret/index.html">Caret</a>
<ul>
<li>The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models.</li>
<li>For the programming language R</li>
</ul></li>
<li><a href="https://www.fast.ai">Fast.ai</a>
<ul>
<li>Making neural nets uncool again</li>
<li>Blogs</li>
<li>MOOC<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a></li>
</ul></li>
</ul>
</div>
<div id="favourite-cloud-computing-platforms" class="section level2">
<h2><span class="header-section-number">23.19</span> Favourite cloud computing platforms</h2>
<p>Favourite cloud computing platforms are shown in the graph below</p>
<hr />
<p><img src="Figs/MlCloudFrameworks-1.png" width="1152" />
The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
<ul>
<li><a href="https://aws.amazon.com">Amazon Web Services (AWS)</a>
<ul>
<li>AWS has the services to help you build sophisticated applications with increased flexibility, scalability and reliability</li>
</ul></li>
<li><a href="https://cloud.google.com">Google Cloud Platform (GCP)</a>
<ul>
<li>Build scalable apps</li>
</ul></li>
<li><a href="https://azure.microsoft.com/en-us/">Microsoft Azure</a>
<ul>
<li>Turn ideas into solutions with more than 100 services to build, deploy, and manage applications—in the cloud, on-premises, and at the edge—using the tools and frameworks of your choice.</li>
</ul></li>
<li><a href="https://www.ibm.com/cloud">IBM Cloud</a>
<ul>
<li>Discover a faster, more secure journey to cloud trusted by thousands of enterprises across 20 industries</li>
</ul></li>
<li><a href="https://cloud.vmware.com">VMware Cloud</a>
<ul>
<li>Manage your entire app portfolio across hybrid and native public clouds</li>
</ul></li>
<li><a href="https://www.oracle.com/cloud/">Oracle Cloud</a>
<ul>
<li>Oracle Cloud is a cloud computing service offered by Oracle Corporation providing servers, storage, network, applications and services through a global network of Oracle Corporation managed data centers.</li>
</ul></li>
<li><a href="https://www.salesforce.com/products/service-cloud/overview/">Salesforce Cloud</a>
<ul>
<li>Try the world’s #1 service platform: the time-saving, joy-boosting, relationship-building machine.</li>
</ul></li>
<li><a href="https://eu.alibabacloud.com">Alibaba Cloud</a>
<ul>
<li>Experience the Latest in Cloud Computing, Storage, Networking, Security, Big Data and Artificial Intelligence on Alibaba Cloud</li>
</ul></li>
<li><a href="https://www.sap.com/products/cloud-platform.html">SAP Cloud</a>
<ul>
<li>Achieve process excellence, deliver engaging digital experiences, and simplify data-driven innovation with a multi-cloud architecture.</li>
</ul></li>
<li><a href="https://www.redhat.com/en/technologies/cloud-computing/cloud-access">Red Hat Cloud</a>
<ul>
<li>Red Hat® Cloud Access is the program that allows our customers to run eligible Red Hat product subscriptions on certified public cloud providers.</li>
</ul></li>
</ul>
</div>
<div id="favourite-big-data-analytics-products" class="section level2">
<h2><span class="header-section-number">23.20</span> Favourite big data / analytics products</h2>
<p>Favourite big data / analytics products are shown in the graph below</p>
<hr />
<p><img src="Figs/bigData-1.png" width="1152" /></p>
<p>The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />
</div>
<div id="favourite-automated-machine-learning-tools-or-partial-automl-tools" class="section level2">
<h2><span class="header-section-number">23.21</span> Favourite automated machine learning tools (or partial AutoML tools)</h2>
<p>Favourite automated machine learning tools (or partial AutoML tools) are shown in the graph below</p>
<hr />
<p><img src="Figs/automatedMlTools-1.png" width="1152" />
The last Qualification which is cut off in the legend in the plot above reads <strong>“Some college/university study without earning a bachelor’s degree”</strong></p>
<hr />

</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>

<div id="refs" class="references">
<div id="ref-ayres2007super">
<p>Ayres, Ian. 2007. <em>Super Crunchers: Why Thinking-by-Numbers Is the New Way to Be Smart</em>. Bantam Books.</p>
</div>
<div id="ref-barachant2013classification">
<p>Barachant, Alexandre, Stéphane Bonnet, Marco Congedo, and Christian Jutten. 2013. “Classification of Covariance Matrices Using a Riemannian-Based Kernel for Bci Applications.” <em>Neurocomputing</em> 112: 172–78.</p>
</div>
<div id="ref-binet1916new">
<p>Binet, Alfred, and Th Simon. 1916. “New Methods for the Diagnosis of the Intellectual Level of Subnormals.(L’Année Psych., 1905, Pp. 191-244).”</p>
</div>
<div id="ref-bojarski2016visualbackprop">
<p>Bojarski, Mariusz, Anna Choromanska, Krzysztof Choromanski, Bernhard Firner, Larry Jackel, Urs Muller, and Karol Zieba. 2016. “Visualbackprop: Efficient Visualization of Cnns.” <em>arXiv Preprint arXiv:1611.05418</em>.</p>
</div>
<div id="ref-bojarski2017explaining">
<p>Bojarski, Mariusz, Philip Yeres, Anna Choromanska, Krzysztof Choromanski, Bernhard Firner, Lawrence Jackel, and Urs Muller. 2017. “Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car.” <em>arXiv Preprint arXiv:1704.07911</em>.</p>
</div>
<div id="ref-goodfellow2014explaining">
<p>Goodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. “Explaining and Harnessing Adversarial Examples.” <em>arXiv Preprint arXiv:1412.6572</em>.</p>
</div>
<div id="ref-gottfredson1997mainstream">
<p>Gottfredson, Linda S. 1997. “Mainstream Science on Intelligence: An Editorial with 52 Signatories, History, and Bibliography.” Citeseer.</p>
</div>
<div id="ref-harari2016homo">
<p>Harari, Yuval Noah. 2016. <em>Homo Deus: A Brief History of Tomorrow</em>. Random House.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer.</p>
</div>
<div id="ref-kahneman2011thinking">
<p>Kahneman, Daniel. 2011. <em>Thinking, Fast and Slow</em>. Macmillan.</p>
</div>
<div id="ref-kuhn2013applied">
<p>Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. Vol. 26. Springer.</p>
</div>
<div id="ref-ILSVRC15">
<p>Russakovsky, Olga, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, et al. 2015. “ImageNet Large Scale Visual Recognition Challenge.” <em>International Journal of Computer Vision (IJCV)</em> 115 (3): 211–52. <a href="https://doi.org/10.1007/s11263-015-0816-y">https://doi.org/10.1007/s11263-015-0816-y</a>.</p>
</div>
<div id="ref-tegmark2017life">
<p>Tegmark, Max. 2017. <em>Life 3.0: Being Human in the Age of Artificial Intelligence</em>. Knopf.</p>
</div>
<div id="ref-temko2011eeg">
<p>Temko, A, E Thomas, W Marnane, G Lightbody, and G Boylan. 2011a. “EEG-Based Neonatal Seizure Detection with Support Vector Machines.” <em>Clinical Neurophysiology</em> 122 (3): 464–73.</p>
</div>
<div id="ref-temko2011performance">
<p>Temko, A, E Thomas, W Marnane, G Lightbody, and GB Boylan. 2011b. “Performance Assessment for Eeg-Based Neonatal Seizure Detectors.” <em>Clinical Neurophysiology</em> 122 (3): 474–82.</p>
</div>
<div id="ref-tulio2016should">
<p>Tulio Ribeiro, Marco, Sameer Singh, and Carlos Guestrin. 2016. “" Why Should I Trust You?": Explaining the Predictions of Any Classifier.” <em>arXiv Preprint arXiv:1602.04938</em>.</p>
</div>
<div id="ref-wei2019benchmarking">
<p>Wei, Gu-Yeon, David Brooks, and others. 2019. “Benchmarking Tpu, Gpu, and Cpu Platforms for Deep Learning.” <em>arXiv Preprint arXiv:1907.10701</em>.</p>
</div>
<div id="ref-widmaier2019towards">
<p>Widmaier, Mark, Maximilian Arnold, Sebastian Dorner, Sebastian Cammerer, and Stephan ten Brink. 2019. “Towards Practical Indoor Positioning Based on Massive Mimo Systems.” In <em>2019 Ieee 90th Vehicular Technology Conference (Vtc2019-Fall)</em>, 1–6. IEEE.</p>
</div>
<div id="ref-zhang2018exploring">
<p>Zhang, Zhongxing, Geert Mayer, Yves Dauvilliers, Giuseppe Plazzi, Fabio Pizza, Rolf Fronczek, Joan Santamaria, et al. 2018. “Exploring the Clinical Features of Narcolepsy Type 1 Versus Narcolepsy Type 2 from European Narcolepsy Network Database with Machine Learning.” <em>Scientific Reports</em> 8 (1): 1–11.</p>
</div>
<div id="ref-CycleGAN2017">
<p>Zhu, Jun-Yan, Taesung Park, Phillip Isola, and Alexei A Efros. 2017. “Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks.” In <em>Computer Vision (Iccv), 2017 Ieee International Conference on</em>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>American pioneer in the field of computer gaming and artificial intelligence <a href="https://en.wikipedia.org/wiki/Arthur_Samuel" class="uri">https://en.wikipedia.org/wiki/Arthur_Samuel</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>professor of Computer Science and Machine Learning at Carnegie Mellon <a href="http://www.cs.cmu.edu/~tom/" class="uri">http://www.cs.cmu.edu/~tom/</a><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>17*35=595<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Knowledge neglect <a href="https://en.wikipedia.org/wiki/Knowledge_neglect" class="uri">https://en.wikipedia.org/wiki/Knowledge_neglect</a><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Die drei letzten Bundespräsidenten: Steinmeier, Gauck, Wulf<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p><a href="https://www.anesi.com/bayes.htm" class="uri">https://www.anesi.com/bayes.htm</a><a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Pingo question: What is the probability that the cab involved in the accident was Blue rather than Green? <a href="https://pingo.coactum.de/questions" class="uri">https://pingo.coactum.de/questions</a><a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Screening mammography aims to identify breast cancer at earlier stages of the disease, when treatment can be more successful. Despite the existence of screening programmes worldwide, the interpretation of mammograms is affected by high rates of false positives and false negatives. Here we present an artificial intelligence (AI) system that is capable of surpassing human experts in breast cancer prediction. To assess its performance in the clinical setting, we curated a large representative dataset from the UK and a large enriched dataset from the USA. We show an absolute reduction of 5.7% and 1.2% (USA and UK) in false positives and 9.4% and 2.7% in false negatives. We provide evidence of the ability of the system to generalize from the UK to the USA. In an independent study of six radiologists, the AI system outperformed all of the human readers: the area under the receiver operating characteristic curve (AUC-ROC) for the AI system was greater than the AUC-ROC for the average radiologist by an absolute margin of 11.5%. We ran a simulation in which the AI system participated in the double-reading process that is used in the UK, and found that the AI system maintained non-inferior performance and reduced the workload of the second reader by 88%. This robust assessment of the AI system paves the way for clinical trials to improve the accuracy and efficiency of breast cancer screening. <a href="https://www.nature.com/articles/s41586-019-1799-6" class="uri">https://www.nature.com/articles/s41586-019-1799-6</a><a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Abstract With an estimated 160,000 deaths in 2018, lung cancer is the most common cause of cancer death in the United States1. Lung cancer screening using low-dose computed tomography has been shown to reduce mortality by 20–43% and is now included in US screening guidelines. Existing challenges include inter-grader variability and high false-positive and false-negative rates. We propose a deep learning algorithm that uses a patient’s current and prior computed tomography volumes to predict the risk of lung cancer. Our model achieves a state-of-the-art performance (94.4% area under the curve) on 6,716 National Lung Cancer Screening Trial cases, and performs similarly on an independent clinical validation set of 1,139 cases. We conducted two reader studies. When prior computed tomography imaging was not available, our model outperformed all six radiologists with absolute reductions of 11% in false positives and 5% in false negatives. Where prior computed tomography imaging was available, the model performance was on-par with the same radiologists. This creates an opportunity to optimize the screening process via computer assistance and automation. While the vast majority of patients remain unscreened, we show the potential for deep learning models to increase the accuracy, consistency and adoption of lung cancer screening worldwide. Website: <a href="https://www.nature.com/articles/s41591-019-0447-x" class="uri">https://www.nature.com/articles/s41591-019-0447-x</a><a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Homepage of ILSVRC <a href="http://www.image-net.org/challenges/LSVRC/" class="uri">http://www.image-net.org/challenges/LSVRC/</a><a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p> Homepage of ImageNet <a href="http://www.image-net.org" class="uri">http://www.image-net.org</a><a href="#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p><a href="https://deepmind.com/blog/article/alphago-zero-starting-scratch" class="uri">https://deepmind.com/blog/article/alphago-zero-starting-scratch</a><a href="#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Homepage of DeepMind <a href="https://deepmind.com" class="uri">https://deepmind.com</a><a href="#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Pingo question: Ihre Position zur AGI? <a href="https://pingo.coactum.de/questions" class="uri">https://pingo.coactum.de/questions</a><a href="#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>“Dataism was born from the explosive confluence of two scientific tidal waves. In the 150 years since Charles Darwin published On the Origin of Species, the life sciences have come to see organisms as biochemical algorithms. Simultaneously, in the eight decades since Alan Turing formulated the idea of a Turing Machine, computer scientists have learned to engineer increasingly sophisticated electronic algorithms. Dataism puts the two together, pointing out that exactly the same mathematical laws apply to both biochemical and electronic algorithms. Dataism thereby collapses the barrier between animals and machines, and expects electronic algorithms to eventually decipher and outperform biochemical algorithms.” Harari, Yuval Noah. Homo Deus: A Brief History of Tomorrow . HarperCollins. Kindle Edition. <a href="#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>Good source for feature engineering: <a href="http://www.feat.engineering/index.html" class="uri">http://www.feat.engineering/index.html</a><a href="#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>using the median of all 13 models to determine which 9 models seemed best, then taking the mean of a few different medians of the different model predictions<a href="#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Good source for feature engineering: <a href="http://www.feat.engineering/index.html" class="uri">http://www.feat.engineering/index.html</a><a href="#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Tera Operations Per Second<a href="#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>Massive Open Online Courses<a href="#fnref20" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MlOrienttionBookDown.pdf", "MlOrienttionBookDown.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
